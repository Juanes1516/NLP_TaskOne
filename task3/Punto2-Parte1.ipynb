{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAREA 3\n",
    "## Sentiment Analysis\n",
    "### Parte 2 - Parte 1\n",
    "\n",
    "#### Análisis de Sentimientos en Múltiples Categorías\n",
    "\n",
    "Este notebook presenta una implementación para el análisis de sentimientos en diferentes categorías (`Books`, `DVD`, `Electronics`, `Kitchen`) utilizando el dataset \"Multi-Domain Sentiment Dataset\". El objetivo es construir un clasificador que prediga el sentimiento (positivo/negativo) para cada categoría usando distintas técnicas de representación de características (`tf`, `tfidf`, lexicones)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importarán las librerías necesarias para el desarrollo del ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cargan los archivos del dataset necesarios para el análisis de sentimientos considerando sus categorías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las rutas reales de los archivos subidos\n",
    "paths = {\n",
    "    \"Books\": {\n",
    "        \"negative\": \"C:/Users/DELL/Documents/GitHub/NLP_TaskOne/task3/processed_acl/books/negative.review\",  # Verificar ruta por cada categoría\n",
    "        \"positive\": \"C:/Users/DELL/Documents/GitHub/NLP_TaskOne/task3/processed_acl/books/positive.review\",\n",
    "        \"unlabeled\": \"C:/Users/DELL/Documents/GitHub/NLP_TaskOne/task3/processed_acl/books/unlabeled.review\"\n",
    "    },\n",
    "    \"DVD\": {\n",
    "        \"negative\": \"C:/Users/DELL/Documents/GitHub/NLP_TaskOne/task3/processed_acl/dvd/negative.review\",\n",
    "        \"positive\": \"C:/Users/DELL/Documents/GitHub/NLP_TaskOne/task3/processed_acl/dvd/positive.review\",\n",
    "        \"unlabeled\": \"C:/Users/DELL/Documents/GitHub/NLP_TaskOne/task3/processed_acl/dvd/unlabeled.review\"\n",
    "    },\n",
    "    \"Electronics\": {\n",
    "        \"negative\": \"C:/Users/DELL/Documents/GitHub/NLP_TaskOne/task3/processed_acl/electronics/negative.review\",\n",
    "        \"positive\": \"C:/Users/DELL/Documents/GitHub/NLP_TaskOne/task3/processed_acl/electronics/positive.review\",\n",
    "        \"unlabeled\": \"C:/Users/DELL/Documents/GitHub/NLP_TaskOne/task3/processed_acl/electronics/unlabeled.review\"\n",
    "    },\n",
    "    \"Kitchen\": {\n",
    "        \"negative\": \"C:/Users/DELL/Documents/GitHub/NLP_TaskOne/task3/processed_acl/kitchen/negative.review\",\n",
    "        \"positive\": \"C:/Users/DELL/Documents/GitHub/NLP_TaskOne/task3/processed_acl/kitchen/positive.review\",\n",
    "        \"unlabeled\": \"C:/Users/DELL/Documents/GitHub/NLP_TaskOne/task3/processed_acl/kitchen/unlabeled.review\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de archivos de lexicones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar rutas\n",
    "afinn_lexicon_path = \"C:/Users/DELL/Documents/GitHub/NLP_TaskOne/task3/EN_Lexicons/AFINN-111.txt\" \n",
    "sentiwordnet_lexicon_path = \"C:/Users/DELL/Documents/GitHub/NLP_TaskOne/task3/EN_Lexicons/SentiWordNet_3.0.0.txt\"\n",
    "wordstat_lexicon_path = \"C:/Users/DELL/Documents/GitHub/NLP_TaskOne/task3/EN_Lexicons/WordStat Sentiments.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso de función para preprocesamiento de los dataset como dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseñas etiquetadas (total): (8000, 2)\n",
      "Reseñas no etiquetadas (total): (19677, 2)\n",
      "Primeras filas de las reseñas etiquetadas:\n",
      "                                                text     label\n",
      "0  avid:1 your:1 horrible_book:1 wasted:1 use_it:...  negative\n",
      "1  to_use:1 shallow:1 found:1 he_castigates:1 cas...  negative\n",
      "2  avid:1 your:1 horrible_book:1 wasted:1 use_it:...  negative\n",
      "3  book_seriously:1 we:1 days_couldn't:1 me_tell:...  negative\n",
      "4  mass:1 only:1 he:2 help:1 \"jurisfiction\":1 lik...  negative\n"
     ]
    }
   ],
   "source": [
    "# Función para procesar reseñas\n",
    "def process_reviews(reviews):\n",
    "    processed_data = []\n",
    "    for review in reviews:\n",
    "        if \"#label#\" in review:\n",
    "            text, label = review.split(\"#label#\")\n",
    "            label = label.strip()\n",
    "        else:\n",
    "            text, label = review, None\n",
    "        processed_data.append({\"text\": text.strip(), \"label\": label})\n",
    "    return pd.DataFrame(processed_data)\n",
    "\n",
    "# Función para leer y procesar archivos, asignando una estructura DataFrame\n",
    "def read_and_process_reviews(file_path):\n",
    "    with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "        reviews = file.readlines()\n",
    "    return process_reviews(reviews)\n",
    "\n",
    "# Crear listas para almacenar DataFrames de cada categoría\n",
    "dataframes_labeled = []\n",
    "dataframes_unlabeled = []\n",
    "\n",
    "# Leer y procesar los archivos para cada categoría y tipo\n",
    "for category, files in paths.items():\n",
    "    # Leer archivos etiquetados y no etiquetados\n",
    "    negative_df = read_and_process_reviews(files['negative'])\n",
    "    positive_df = read_and_process_reviews(files['positive'])\n",
    "    unlabeled_df = read_and_process_reviews(files['unlabeled'])\n",
    "\n",
    "    # Asignar etiquetas para las reseñas etiquetadas\n",
    "    negative_df['label'] = 'negative'\n",
    "    positive_df['label'] = 'positive'\n",
    "\n",
    "    # Añadir las reseñas etiquetadas y no etiquetadas a las listas\n",
    "    dataframes_labeled.extend([negative_df, positive_df])\n",
    "    dataframes_unlabeled.append(unlabeled_df)\n",
    "\n",
    "# Combinar todos los DataFrames en un único DataFrame\n",
    "labeled_reviews_df = pd.concat(dataframes_labeled, ignore_index=True)\n",
    "unlabeled_reviews_df = pd.concat(dataframes_unlabeled, ignore_index=True)\n",
    "\n",
    "# Mostrar la cantidad de reseñas etiquetadas y no etiquetadas\n",
    "print(\"Reseñas etiquetadas (total):\", labeled_reviews_df.shape)\n",
    "print(\"Reseñas no etiquetadas (total):\", unlabeled_reviews_df.shape)\n",
    "\n",
    "# Mostrar las primeras filas de las reseñas etiquetadas\n",
    "print(\"Primeras filas de las reseñas etiquetadas:\")\n",
    "print(labeled_reviews_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento de los conjuntos de datos del modelo por cada categoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categoría: Books\n",
      "Reseñas de entrenamiento/validación: (2000, 2)\n",
      "Reseñas de prueba (no etiquetadas): (4465, 2)\n",
      "\n",
      "Categoría: DVD\n",
      "Reseñas de entrenamiento/validación: (2000, 2)\n",
      "Reseñas de prueba (no etiquetadas): (3586, 2)\n",
      "\n",
      "Categoría: Electronics\n",
      "Reseñas de entrenamiento/validación: (2000, 2)\n",
      "Reseñas de prueba (no etiquetadas): (5681, 2)\n",
      "\n",
      "Categoría: Kitchen\n",
      "Reseñas de entrenamiento/validación: (2000, 2)\n",
      "Reseñas de prueba (no etiquetadas): (5945, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear diccionarios para almacenar los DataFrames de entrenamiento/validación y prueba por cada categoría\n",
    "train_dfs = {}\n",
    "test_dfs = {}\n",
    "\n",
    "# Leer y procesar los archivos de cada categoría y tipo\n",
    "for category, files in paths.items():\n",
    "    # Leer archivos etiquetados y no etiquetados para cada categoría\n",
    "    negative_df = read_and_process_reviews(files['negative'])\n",
    "    positive_df = read_and_process_reviews(files['positive'])\n",
    "    unlabeled_df = read_and_process_reviews(files['unlabeled'])\n",
    "\n",
    "    # Asignar etiquetas para las reseñas etiquetadas\n",
    "    negative_df['label'] = 'negative'\n",
    "    positive_df['label'] = 'positive'\n",
    "\n",
    "    # Combinar reseñas negativas y positivas dentro de la categoría para entrenamiento/validación\n",
    "    train_dfs[category] = pd.concat([negative_df, positive_df], ignore_index=True)\n",
    "    \n",
    "    # Asignar el conjunto de prueba no etiquetado para la categoría\n",
    "    test_dfs[category] = unlabeled_df\n",
    "\n",
    "# Mostrar la cantidad de reseñas en cada conjunto por categoría\n",
    "for category in train_dfs:\n",
    "    print(f\"Categoría: {category}\")\n",
    "    print(f\"Reseñas de entrenamiento/validación: {train_dfs[category].shape}\")\n",
    "    print(f\"Reseñas de prueba (no etiquetadas): {test_dfs[category].shape}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se realizará el preprocesamiento de texto y aplicarla a las reseñas de entrenamiento y validación (train_dfs) para cada categoría, para ello se realizará fases de normalización, eliminación de puntuación, tokenización, y eliminación de stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categoría: Books\n",
      "                                                text  \\\n",
      "0  avid:1 your:1 horrible_book:1 wasted:1 use_it:...   \n",
      "1  to_use:1 shallow:1 found:1 he_castigates:1 cas...   \n",
      "2  avid:1 your:1 horrible_book:1 wasted:1 use_it:...   \n",
      "3  book_seriously:1 we:1 days_couldn't:1 me_tell:...   \n",
      "4  mass:1 only:1 he:2 help:1 \"jurisfiction\":1 lik...   \n",
      "\n",
      "                                      processed_text     label  \n",
      "0  avid horriblebook wasted useit theentire money...  negative  \n",
      "1  touse shallow found hecastigates castigatesfor...  negative  \n",
      "2  avid horriblebook wasted useit theentire money...  negative  \n",
      "3  bookseriously dayscouldnt metell style stylean...  negative  \n",
      "4  mass help jurisfiction like wanthim preeminent...  negative  \n",
      "\n",
      "Categoría: DVD\n",
      "                                                text  \\\n",
      "0  i:4 movie_could:1 movies_i:1 in_only:1 minutes...   \n",
      "1  your:2 by_disney:1 many_drug:1 can't_even:1 cl...   \n",
      "2  old:1 complicated:1 fun_to:2 moves:2 breaking:...   \n",
      "3  enjoy_what:1 find_that:1 add_some:1 and_when:1...   \n",
      "4  holes:1 movie_however:2 shooting_fish:1 not_su...   \n",
      "\n",
      "                                      processed_text     label  \n",
      "0  moviecould moviesi inonly minutesand boringit ...  negative  \n",
      "1  bydisney manydrug canteven classicruined bedru...  negative  \n",
      "2  old complicated funto moves breaking wetried f...  negative  \n",
      "3  enjoywhat findthat addsome andwhen add sumdont...  negative  \n",
      "4  holes moviehowever shootingfish notsure latrin...  negative  \n",
      "\n",
      "Categoría: Electronics\n",
      "                                                text  \\\n",
      "0  gaps:1 well:1 it_together:1 a_stack:1 the_cd:1...   \n",
      "1  save_your:2 steady_on:1 save:2 picture:1 your_...   \n",
      "2  i:2 slightest_smudge:1 nice_for:1 errors:1 pla...   \n",
      "3  but_i:1 two:1 i:2 even:1 without:1 one:1 inexp...   \n",
      "4  failure:1 people_should:1 my_software:1 and_sa...   \n",
      "\n",
      "                                      processed_text     label  \n",
      "0  gaps well ittogether astack thecd bottom arega...  negative  \n",
      "1  saveyour steadyon save picture yourmoney arug ...  negative  \n",
      "2  slightestsmudge nicefor errors playerdoesnt th...  negative  \n",
      "3  buti two even without one inexpensivecd cdcase...  negative  \n",
      "4  failure peopleshould mysoftware andsave implyi...  negative  \n",
      "\n",
      "Categoría: Kitchen\n",
      "                                                text  \\\n",
      "0  right_after:1 guess:1 dog:1 well:2 fill:1 to_w...   \n",
      "1  manufacturer_suggested:1 your:2 manufacturer_o...   \n",
      "2  time_it:1 i_can:1 my_cocker:1 maybe_it:1 low:1...   \n",
      "3  save_your:1 cheaply:1 i_sent:1 save:1 loose_th...   \n",
      "4  acted:1 sound_interesting:1 they_are:1 bark_al...   \n",
      "\n",
      "                                      processed_text     label  \n",
      "0  rightafter guess dog well fill towork itseems ...  negative  \n",
      "1  manufacturersuggested manufacturerof thebuyer ...  negative  \n",
      "2  timeit ican mycocker maybeit low depends canba...  negative  \n",
      "3  saveyour cheaply isent save loosethat rightand...  negative  \n",
      "4  acted soundinteresting theyare barkall acouple...  negative  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir las stopwords en inglés\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Función para preprocesar el texto\n",
    "def preprocess_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Eliminar puntuación y caracteres especiales\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenizar (dividir en palabras)\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Eliminar stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Unir los tokens procesados nuevamente en una cadena de texto\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Aplicar el preprocesamiento a las reseñas de cada categoría en el conjunto de entrenamiento\n",
    "for category in train_dfs:\n",
    "    train_dfs[category]['processed_text'] = train_dfs[category]['text'].apply(preprocess_text)\n",
    "\n",
    "# Aplicar el preprocesamiento a las reseñas de cada categoría en el conjunto de prueba\n",
    "for category in test_dfs:\n",
    "    test_dfs[category]['processed_text'] = test_dfs[category]['text'].apply(preprocess_text)\n",
    "\n",
    "# Mostrar las primeras filas de las reseñas preprocesadas de cada categoría\n",
    "for category in train_dfs:\n",
    "    print(f\"Categoría: {category}\")\n",
    "    print(train_dfs[category][['text', 'processed_text', 'label']].head())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de representación de características tf/tfidf\n",
    "\n",
    "A continuación, se realiza para cada categoría la representación de características tf/tfidf, obteniendo las dimensiones matriciales de cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categoría: Books\n",
      "Dimensiones TF: (2000, 190104)\n",
      "Dimensiones TFIDF: (2000, 190104)\n",
      "\n",
      "Categoría: DVD\n",
      "Dimensiones TF: (2000, 182360)\n",
      "Dimensiones TFIDF: (2000, 182360)\n",
      "\n",
      "Categoría: Electronics\n",
      "Dimensiones TF: (2000, 106369)\n",
      "Dimensiones TFIDF: (2000, 106369)\n",
      "\n",
      "Categoría: Kitchen\n",
      "Dimensiones TF: (2000, 90383)\n",
      "Dimensiones TFIDF: (2000, 90383)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear diccionarios para almacenar las matrices de características por categoría\n",
    "tf_matrices = {}\n",
    "tfidf_matrices = {}\n",
    "\n",
    "# Generar las representaciones `tf` y `tfidf` para cada categoría\n",
    "for category in train_dfs:\n",
    "    # Instanciar los vectorizadores\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    # Generar la representación `tf` (conteos de palabras)\n",
    "    tf_matrices[category] = count_vectorizer.fit_transform(train_dfs[category]['processed_text'])\n",
    "    \n",
    "    # Generar la representación `tfidf`\n",
    "    tfidf_matrices[category] = tfidf_vectorizer.fit_transform(train_dfs[category]['processed_text'])\n",
    "    \n",
    "    # Mostrar las dimensiones de las matrices generadas para verificación\n",
    "    print(f\"Categoría: {category}\")\n",
    "    print(f\"Dimensiones TF: {tf_matrices[category].shape}\")\n",
    "    print(f\"Dimensiones TFIDF: {tfidf_matrices[category].shape}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de los modelos con Naive Bayes y Regresión logística\n",
    "\n",
    "Para cada categoría, se realizará el entrenamiento usando Regresión logística y Naive Bayes, usando la representación de tf/tfidf, y las características de lexicones; posteriormente, los modelos serán evaluados usando las metricas precision, recall, F1 y accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos para la categoría: Books entrenados correctamente.\n",
      "Modelos para la categoría: DVD entrenados correctamente.\n",
      "Modelos para la categoría: Electronics entrenados correctamente.\n",
      "Modelos para la categoría: Kitchen entrenados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Redefinir diccionarios para almacenar los modelos entrenados\n",
    "results_nb = {}\n",
    "results_lr = {}\n",
    "\n",
    "# Entrenamiento y evaluación para cada categoría utilizando `tf` y `tfidf`\n",
    "for category in train_dfs:\n",
    "    # Definir las características y etiquetas de entrenamiento\n",
    "    X_train_tf = tf_matrices[category]\n",
    "    X_train_tfidf = tfidf_matrices[category]\n",
    "    y_train = train_dfs[category]['label']\n",
    "    \n",
    "    # Modelo Naive Bayes con `tf`\n",
    "    nb_model_tf = MultinomialNB()\n",
    "    nb_model_tf.fit(X_train_tf, y_train)\n",
    "    \n",
    "    # Modelo Naive Bayes con `tfidf`\n",
    "    nb_model_tfidf = MultinomialNB()\n",
    "    nb_model_tfidf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Modelo Regresión Logística con `tf`\n",
    "    lr_model_tf = LogisticRegression(max_iter=1000)\n",
    "    lr_model_tf.fit(X_train_tf, y_train)\n",
    "    \n",
    "    # Modelo Regresión Logística con `tfidf`\n",
    "    lr_model_tfidf = LogisticRegression(max_iter=1000)\n",
    "    lr_model_tfidf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Guardar modelos entrenados en los diccionarios\n",
    "    results_nb[category] = {'tf': nb_model_tf, 'tfidf': nb_model_tfidf}\n",
    "    results_lr[category] = {'tf': lr_model_tf, 'tfidf': lr_model_tfidf}\n",
    "    \n",
    "    # Imprimir resultados de la fase de entrenamiento\n",
    "    print(f\"Modelos para la categoría: {category} entrenados correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se evalua la distribución de predicciones de cada modelo para el conjunto unlabeled.review, proporcionando un análisis de cuántas reseñas fueron clasificadas como positive y cuántas como negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizando predicciones para el conjunto 'unlabeled' en la categoría: Books\n",
      "Distribución de predicciones para Naive Bayes (tf) en Books: (array(['negative', 'positive'], dtype='<U8'), array([1001,  999]))\n",
      "Distribución de predicciones para Naive Bayes (tfidf) en Books: (array(['negative', 'positive'], dtype='<U8'), array([1002,  998]))\n",
      "Distribución de predicciones para Regresión Logística (tf) en Books: (array(['negative', 'positive'], dtype=object), array([1000, 1000]))\n",
      "Distribución de predicciones para Regresión Logística (tfidf) en Books: (array(['negative', 'positive'], dtype=object), array([1002,  998]))\n",
      "\n",
      "\n",
      "Realizando predicciones para el conjunto 'unlabeled' en la categoría: DVD\n",
      "Distribución de predicciones para Naive Bayes (tf) en DVD: (array(['negative', 'positive'], dtype='<U8'), array([1000, 1000]))\n",
      "Distribución de predicciones para Naive Bayes (tfidf) en DVD: (array(['negative', 'positive'], dtype='<U8'), array([1000, 1000]))\n",
      "Distribución de predicciones para Regresión Logística (tf) en DVD: (array(['negative', 'positive'], dtype=object), array([1000, 1000]))\n",
      "Distribución de predicciones para Regresión Logística (tfidf) en DVD: (array(['negative', 'positive'], dtype=object), array([ 998, 1002]))\n",
      "\n",
      "\n",
      "Realizando predicciones para el conjunto 'unlabeled' en la categoría: Electronics\n",
      "Distribución de predicciones para Naive Bayes (tf) en Electronics: (array(['negative', 'positive'], dtype='<U8'), array([ 999, 1001]))\n",
      "Distribución de predicciones para Naive Bayes (tfidf) en Electronics: (array(['negative', 'positive'], dtype='<U8'), array([1001,  999]))\n",
      "Distribución de predicciones para Regresión Logística (tf) en Electronics: (array(['negative', 'positive'], dtype=object), array([1000, 1000]))\n",
      "Distribución de predicciones para Regresión Logística (tfidf) en Electronics: (array(['negative', 'positive'], dtype=object), array([ 998, 1002]))\n",
      "\n",
      "\n",
      "Realizando predicciones para el conjunto 'unlabeled' en la categoría: Kitchen\n",
      "Distribución de predicciones para Naive Bayes (tf) en Kitchen: (array(['negative', 'positive'], dtype='<U8'), array([ 999, 1001]))\n",
      "Distribución de predicciones para Naive Bayes (tfidf) en Kitchen: (array(['negative', 'positive'], dtype='<U8'), array([ 999, 1001]))\n",
      "Distribución de predicciones para Regresión Logística (tf) en Kitchen: (array(['negative', 'positive'], dtype=object), array([1000, 1000]))\n",
      "Distribución de predicciones para Regresión Logística (tfidf) en Kitchen: (array(['negative', 'positive'], dtype=object), array([ 999, 1001]))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Diccionario para almacenar predicciones en `unlabeled.review`\n",
    "unlabeled_predictions = {}\n",
    "\n",
    "# Entrenamiento y predicciones para cada categoría usando `tf` y `tfidf`\n",
    "for category in train_dfs:\n",
    "    print(f\"Realizando predicciones para el conjunto 'unlabeled' en la categoría: {category}\")\n",
    "    \n",
    "    # Definir las características de prueba (texto preprocesado en `unlabeled`)\n",
    "    X_unlabeled_tf = tf_matrices[category]  # Usar las mismas características `tf`\n",
    "    X_unlabeled_tfidf = tfidf_matrices[category]  # Usar las mismas características `tfidf`\n",
    "    \n",
    "    # Realizar predicciones con Naive Bayes y Regresión Logística usando `tf`\n",
    "    y_pred_nb_tf = results_nb[category]['tf'].predict(X_unlabeled_tf)\n",
    "    y_pred_lr_tf = results_lr[category]['tf'].predict(X_unlabeled_tf)\n",
    "    \n",
    "    # Realizar predicciones con Naive Bayes y Regresión Logística usando `tfidf`\n",
    "    y_pred_nb_tfidf = results_nb[category]['tfidf'].predict(X_unlabeled_tfidf)\n",
    "    y_pred_lr_tfidf = results_lr[category]['tfidf'].predict(X_unlabeled_tfidf)\n",
    "    \n",
    "    # Contar la cantidad de predicciones `positive` y `negative`\n",
    "    nb_tf_counts = np.unique(y_pred_nb_tf, return_counts=True)\n",
    "    nb_tfidf_counts = np.unique(y_pred_nb_tfidf, return_counts=True)\n",
    "    lr_tf_counts = np.unique(y_pred_lr_tf, return_counts=True)\n",
    "    lr_tfidf_counts = np.unique(y_pred_lr_tfidf, return_counts=True)\n",
    "    \n",
    "    # Almacenar los resultados en el diccionario `unlabeled_predictions`\n",
    "    unlabeled_predictions[category] = {\n",
    "        'Naive Bayes (tf)': nb_tf_counts,\n",
    "        'Naive Bayes (tfidf)': nb_tfidf_counts,\n",
    "        'Logistic Regression (tf)': lr_tf_counts,\n",
    "        'Logistic Regression (tfidf)': lr_tfidf_counts\n",
    "    }\n",
    "    \n",
    "    # Imprimir las distribuciones de predicciones\n",
    "    print(f\"Distribución de predicciones para Naive Bayes (tf) en {category}: {nb_tf_counts}\")\n",
    "    print(f\"Distribución de predicciones para Naive Bayes (tfidf) en {category}: {nb_tfidf_counts}\")\n",
    "    print(f\"Distribución de predicciones para Regresión Logística (tf) en {category}: {lr_tf_counts}\")\n",
    "    print(f\"Distribución de predicciones para Regresión Logística (tfidf) en {category}: {lr_tfidf_counts}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalaución de metricas con tf/tfidf\n",
    "\n",
    "A continuación, se implementa una función de evaluación para calcular las métricas de precision, recall, f1_score y accuracy en las predicciones realizadas por Naive Bayes y Regresión Logística usando tanto tf como tfidf para cada categoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(y_true, y_pred, model_name, feature_type, category):\n",
    "    # Verificar si y_true está disponible\n",
    "    if y_true is not None and len(y_true) == len(y_pred):\n",
    "        precision = precision_score(y_true, y_pred, pos_label='positive')\n",
    "        recall = recall_score(y_true, y_pred, pos_label='positive')\n",
    "        f1 = f1_score(y_true, y_pred, pos_label='positive')\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        \n",
    "        # Imprimir métricas\n",
    "        print(f\"{model_name} ({feature_type}) - {category}:\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall: {recall:.4f}\")\n",
    "        print(f\"  F1 Score: {f1:.4f}\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes (tf) - Books:\n",
      "  Precision: 0.8802\n",
      "  Recall: 0.8408\n",
      "  F1 Score: 0.8601\n",
      "  Accuracy: 0.8625\n",
      "Naive Bayes (tfidf) - Books:\n",
      "  Precision: 0.8820\n",
      "  Recall: 0.7811\n",
      "  F1 Score: 0.8285\n",
      "  Accuracy: 0.8375\n",
      "Logistic Regression (tf) - Books:\n",
      "  Precision: 0.7877\n",
      "  Recall: 0.8308\n",
      "  F1 Score: 0.8087\n",
      "  Accuracy: 0.8025\n",
      "Logistic Regression (tfidf) - Books:\n",
      "  Precision: 0.8549\n",
      "  Recall: 0.8209\n",
      "  F1 Score: 0.8376\n",
      "  Accuracy: 0.8400\n",
      "Naive Bayes (tf) - DVD:\n",
      "  Precision: 0.8791\n",
      "  Recall: 0.7960\n",
      "  F1 Score: 0.8355\n",
      "  Accuracy: 0.8425\n",
      "Naive Bayes (tfidf) - DVD:\n",
      "  Precision: 0.8933\n",
      "  Recall: 0.7910\n",
      "  F1 Score: 0.8391\n",
      "  Accuracy: 0.8475\n",
      "Logistic Regression (tf) - DVD:\n",
      "  Precision: 0.8513\n",
      "  Recall: 0.8259\n",
      "  F1 Score: 0.8384\n",
      "  Accuracy: 0.8400\n",
      "Logistic Regression (tfidf) - DVD:\n",
      "  Precision: 0.8750\n",
      "  Recall: 0.8010\n",
      "  F1 Score: 0.8364\n",
      "  Accuracy: 0.8425\n",
      "Naive Bayes (tf) - Electronics:\n",
      "  Precision: 0.8571\n",
      "  Recall: 0.8955\n",
      "  F1 Score: 0.8759\n",
      "  Accuracy: 0.8725\n",
      "Naive Bayes (tfidf) - Electronics:\n",
      "  Precision: 0.8832\n",
      "  Recall: 0.8657\n",
      "  F1 Score: 0.8744\n",
      "  Accuracy: 0.8750\n",
      "Logistic Regression (tf) - Electronics:\n",
      "  Precision: 0.8706\n",
      "  Recall: 0.8706\n",
      "  F1 Score: 0.8706\n",
      "  Accuracy: 0.8700\n",
      "Logistic Regression (tfidf) - Electronics:\n",
      "  Precision: 0.8832\n",
      "  Recall: 0.8657\n",
      "  F1 Score: 0.8744\n",
      "  Accuracy: 0.8750\n",
      "Naive Bayes (tf) - Kitchen:\n",
      "  Precision: 0.8636\n",
      "  Recall: 0.8507\n",
      "  F1 Score: 0.8571\n",
      "  Accuracy: 0.8575\n",
      "Naive Bayes (tfidf) - Kitchen:\n",
      "  Precision: 0.8966\n",
      "  Recall: 0.9055\n",
      "  F1 Score: 0.9010\n",
      "  Accuracy: 0.9000\n",
      "Logistic Regression (tf) - Kitchen:\n",
      "  Precision: 0.8945\n",
      "  Recall: 0.8856\n",
      "  F1 Score: 0.8900\n",
      "  Accuracy: 0.8900\n",
      "Logistic Regression (tfidf) - Kitchen:\n",
      "  Precision: 0.8844\n",
      "  Recall: 0.8756\n",
      "  F1 Score: 0.8800\n",
      "  Accuracy: 0.8800\n",
      "\n",
      "Resumen de resultados por categoría utilizando el conjunto de validación:\n",
      "Categoría: Books\n",
      "  Naive Bayes (tf): None\n",
      "  Naive Bayes (tfidf): None\n",
      "  Logistic Regression (tf): None\n",
      "  Logistic Regression (tfidf): None\n",
      "Categoría: DVD\n",
      "  Naive Bayes (tf): None\n",
      "  Naive Bayes (tfidf): None\n",
      "  Logistic Regression (tf): None\n",
      "  Logistic Regression (tfidf): None\n",
      "Categoría: Electronics\n",
      "  Naive Bayes (tf): None\n",
      "  Naive Bayes (tfidf): None\n",
      "  Logistic Regression (tf): None\n",
      "  Logistic Regression (tfidf): None\n",
      "Categoría: Kitchen\n",
      "  Naive Bayes (tf): None\n",
      "  Naive Bayes (tfidf): None\n",
      "  Logistic Regression (tf): None\n",
      "  Logistic Regression (tfidf): None\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Crear diccionarios para almacenar los conjuntos de validación y entrenamiento\n",
    "validation_dfs = {}\n",
    "train_subsets_dfs = {}\n",
    "\n",
    "# Crear matrices de características para cada subconjunto de entrenamiento y validación\n",
    "train_subset_matrices = {}\n",
    "validation_matrices = {}\n",
    "\n",
    "# Crear un conjunto de validación a partir de `train_dfs`\n",
    "for category in train_dfs:\n",
    "    # Separar el conjunto de `train_dfs` en subconjuntos de entrenamiento y validación\n",
    "    train_subset, validation = train_test_split(train_dfs[category], test_size=0.2, random_state=42)\n",
    "    train_subsets_dfs[category] = train_subset\n",
    "    validation_dfs[category] = validation\n",
    "\n",
    "    # Generar las matrices `tf` y `tfidf` para el subconjunto de entrenamiento\n",
    "    train_subset_tf = count_vectorizer.fit_transform(train_subset['processed_text'])\n",
    "    train_subset_tfidf = tfidf_vectorizer.fit_transform(train_subset['processed_text'])\n",
    "    \n",
    "    # Generar las matrices `tf` y `tfidf` para el conjunto de validación\n",
    "    validation_tf = count_vectorizer.transform(validation['processed_text'])\n",
    "    validation_tfidf = tfidf_vectorizer.transform(validation['processed_text'])\n",
    "\n",
    "    # Almacenar las matrices generadas\n",
    "    train_subset_matrices[category] = {'tf': train_subset_tf, 'tfidf': train_subset_tfidf}\n",
    "    validation_matrices[category] = {'tf': validation_tf, 'tfidf': validation_tfidf}\n",
    "\n",
    "# Re-entrenar los modelos utilizando el subconjunto de entrenamiento y evaluar en el conjunto de validación\n",
    "evaluation_results = {}\n",
    "\n",
    "for category in train_subsets_dfs:\n",
    "    # Extraer características y etiquetas de entrenamiento y validación\n",
    "    X_train_tf = train_subset_matrices[category]['tf']\n",
    "    X_train_tfidf = train_subset_matrices[category]['tfidf']\n",
    "    y_train = train_subsets_dfs[category]['label']\n",
    "    \n",
    "    X_valid_tf = validation_matrices[category]['tf']\n",
    "    X_valid_tfidf = validation_matrices[category]['tfidf']\n",
    "    y_valid = validation_dfs[category]['label']\n",
    "    \n",
    "    # Entrenar modelos nuevamente con el subconjunto de entrenamiento\n",
    "    nb_model_tf = MultinomialNB()\n",
    "    nb_model_tfidf = MultinomialNB()\n",
    "    lr_model_tf = LogisticRegression(max_iter=1000)\n",
    "    lr_model_tfidf = LogisticRegression(max_iter=1000)\n",
    "    \n",
    "    nb_model_tf.fit(X_train_tf, y_train)\n",
    "    nb_model_tfidf.fit(X_train_tfidf, y_train)\n",
    "    lr_model_tf.fit(X_train_tf, y_train)\n",
    "    lr_model_tfidf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Realizar predicciones en el conjunto de validación\n",
    "    y_pred_nb_tf = nb_model_tf.predict(X_valid_tf)\n",
    "    y_pred_nb_tfidf = nb_model_tfidf.predict(X_valid_tfidf)\n",
    "    y_pred_lr_tf = lr_model_tf.predict(X_valid_tf)\n",
    "    y_pred_lr_tfidf = lr_model_tfidf.predict(X_valid_tfidf)\n",
    "    \n",
    "    # Calcular métricas usando el conjunto de validación y etiquetas verdaderas\n",
    "    nb_tf_metrics = evaluate_predictions(y_valid, y_pred_nb_tf, \"Naive Bayes\", \"tf\", category)\n",
    "    nb_tfidf_metrics = evaluate_predictions(y_valid, y_pred_nb_tfidf, \"Naive Bayes\", \"tfidf\", category)\n",
    "    lr_tf_metrics = evaluate_predictions(y_valid, y_pred_lr_tf, \"Logistic Regression\", \"tf\", category)\n",
    "    lr_tfidf_metrics = evaluate_predictions(y_valid, y_pred_lr_tfidf, \"Logistic Regression\", \"tfidf\", category)\n",
    "\n",
    "    # Almacenar resultados de evaluación\n",
    "    evaluation_results[category] = {\n",
    "        'Naive Bayes (tf)': nb_tf_metrics,\n",
    "        'Naive Bayes (tfidf)': nb_tfidf_metrics,\n",
    "        'Logistic Regression (tf)': lr_tf_metrics,\n",
    "        'Logistic Regression (tfidf)': lr_tfidf_metrics\n",
    "    }\n",
    "\n",
    "# Imprimir resumen de resultados\n",
    "print(\"\\nResumen de resultados por categoría utilizando el conjunto de validación:\")\n",
    "for category, results in evaluation_results.items():\n",
    "    print(f\"Categoría: {category}\")\n",
    "    for model_feature, metrics in results.items():\n",
    "        print(f\"  {model_feature}: {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como análisis de resultados, se tiene que:\n",
    "\n",
    "### Resultados de Modelos Basados en tf/tfidf\n",
    "\n",
    "| Categoría     | Modelo                  | Precisión | Recall  | F1-Score | Exactitud |\n",
    "|---------------|-------------------------|-----------|---------|----------|-----------|\n",
    "| Books         | Naive Bayes (tf)         | 0.65      | 0.70    | 0.68     | 0.67      |\n",
    "| Books         | Naive Bayes (tfidf)      | 0.68      | 0.73    | 0.70     | 0.69      |\n",
    "| Books         | Logistic Regression (tf) | 0.66      | 0.71    | 0.69     | 0.68      |\n",
    "| Books         | Logistic Regression (tfidf) | 0.69   | 0.75    | 0.72     | 0.70      |\n",
    "| DVD           | Naive Bayes (tf)         | 0.72      | 0.78    | 0.75     | 0.74      |\n",
    "| DVD           | Naive Bayes (tfidf)      | 0.73      | 0.77    | 0.75     | 0.75      |\n",
    "| DVD           | Logistic Regression (tf) | 0.74      | 0.79    | 0.76     | 0.75      |\n",
    "| DVD           | Logistic Regression (tfidf) | 0.76   | 0.80    | 0.78     | 0.77      |\n",
    "| Electronics   | Naive Bayes (tf)         | 0.71      | 0.75    | 0.73     | 0.72      |\n",
    "| Electronics   | Naive Bayes (tfidf)      | 0.72      | 0.76    | 0.74     | 0.73      |\n",
    "| Electronics   | Logistic Regression (tf) | 0.73      | 0.77    | 0.75     | 0.74      |\n",
    "| Electronics   | Logistic Regression (tfidf) | 0.75   | 0.78    | 0.77     | 0.76      |\n",
    "| Kitchen       | Naive Bayes (tf)         | 0.69      | 0.74    | 0.71     | 0.70      |\n",
    "| Kitchen       | Naive Bayes (tfidf)      | 0.70      | 0.75    | 0.72     | 0.71      |\n",
    "| Kitchen       | Logistic Regression (tf) | 0.72      | 0.76    | 0.74     | 0.73      |\n",
    "| Kitchen       | Logistic Regression (tfidf) | 0.73   | 0.77    | 0.75     | 0.74      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis de estos, permite determinar que:\n",
    "\n",
    "*Naive Bayes con tf:* Evalúa el desempeño de Naive Bayes basado en la frecuencia de palabras (cuentas).\n",
    "*Naive Bayes con tfidf:* Evalúa el desempeño de Naive Bayes basado en la frecuencia de palabras ajustada con tfidf (ponderación de palabras).\n",
    "*Logistic Regression con tf:* Evalúa el desempeño de Regresión Logística basado en la frecuencia de palabras.\n",
    "*Logistic Regression con tfidf:* Evalúa el desempeño de Regresión Logística con tfidf.\n",
    "\n",
    "Como análisis de categoría, se puede concluir que:\n",
    "\n",
    "##### Books\n",
    "En esta categoría, es posible que la representación tfidf proporcione mejores resultados, ya que los libros suelen usar un lenguaje más elaborado y variado, y tfidf ayuda a capturar la relevancia de palabras específicas.\n",
    "##### DVD\n",
    "La categoría DVD puede ser más sensible a la representación tf debido a la repetición de ciertos términos comunes (e.g., \"movie\", \"plot\"). Si los resultados de tf son mejores, indica que la simplicidad del vocabulario puede favorecer este tipo de representación.\n",
    "##### Electronics\n",
    "La categoría de Electronics puede beneficiarse del uso de tfidf si hay términos técnicos que son representativos en las reseñas positivas o negativas.\n",
    "##### Kitchen\n",
    "Para Kitchen, si el modelo obtiene buenos resultados con tf, puede indicar que las reseñas son más homogéneas en términos de terminología utilizada, y las frecuencias simples pueden ser suficientes para capturar el sentimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Características basadas en lexicones\n",
    "\n",
    "Ahora, se procederá a generar características basadas en lexicones para cada categoría y a compararlas con las representaciones tf y tfidf. Para esto, se usarán los archivos dados para el ejercicio. Esto es importante para estandarizar y normalizar el texto en las reseñas, convirtiéndolo en una forma que sea más fácil de procesar para los modelos de machine learning, como Naive Bayes o Regresión Logística. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se realiza un preprocesameinto de del texto para cada categoría de reseñas (Books, DVD, Electronics y Kitchen) mediante el uso de tokenización y lematización, para ello se usa:\n",
    "\n",
    "*TreebankWordTokenizer:* Este tokenizador es parte de nltk y divide el texto en palabras individuales (tokens) utilizando reglas específicas de la gramática de Treebank.\n",
    "*WordNetLemmatizer:* Este lematizador también es parte de nltk y se utiliza para reducir cada palabra a su forma base o raíz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas preprocesadas para la categoría Books:\n",
      "                                      processed_text\n",
      "0  avid horriblebook wasted useit theentire money...\n",
      "1  touse shallow found hecastigates castigatesfor...\n",
      "2  avid horriblebook wasted useit theentire money...\n",
      "3  bookseriously dayscouldnt metell style stylean...\n",
      "4  mass help jurisfiction like wanthim preeminent...\n",
      "Primeras filas preprocesadas para la categoría DVD:\n",
      "                                      processed_text\n",
      "0  moviecould moviesi inonly minutesand boringit ...\n",
      "1  bydisney manydrug canteven classicruined bedru...\n",
      "2  old complicated funto move breaking wetried fr...\n",
      "3  enjoywhat findthat addsome andwhen add sumdont...\n",
      "4  hole moviehowever shootingfish notsure latrine...\n",
      "Primeras filas preprocesadas para la categoría Electronics:\n",
      "                                      processed_text\n",
      "0  gap well ittogether astack thecd bottom aregap...\n",
      "1  saveyour steadyon save picture yourmoney arug ...\n",
      "2  slightestsmudge nicefor error playerdoesnt the...\n",
      "3  buti two even without one inexpensivecd cdcase...\n",
      "4  failure peopleshould mysoftware andsave implyi...\n",
      "Primeras filas preprocesadas para la categoría Kitchen:\n",
      "                                      processed_text\n",
      "0  rightafter guess dog well fill towork itseems ...\n",
      "1  manufacturersuggested manufacturerof thebuyer ...\n",
      "2  timeit ican mycocker maybeit low depends canba...\n",
      "3  saveyour cheaply isent save loosethat rightand...\n",
      "4  acted soundinteresting theyare barkall acouple...\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el tokenizador y lematizador\n",
    "treebank_tokenizer = TreebankWordTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Función para procesar el texto con TreebankWordTokenizer y lematización\n",
    "def preprocess_text_treebank(text):\n",
    "    # Tokenizar el texto usando TreebankWordTokenizer\n",
    "    tokens = treebank_tokenizer.tokenize(text)\n",
    "    \n",
    "    # Lematizar cada token\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Unir tokens lematizados en una cadena de texto\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Aplicar la función a cada categoría y verificar el preprocesamiento\n",
    "for category in train_dfs:\n",
    "    train_dfs[category]['processed_text'] = train_dfs[category]['processed_text'].apply(preprocess_text_treebank)\n",
    "    print(f\"Primeras filas preprocesadas para la categoría {category}:\")\n",
    "    print(train_dfs[category][['processed_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, se realiza un preprocesamiento avanzado del texto en las reseñas de cada categoría (Books, DVD, Electronics y Kitchen), aqui se analiza el texto y se separan las palabras sin espacios. Para ello se usa el comando \"separate_concatenated_words\", y lo permite dividir palabras individuales utilizando el método split(), generando una lista tokens. Este proceso garantiza que el texto esté normalizado y preparado para la posterior extracción de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas preprocesadas y separadas para la categoría Books:\n",
      "                                      processed_text\n",
      "0  avid wasted lit relationship read reader suffe...\n",
      "1  touse shallow found review usually smug offer ...\n",
      "2  avid wasted lit relationship read reader suffe...\n",
      "3  style real review read tell inlet inone happy ...\n",
      "4  mass help like raven small picked woman event ...\n",
      "Primeras filas preprocesadas y separadas para la categoría DVD:\n",
      "                                      processed_text\n",
      "0  decent run long ever even anything miss waiste...\n",
      "1  bedrug child even free good movie child buy cl...\n",
      "2  old complicated move breaking fraction enough ...\n",
      "3  add subtitle already damned time movie hard wa...\n",
      "4  hole clue acting going cant painter movie perf...\n",
      "Primeras filas preprocesadas y separadas para la categoría Electronics:\n",
      "                                      processed_text\n",
      "0  gap well bottom metal even pain fit carpet bas...\n",
      "1  save picture nice advice hold something need l...\n",
      "2  error useless nice even horrible constantly wo...\n",
      "3  two even without one open break knew case inex...\n",
      "4  failure learn disc read first suck rate best b...\n",
      "Primeras filas preprocesadas y separadas para la categoría Kitchen:\n",
      "                                      processed_text\n",
      "0  guess dog well fill keep care bark cairn fairl...\n",
      "1  billed card aware useless single review read e...\n",
      "2  low fine dog time bark spaniel amusing effecti...\n",
      "3  cheaply save time made item loose cool money m...\n",
      "4  initially product interesting like couple even...\n"
     ]
    }
   ],
   "source": [
    "# Crear un conjunto de palabras en inglés\n",
    "english_words = set(words.words())\n",
    "\n",
    "# Inicializar el tokenizador y lematizador\n",
    "treebank_tokenizer = TreebankWordTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Función para dividir palabras concatenadas\n",
    "def separate_concatenated_words(text):\n",
    "    # Tokenizar el texto en palabras individuales\n",
    "    tokens = text.split()\n",
    "    separated_words = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token.lower() in english_words:  # Si la palabra ya es válida, se agrega tal cual\n",
    "            separated_words.append(token.lower())\n",
    "        else:\n",
    "            # Intentar dividir palabras concatenadas utilizando una regla heurística\n",
    "            split_words = re.findall('[a-zA-Z]+', token)  # Dividir en partes al encontrar secuencias de letras\n",
    "            for word in split_words:\n",
    "                if word.lower() in english_words:\n",
    "                    separated_words.append(word.lower())\n",
    "    \n",
    "    # Unir palabras separadas nuevamente en una cadena de texto\n",
    "    return ' '.join(separated_words)\n",
    "\n",
    "# Definir la función `check_lexicon_matches`\n",
    "def check_lexicon_matches(text, afinn_lexicon, sentiwordnet_lexicon, wordstat_lexicon):\n",
    "    matches = {\n",
    "        'afinn_matches': [],\n",
    "        'sentiwordnet_matches': [],\n",
    "        'wordstat_positive_matches': [],\n",
    "        'wordstat_negative_matches': [],\n",
    "        'wordstat_neutral_matches': []\n",
    "    }\n",
    "    \n",
    "    # Tokenizar el texto\n",
    "    words = text.split()\n",
    "    \n",
    "    # Revisar cada palabra en los lexicones\n",
    "    for word in words:\n",
    "        if word in afinn_lexicon:\n",
    "            matches['afinn_matches'].append(word)\n",
    "        \n",
    "        if word in sentiwordnet_lexicon:\n",
    "            matches['sentiwordnet_matches'].append(word)\n",
    "        \n",
    "        if word in wordstat_lexicon['positive']:\n",
    "            matches['wordstat_positive_matches'].append(word)\n",
    "        \n",
    "        if word in wordstat_lexicon['negative']:\n",
    "            matches['wordstat_negative_matches'].append(word)\n",
    "        \n",
    "        if word in wordstat_lexicon['neutral']:\n",
    "            matches['wordstat_neutral_matches'].append(word)\n",
    "    \n",
    "    return matches\n",
    "\n",
    "# Función para procesar el texto con separación de palabras, tokenización y lematización\n",
    "def preprocess_text(text):\n",
    "    # Separar palabras concatenadas\n",
    "    separated_text = separate_concatenated_words(text)\n",
    "    \n",
    "    # Tokenizar el texto usando TreebankWordTokenizer\n",
    "    tokens = treebank_tokenizer.tokenize(separated_text)\n",
    "    \n",
    "    # Lematizar cada token\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Unir tokens lematizados en una cadena de texto\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Aplicar la función de preprocesamiento completa a cada categoría\n",
    "for category in train_dfs:\n",
    "    train_dfs[category]['processed_text'] = train_dfs[category]['processed_text'].apply(preprocess_text)\n",
    "    print(f\"Primeras filas preprocesadas y separadas para la categoría {category}:\")\n",
    "    print(train_dfs[category][['processed_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizando el conjunto de lexicones disponibles para el ejercicio, se observa que el lexicon de \"WordStat\", muestra dificultades de similitud con el corpus del ejercicio, por lo que se procede a realizar una fase adicional sobre este dataset para lograr evidenciar la similitud de este con respecto al texto del corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras palabras en SentiWordNet: [('able#1', 0.125), ('unable#1', -0.75), ('dorsal#2', 0.0), ('ventral#2', 0.0), ('acroscopic#1', 0.0), ('basiscopic#1', 0.0), ('abducting#1', 0.0), ('adductive#1', 0.0), ('nascent#1', 0.0), ('emerging#2', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "# Función para cargar SentiWordNet con validación adicional\n",
    "def load_sentiwordnet_lexicon(file_path):\n",
    "    sentiwordnet_lexicon = {}\n",
    "\n",
    "    # Abrir el archivo y leer línea por línea\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Ignorar líneas de comentarios y vacías\n",
    "            if line.startswith(\"#\") or not line.strip():\n",
    "                continue\n",
    "\n",
    "            # Dividir la línea en componentes (usualmente separadas por tabuladores)\n",
    "            components = line.split('\\t')\n",
    "            if len(components) >= 5:  # Asegurarse de que la línea tenga suficientes elementos\n",
    "                # Extraer la palabra lematizada y sus puntajes positivos y negativos\n",
    "                lemma = components[4].split()[0]  # Palabra lematizada\n",
    "\n",
    "                # Validar que los puntajes positivos y negativos sean valores numéricos\n",
    "                try:\n",
    "                    pos_score = float(components[2]) if components[2] else 0.0  # Puntaje positivo\n",
    "                    neg_score = float(components[3]) if components[3] else 0.0  # Puntaje negativo\n",
    "                except ValueError:\n",
    "                    # Si hay un error en la conversión, continuar con la siguiente línea\n",
    "                    print(f\"Advertencia: Puntaje no numérico en la línea: {line}\")\n",
    "                    continue\n",
    "\n",
    "                # Calcular el puntaje neto (positivos - negativos)\n",
    "                net_score = pos_score - neg_score\n",
    "                \n",
    "                # Almacenar el puntaje neto de la palabra en el diccionario\n",
    "                sentiwordnet_lexicon[lemma] = net_score\n",
    "\n",
    "    return sentiwordnet_lexicon\n",
    "\n",
    "# Cargar el archivo SentiWordNet desde la ruta especificada\n",
    "sentiwordnet_lexicon = load_sentiwordnet_lexicon(sentiwordnet_lexicon_path)\n",
    "\n",
    "# Verificar las primeras palabras cargadas para asegurarnos de que se haya realizado correctamente\n",
    "print(\"Primeras palabras en SentiWordNet:\", list(sentiwordnet_lexicon.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se realiza una normalización del lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras cargadas en AFINN: [('abandon', -2), ('abandoned', -2), ('abandons', -2), ('abducted', -2), ('abduction', -2), ('abductions', -2), ('abhor', -3), ('abhorred', -3), ('abhorrent', -3), ('abhors', -3)]\n",
      "Verificando coincidencias de lexicones normalizados para la categoría: Books\n",
      "Palabras en la reseña: ['avid', 'wasted', 'lit', 'relationship', 'read', 'reader', 'suffering', 'gotten', 'horrible', 'friend', 'back', 'life', 'copy', 'rate', 'man', 'half', 'lower', 'time', 'book', 'possible', 'spent', 'one', 'part', 'entire', 'use', 'fire', 'reading', 'picked', 'purpose', 'old', 'better', 'star', 'got', 'waste', 'year', 'wish', 'boy', 'less', 'headache']\n",
      "Coincidencias en AFINN: ['avid', 'wasted', 'suffering', 'horrible', 'fire', 'better', 'waste', 'wish']\n",
      "Coincidencias en SentiWordNet: []\n",
      "Coincidencias en WordStat Positive: []\n",
      "Coincidencias en WordStat Negative: []\n",
      "Coincidencias en WordStat Neutral: []\n",
      "\n",
      "\n",
      "Verificando coincidencias de lexicones normalizados para la categoría: DVD\n",
      "Palabras en la reseña: ['decent', 'run', 'long', 'ever', 'even', 'anything', 'miss', 'waisted', 'ran', 'wouldnt', 'good', 'movie', 'movie', 'one', 'people', 'love', 'aquarter', 'shame', 'minute', 'actor', 'worst', 'end', 'least', 'entire', 'seen', 'ashame', 'saw', 'enjoy', 'boring', 'quarter', 'might', 'unfortunately', 'around', 'wait', 'bad', 'theater']\n",
      "Coincidencias en AFINN: ['miss', 'good', 'love', 'shame', 'worst', 'ashame', 'enjoy', 'boring', 'bad']\n",
      "Coincidencias en SentiWordNet: []\n",
      "Coincidencias en WordStat Positive: ['good']\n",
      "Coincidencias en WordStat Negative: ['bad']\n",
      "Coincidencias en WordStat Neutral: []\n",
      "\n",
      "\n",
      "Verificando coincidencias de lexicones normalizados para la categoría: Electronics\n",
      "Palabras en la reseña: ['gap', 'well', 'bottom', 'metal', 'even', 'pain', 'fit', 'carpet', 'basically', 'piece', 'one', 'get', 'together', 'want', 'apiece', 'pull', 'rack', 'lot', 'break', 'individual', 'doesnt', 'loose', 'vertical', 'designed', 'whole', 'extremely', 'easy', 'stack', 'hold', 'guess', 'slot', 'bad', 'guide', 'bought']\n",
      "Coincidencias en AFINN: ['pain', 'fit', 'want', 'loose', 'easy', 'bad']\n",
      "Coincidencias en SentiWordNet: []\n",
      "Coincidencias en WordStat Positive: []\n",
      "Coincidencias en WordStat Negative: ['bad']\n",
      "Coincidencias en WordStat Neutral: []\n",
      "\n",
      "\n",
      "Verificando coincidencias de lexicones normalizados para la categoría: Kitchen\n",
      "Palabras en la reseña: ['guess', 'dog', 'well', 'fill', 'keep', 'care', 'bark', 'cairn', 'fairly', 'formy', 'either', 'away', 'sure', 'look', 'spray', 'barker', 'barking', 'theyre', 'work', 'also', 'small', 'yappy', 'persistent', 'terrier', 'right', 'getting', 'stubborn', 'supposed', 'doesnt', 'many', 'working', 'spray']\n",
      "Coincidencias en AFINN: ['care', 'stubborn']\n",
      "Coincidencias en SentiWordNet: []\n",
      "Coincidencias en WordStat Positive: []\n",
      "Coincidencias en WordStat Negative: []\n",
      "Coincidencias en WordStat Neutral: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definición de la función para normalizar\n",
    "def normalize_wordstat_lexicon(wordstat_lexicon):\n",
    "    normalized_lexicon = {category: set() for category in wordstat_lexicon}\n",
    "    for category in wordstat_lexicon:\n",
    "        for word in wordstat_lexicon[category]:\n",
    "            normalized_word = word.replace('@', '').replace('_', ' ')\n",
    "            normalized_lexicon[category].add(normalized_word)\n",
    "    return normalized_lexicon\n",
    "\n",
    "# Crear y normalizar el lexicón\n",
    "wordstat_lexicon = {\n",
    "    'positive': {'good', 'great', 'excellent'},\n",
    "    'negative': {'bad', 'worse', 'terrible'},\n",
    "    'neutral': {'average', 'ok', 'fine'}\n",
    "}\n",
    "wordstat_normalized_lexicon = normalize_wordstat_lexicon(wordstat_lexicon)\n",
    "\n",
    "# Función para normalizar las palabras en WordStat (remover '@' y '_')\n",
    "def normalize_wordstat_lexicon(wordstat_lexicon):\n",
    "    # Inicializar el diccionario con todas las categorías presentes en wordstat_lexicon\n",
    "    normalized_lexicon = {category: set() for category in wordstat_lexicon}\n",
    "\n",
    "    for category in wordstat_lexicon:\n",
    "        for word in wordstat_lexicon[category]:\n",
    "            # Normalizar la palabra removiendo '@' y '_'\n",
    "            normalized_word = word.replace('@', '').replace('_', ' ')\n",
    "            normalized_lexicon[category].add(normalized_word)\n",
    "    return normalized_lexicon\n",
    "\n",
    "# Definir AFINN Lexicon\n",
    "afinn_lexicon = {}\n",
    "\n",
    "# Cargar AFINN lexicon desde un archivo (asegúrate de tener la ruta correcta)\n",
    "with open(\"C:/Users/DELL/Documents/GitHub/NLP_TaskOne/task3/EN_Lexicons/AFINN-111.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        if line.strip():  # Verificar que no sea una línea vacía\n",
    "            word, score = line.split(\"\\t\")\n",
    "            afinn_lexicon[word] = int(score)\n",
    "\n",
    "# Verificar que `afinn_lexicon` se haya cargado correctamente\n",
    "print(\"Palabras cargadas en AFINN:\", list(afinn_lexicon.items())[:10])\n",
    "\n",
    "# Ahora, con `afinn_lexicon` definido, ejecutar la verificación nuevamente\n",
    "for category in train_dfs:\n",
    "    print(f\"Verificando coincidencias de lexicones normalizados para la categoría: {category}\")\n",
    "    sample_text = train_dfs[category]['processed_text'].iloc[0]  # Tomar la primera reseña de cada categoría\n",
    "    matches = check_lexicon_matches(sample_text, afinn_lexicon, sentiwordnet_lexicon, wordstat_normalized_lexicon)\n",
    "    print(\"Palabras en la reseña:\", sample_text.split())\n",
    "    print(\"Coincidencias en AFINN:\", matches['afinn_matches'])\n",
    "    print(\"Coincidencias en SentiWordNet:\", matches['sentiwordnet_matches'])\n",
    "    print(\"Coincidencias en WordStat Positive:\", matches['wordstat_positive_matches'])\n",
    "    print(\"Coincidencias en WordStat Negative:\", matches['wordstat_negative_matches'])\n",
    "    print(\"Coincidencias en WordStat Neutral:\", matches['wordstat_neutral_matches'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las coincidencias con WordStat son limitadas, mientras que AFINN ofrece una mejor identificación de palabras relevantes. Se debe revisar si las palabras coincidentes en AFINN deberían pertenecer también a WordStat\n",
    "\n",
    "Al evidenciar que el lexicon \"WordsStat\", son limitadas las coincidencias con el corpus del texto, se toma la decisión de no considerarlo para el entrenamiento del modelo. Igualmente, algunas de las características del lexicon \"SentiWordNet_3.0.0\", evidencia valores negativos, los cuales son perjudiciales en calculos futuros del entrenamiento del modelo. La mayoría de las coincidencias corresponden a palabras identificadas por el lexicón \"AFINN\". Es necesario expandir el SentiWordNet y WordStat lexicon para obtener mejores coincidencias. Estas consideraciones se han de tener en cuenta para el entrenamiento de los modelos de Naive Bayes y Regresión logística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se realiza se implementa una función para extraer características basadas en lexicones (AFINN y SentiWordNet) para cada reseña en el conjunto de datos de cada categoría (Books, DVD, Electronics, Kitchen). Este proceso es importante para transformar el corpus en representacion numérica, el cual será utilizado para los modelos de clasificación de entrenamiento de Naive Bayes o Regresión Logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrayendo características basadas en lexicones para la categoría: Books\n",
      "Extrayendo características basadas en lexicones para la categoría: DVD\n",
      "Extrayendo características basadas en lexicones para la categoría: Electronics\n",
      "Extrayendo características basadas en lexicones para la categoría: Kitchen\n",
      "Características basadas en lexicones para la categoría: Books\n",
      "                                      processed_text  \\\n",
      "0  avid wasted lit relationship read reader suffe...   \n",
      "1  touse shallow found review usually smug offer ...   \n",
      "2  avid wasted lit relationship read reader suffe...   \n",
      "3  style real review read tell inlet inone happy ...   \n",
      "4  mass help like raven small picked woman event ...   \n",
      "\n",
      "                                    lexicon_features  \n",
      "0  {'afinn_positive_count': 3, 'afinn_negative_co...  \n",
      "1  {'afinn_positive_count': 2, 'afinn_negative_co...  \n",
      "2  {'afinn_positive_count': 3, 'afinn_negative_co...  \n",
      "3  {'afinn_positive_count': 2, 'afinn_negative_co...  \n",
      "4  {'afinn_positive_count': 23, 'afinn_negative_c...  \n",
      "Características basadas en lexicones para la categoría: DVD\n",
      "                                      processed_text  \\\n",
      "0  decent run long ever even anything miss waiste...   \n",
      "1  bedrug child even free good movie child buy cl...   \n",
      "2  old complicated move breaking fraction enough ...   \n",
      "3  add subtitle already damned time movie hard wa...   \n",
      "4  hole clue acting going cant painter movie perf...   \n",
      "\n",
      "                                    lexicon_features  \n",
      "0  {'afinn_positive_count': 3, 'afinn_negative_co...  \n",
      "1  {'afinn_positive_count': 3, 'afinn_negative_co...  \n",
      "2  {'afinn_positive_count': 2, 'afinn_negative_co...  \n",
      "3  {'afinn_positive_count': 5, 'afinn_negative_co...  \n",
      "4  {'afinn_positive_count': 7, 'afinn_negative_co...  \n",
      "Características basadas en lexicones para la categoría: Electronics\n",
      "                                      processed_text  \\\n",
      "0  gap well bottom metal even pain fit carpet bas...   \n",
      "1  save picture nice advice hold something need l...   \n",
      "2  error useless nice even horrible constantly wo...   \n",
      "3  two even without one open break knew case inex...   \n",
      "4  failure learn disc read first suck rate best b...   \n",
      "\n",
      "                                    lexicon_features  \n",
      "0  {'afinn_positive_count': 3, 'afinn_negative_co...  \n",
      "1  {'afinn_positive_count': 2, 'afinn_negative_co...  \n",
      "2  {'afinn_positive_count': 1, 'afinn_negative_co...  \n",
      "3  {'afinn_positive_count': 0, 'afinn_negative_co...  \n",
      "4  {'afinn_positive_count': 2, 'afinn_negative_co...  \n",
      "Características basadas en lexicones para la categoría: Kitchen\n",
      "                                      processed_text  \\\n",
      "0  guess dog well fill keep care bark cairn fairl...   \n",
      "1  billed card aware useless single review read e...   \n",
      "2  low fine dog time bark spaniel amusing effecti...   \n",
      "3  cheaply save time made item loose cool money m...   \n",
      "4  initially product interesting like couple even...   \n",
      "\n",
      "                                    lexicon_features  \n",
      "0  {'afinn_positive_count': 1, 'afinn_negative_co...  \n",
      "1  {'afinn_positive_count': 1, 'afinn_negative_co...  \n",
      "2  {'afinn_positive_count': 1, 'afinn_negative_co...  \n",
      "3  {'afinn_positive_count': 2, 'afinn_negative_co...  \n",
      "4  {'afinn_positive_count': 3, 'afinn_negative_co...  \n"
     ]
    }
   ],
   "source": [
    "# Definir la función para extraer características basadas en lexicones\n",
    "def extract_lexicon_features(text, afinn_lexicon, sentiwordnet_lexicon):\n",
    "    # Inicializar contadores y puntajes\n",
    "    afinn_positive_count = 0\n",
    "    afinn_negative_count = 0\n",
    "    sentiwordnet_score = 0\n",
    "    \n",
    "    # Tokenizar el texto\n",
    "    words = text.split()\n",
    "    \n",
    "    # Recorrer cada palabra y verificar en los lexicones\n",
    "    for word in words:\n",
    "        # Revisar en el lexicón AFINN\n",
    "        if word in afinn_lexicon:\n",
    "            if afinn_lexicon[word] > 0:\n",
    "                afinn_positive_count += 1\n",
    "            elif afinn_lexicon[word] < 0:\n",
    "                afinn_negative_count += 1\n",
    "        \n",
    "        # Revisar en el lexicón SentiWordNet\n",
    "        if word in sentiwordnet_lexicon:\n",
    "            sentiwordnet_score += sentiwordnet_lexicon[word]\n",
    "    \n",
    "    # Retornar las características como un diccionario\n",
    "    return {\n",
    "        'afinn_positive_count': afinn_positive_count,\n",
    "        'afinn_negative_count': afinn_negative_count,\n",
    "        'sentiwordnet_score': sentiwordnet_score\n",
    "    }\n",
    "\n",
    "# Aplicar la extracción de características para cada categoría en el conjunto de entrenamiento\n",
    "for category in train_dfs:\n",
    "    print(f\"Extrayendo características basadas en lexicones para la categoría: {category}\")\n",
    "    train_dfs[category]['lexicon_features'] = train_dfs[category]['processed_text'].apply(\n",
    "        lambda x: extract_lexicon_features(x, afinn_lexicon, sentiwordnet_lexicon)\n",
    "    )\n",
    "\n",
    "# Verificar las primeras filas con las nuevas características\n",
    "for category in train_dfs:\n",
    "    print(f\"Características basadas en lexicones para la categoría: {category}\")\n",
    "    print(train_dfs[category][['processed_text', 'lexicon_features']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, se procede a separar las características en columnas individuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas de características expandidas para la categoría Books:\n",
      "                                                text     label  \\\n",
      "0  avid:1 your:1 horrible_book:1 wasted:1 use_it:...  negative   \n",
      "1  to_use:1 shallow:1 found:1 he_castigates:1 cas...  negative   \n",
      "2  avid:1 your:1 horrible_book:1 wasted:1 use_it:...  negative   \n",
      "3  book_seriously:1 we:1 days_couldn't:1 me_tell:...  negative   \n",
      "4  mass:1 only:1 he:2 help:1 \"jurisfiction\":1 lik...  negative   \n",
      "\n",
      "                                      processed_text  afinn_positive_count  \\\n",
      "0  avid wasted lit relationship read reader suffe...                     3   \n",
      "1  touse shallow found review usually smug offer ...                     2   \n",
      "2  avid wasted lit relationship read reader suffe...                     3   \n",
      "3  style real review read tell inlet inone happy ...                     2   \n",
      "4  mass help like raven small picked woman event ...                    23   \n",
      "\n",
      "   afinn_negative_count  sentiwordnet_score  \n",
      "0                     5                   0  \n",
      "1                     1                   0  \n",
      "2                     5                   0  \n",
      "3                     3                   0  \n",
      "4                    18                   0  \n",
      "Primeras filas de características expandidas para la categoría DVD:\n",
      "                                                text     label  \\\n",
      "0  i:4 movie_could:1 movies_i:1 in_only:1 minutes...  negative   \n",
      "1  your:2 by_disney:1 many_drug:1 can't_even:1 cl...  negative   \n",
      "2  old:1 complicated:1 fun_to:2 moves:2 breaking:...  negative   \n",
      "3  enjoy_what:1 find_that:1 add_some:1 and_when:1...  negative   \n",
      "4  holes:1 movie_however:2 shooting_fish:1 not_su...  negative   \n",
      "\n",
      "                                      processed_text  afinn_positive_count  \\\n",
      "0  decent run long ever even anything miss waiste...                     3   \n",
      "1  bedrug child even free good movie child buy cl...                     3   \n",
      "2  old complicated move breaking fraction enough ...                     2   \n",
      "3  add subtitle already damned time movie hard wa...                     5   \n",
      "4  hole clue acting going cant painter movie perf...                     7   \n",
      "\n",
      "   afinn_negative_count  sentiwordnet_score  \n",
      "0                     6                   0  \n",
      "1                     1                   0  \n",
      "2                     0                   0  \n",
      "3                     5                   0  \n",
      "4                     5                   0  \n",
      "Primeras filas de características expandidas para la categoría Electronics:\n",
      "                                                text     label  \\\n",
      "0  gaps:1 well:1 it_together:1 a_stack:1 the_cd:1...  negative   \n",
      "1  save_your:2 steady_on:1 save:2 picture:1 your_...  negative   \n",
      "2  i:2 slightest_smudge:1 nice_for:1 errors:1 pla...  negative   \n",
      "3  but_i:1 two:1 i:2 even:1 without:1 one:1 inexp...  negative   \n",
      "4  failure:1 people_should:1 my_software:1 and_sa...  negative   \n",
      "\n",
      "                                      processed_text  afinn_positive_count  \\\n",
      "0  gap well bottom metal even pain fit carpet bas...                     3   \n",
      "1  save picture nice advice hold something need l...                     2   \n",
      "2  error useless nice even horrible constantly wo...                     1   \n",
      "3  two even without one open break knew case inex...                     0   \n",
      "4  failure learn disc read first suck rate best b...                     2   \n",
      "\n",
      "   afinn_negative_count  sentiwordnet_score  \n",
      "0                     3                   0  \n",
      "1                     0                   0  \n",
      "2                     4                   0  \n",
      "3                     0                   0  \n",
      "4                     3                   0  \n",
      "Primeras filas de características expandidas para la categoría Kitchen:\n",
      "                                                text     label  \\\n",
      "0  right_after:1 guess:1 dog:1 well:2 fill:1 to_w...  negative   \n",
      "1  manufacturer_suggested:1 your:2 manufacturer_o...  negative   \n",
      "2  time_it:1 i_can:1 my_cocker:1 maybe_it:1 low:1...  negative   \n",
      "3  save_your:1 cheaply:1 i_sent:1 save:1 loose_th...  negative   \n",
      "4  acted:1 sound_interesting:1 they_are:1 bark_al...  negative   \n",
      "\n",
      "                                      processed_text  afinn_positive_count  \\\n",
      "0  guess dog well fill keep care bark cairn fairl...                     1   \n",
      "1  billed card aware useless single review read e...                     1   \n",
      "2  low fine dog time bark spaniel amusing effecti...                     1   \n",
      "3  cheaply save time made item loose cool money m...                     2   \n",
      "4  initially product interesting like couple even...                     3   \n",
      "\n",
      "   afinn_negative_count  sentiwordnet_score  \n",
      "0                     1                   0  \n",
      "1                     5                   0  \n",
      "2                     0                   0  \n",
      "3                     2                   0  \n",
      "4                     0                   0  \n"
     ]
    }
   ],
   "source": [
    "# Separar características de 'lexicon_features' en columnas individuales\n",
    "for category in train_dfs:\n",
    "    # Expandir el diccionario de 'lexicon_features' en columnas separadas\n",
    "    lexicon_df = pd.json_normalize(train_dfs[category]['lexicon_features'])\n",
    "    \n",
    "    # Concatenar las columnas separadas de características con el DataFrame original\n",
    "    train_dfs[category] = pd.concat([train_dfs[category], lexicon_df], axis=1)\n",
    "    \n",
    "    # Eliminar la columna 'lexicon_features' que ya no es necesaria\n",
    "    train_dfs[category].drop(columns=['lexicon_features'], inplace=True)\n",
    "    \n",
    "    print(f\"Primeras filas de características expandidas para la categoría {category}:\")\n",
    "    print(train_dfs[category].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de características, basadas en lexicones\n",
    "\n",
    "Con los lexicones cargados, se procede a generar características, las cuales incluyen, conteo de palabras positivas y conteo de palabras negativas para cada reseña usando los lexicones WordStat, puntuación neta de sentimiento basada en los puntajes de AFINN y SentiWordNet, características adicionales basadas en la combinación de los tres lexicones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características basadas en lexicones para la categoría: Books\n",
      "                                      processed_text  \\\n",
      "0  avid wasted lit relationship read reader suffe...   \n",
      "1  touse shallow found review usually smug offer ...   \n",
      "2  avid wasted lit relationship read reader suffe...   \n",
      "3  style real review read tell inlet inone happy ...   \n",
      "4  mass help like raven small picked woman event ...   \n",
      "\n",
      "                                    lexicon_features  \n",
      "0  {'positive_count': 0, 'negative_count': 0, 'ne...  \n",
      "1  {'positive_count': 0, 'negative_count': 0, 'ne...  \n",
      "2  {'positive_count': 0, 'negative_count': 0, 'ne...  \n",
      "3  {'positive_count': 0, 'negative_count': 1, 'ne...  \n",
      "4  {'positive_count': 1, 'negative_count': 0, 'ne...  \n",
      "Características basadas en lexicones para la categoría: DVD\n",
      "                                      processed_text  \\\n",
      "0  decent run long ever even anything miss waiste...   \n",
      "1  bedrug child even free good movie child buy cl...   \n",
      "2  old complicated move breaking fraction enough ...   \n",
      "3  add subtitle already damned time movie hard wa...   \n",
      "4  hole clue acting going cant painter movie perf...   \n",
      "\n",
      "                                    lexicon_features  \n",
      "0  {'positive_count': 1, 'negative_count': 1, 'ne...  \n",
      "1  {'positive_count': 1, 'negative_count': 0, 'ne...  \n",
      "2  {'positive_count': 0, 'negative_count': 0, 'ne...  \n",
      "3  {'positive_count': 0, 'negative_count': 0, 'ne...  \n",
      "4  {'positive_count': 1, 'negative_count': 0, 'ne...  \n",
      "Características basadas en lexicones para la categoría: Electronics\n",
      "                                      processed_text  \\\n",
      "0  gap well bottom metal even pain fit carpet bas...   \n",
      "1  save picture nice advice hold something need l...   \n",
      "2  error useless nice even horrible constantly wo...   \n",
      "3  two even without one open break knew case inex...   \n",
      "4  failure learn disc read first suck rate best b...   \n",
      "\n",
      "                                    lexicon_features  \n",
      "0  {'positive_count': 0, 'negative_count': 1, 'ne...  \n",
      "1  {'positive_count': 0, 'negative_count': 0, 'ne...  \n",
      "2  {'positive_count': 0, 'negative_count': 1, 'ne...  \n",
      "3  {'positive_count': 0, 'negative_count': 0, 'ne...  \n",
      "4  {'positive_count': 0, 'negative_count': 0, 'ne...  \n",
      "Características basadas en lexicones para la categoría: Kitchen\n",
      "                                      processed_text  \\\n",
      "0  guess dog well fill keep care bark cairn fairl...   \n",
      "1  billed card aware useless single review read e...   \n",
      "2  low fine dog time bark spaniel amusing effecti...   \n",
      "3  cheaply save time made item loose cool money m...   \n",
      "4  initially product interesting like couple even...   \n",
      "\n",
      "                                    lexicon_features  \n",
      "0  {'positive_count': 0, 'negative_count': 0, 'ne...  \n",
      "1  {'positive_count': 0, 'negative_count': 0, 'ne...  \n",
      "2  {'positive_count': 0, 'negative_count': 0, 'ne...  \n",
      "3  {'positive_count': 0, 'negative_count': 0, 'ne...  \n",
      "4  {'positive_count': 0, 'negative_count': 0, 'ne...  \n"
     ]
    }
   ],
   "source": [
    "# Función para calcular características basadas en lexicones\n",
    "def extract_lexicon_features(text, afinn_lexicon, sentiwordnet_lexicon, wordstat_lexicon):\n",
    "    # Tokenizar el texto en palabras individuales (asumiendo que ya está preprocesado y tokenizado correctamente)\n",
    "    words = text.split()\n",
    "    \n",
    "    # Inicializar contadores de características\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    neutral_count = 0\n",
    "    afinn_score = 0\n",
    "    sentiwordnet_score = 0\n",
    "    \n",
    "    # Recorrer cada palabra en el texto\n",
    "    for word in words:\n",
    "        # Contar palabras positivas, negativas y neutrales basadas en WordStat\n",
    "        if word in wordstat_lexicon['positive']:\n",
    "            positive_count += 1\n",
    "        elif word in wordstat_lexicon['negative']:\n",
    "            negative_count += 1\n",
    "        elif word in wordstat_lexicon['neutral']:\n",
    "            neutral_count += 1\n",
    "            \n",
    "        # Calcular el puntaje basado en AFINN\n",
    "        if word in afinn_lexicon:\n",
    "            afinn_score += afinn_lexicon[word]\n",
    "        \n",
    "        # Calcular el puntaje basado en SentiWordNet\n",
    "        if word in sentiwordnet_lexicon:\n",
    "            sentiwordnet_score += sentiwordnet_lexicon[word]\n",
    "    \n",
    "    # Crear un diccionario con las características\n",
    "    features = {\n",
    "        'positive_count': positive_count,\n",
    "        'negative_count': negative_count,\n",
    "        'neutral_count': neutral_count,\n",
    "        'afinn_score': afinn_score,\n",
    "        'sentiwordnet_score': sentiwordnet_score\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Aplicar la extracción de características basadas en lexicones a cada reseña en el conjunto de entrenamiento\n",
    "for category in train_dfs:\n",
    "    train_dfs[category]['lexicon_features'] = train_dfs[category]['processed_text'].apply(\n",
    "        lambda text: extract_lexicon_features(text, afinn_lexicon, sentiwordnet_lexicon, wordstat_lexicon)\n",
    "    )\n",
    "    \n",
    "    # Mostrar una muestra de las características extraídas\n",
    "    print(f\"Características basadas en lexicones para la categoría: {category}\")\n",
    "    print(train_dfs[category][['processed_text', 'lexicon_features']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo usando características de los lexicones\n",
    "\n",
    "Ya con las caracterísitcas separadas de los lexicones, se procede a entrenar el modelo con Naive Bayes y Regresión logísitca, se conidera que para datos negativos de los lexicones, se normalizan los datos con el fin de no afectar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizando y entrenando modelos para la categoría: Books\n",
      "Columnas disponibles en el DataFrame de la categoría Books: ['text', 'label', 'processed_text', 'afinn_positive_count', 'afinn_negative_count', 'sentiwordnet_score', 'lexicon_features']\n",
      "Resultados Naive Bayes para Books:\n",
      "{'precision': np.float64(0.6582914572864321), 'recall': np.float64(0.6517412935323383), 'f1_score': np.float64(0.655), 'accuracy': 0.655}\n",
      "Resultados Regresión Logística para Books:\n",
      "{'precision': np.float64(0.6565656565656566), 'recall': np.float64(0.6467661691542289), 'f1_score': np.float64(0.6516290726817042), 'accuracy': 0.6525}\n",
      "\n",
      "Normalizando y entrenando modelos para la categoría: DVD\n",
      "Columnas disponibles en el DataFrame de la categoría DVD: ['text', 'label', 'processed_text', 'afinn_positive_count', 'afinn_negative_count', 'sentiwordnet_score', 'lexicon_features']\n",
      "Resultados Naive Bayes para DVD:\n",
      "{'precision': np.float64(0.7142857142857143), 'recall': np.float64(0.6965174129353234), 'f1_score': np.float64(0.7052896725440806), 'accuracy': 0.7075}\n",
      "Resultados Regresión Logística para DVD:\n",
      "{'precision': np.float64(0.7208121827411168), 'recall': np.float64(0.7064676616915423), 'f1_score': np.float64(0.7135678391959799), 'accuracy': 0.715}\n",
      "\n",
      "Normalizando y entrenando modelos para la categoría: Electronics\n",
      "Columnas disponibles en el DataFrame de la categoría Electronics: ['text', 'label', 'processed_text', 'afinn_positive_count', 'afinn_negative_count', 'sentiwordnet_score', 'lexicon_features']\n",
      "Resultados Naive Bayes para Electronics:\n",
      "{'precision': np.float64(0.6991150442477876), 'recall': np.float64(0.7860696517412935), 'f1_score': np.float64(0.7400468384074942), 'accuracy': 0.7225}\n",
      "Resultados Regresión Logística para Electronics:\n",
      "{'precision': np.float64(0.7033492822966507), 'recall': np.float64(0.7313432835820896), 'f1_score': np.float64(0.7170731707317073), 'accuracy': 0.71}\n",
      "\n",
      "Normalizando y entrenando modelos para la categoría: Kitchen\n",
      "Columnas disponibles en el DataFrame de la categoría Kitchen: ['text', 'label', 'processed_text', 'afinn_positive_count', 'afinn_negative_count', 'sentiwordnet_score', 'lexicon_features']\n",
      "Resultados Naive Bayes para Kitchen:\n",
      "{'precision': np.float64(0.7289719626168224), 'recall': np.float64(0.7761194029850746), 'f1_score': np.float64(0.7518072289156627), 'accuracy': 0.7425}\n",
      "Resultados Regresión Logística para Kitchen:\n",
      "{'precision': np.float64(0.7313432835820896), 'recall': np.float64(0.7313432835820896), 'f1_score': np.float64(0.7313432835820896), 'accuracy': 0.73}\n"
     ]
    }
   ],
   "source": [
    "# Normalizar características para cada categoría\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Diccionarios para almacenar los resultados de cada modelo\n",
    "results_nb_lexicon = {}\n",
    "results_lr_lexicon = {}\n",
    "\n",
    "# Entrenamiento y evaluación para cada categoría usando las características de lexicones\n",
    "for category in train_dfs:\n",
    "    print(f\"\\nNormalizando y entrenando modelos para la categoría: {category}\")\n",
    "    \n",
    "    # Verificar columnas existentes en el DataFrame\n",
    "    print(f\"Columnas disponibles en el DataFrame de la categoría {category}: {list(train_dfs[category].columns)}\")\n",
    "    \n",
    "    # Definir las características y etiquetas\n",
    "    X = train_dfs[category][['afinn_positive_count', 'afinn_negative_count', 'sentiwordnet_score']]\n",
    "    y = train_dfs[category]['label']\n",
    "    \n",
    "    # Normalizar las características para que no haya valores negativos\n",
    "    X_normalized = scaler.fit_transform(X)\n",
    "    \n",
    "    # Dividir el conjunto en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Modelo Naive Bayes (MultinomialNB)\n",
    "    nb_model = MultinomialNB()\n",
    "    nb_model.fit(X_train, y_train)\n",
    "    y_pred_nb = nb_model.predict(X_test)\n",
    "    \n",
    "    # Evaluación Naive Bayes\n",
    "    precision_nb = precision_score(y_test, y_pred_nb, pos_label='positive', average='binary')\n",
    "    recall_nb = recall_score(y_test, y_pred_nb, pos_label='positive', average='binary')\n",
    "    f1_nb = f1_score(y_test, y_pred_nb, pos_label='positive', average='binary')\n",
    "    accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "    \n",
    "    # Almacenar resultados de Naive Bayes\n",
    "    results_nb_lexicon[category] = {\n",
    "        'precision': precision_nb,\n",
    "        'recall': recall_nb,\n",
    "        'f1_score': f1_nb,\n",
    "        'accuracy': accuracy_nb\n",
    "    }\n",
    "    \n",
    "    # Modelo Regresión Logística (puede trabajar con características normalizadas)\n",
    "    lr_model = LogisticRegression(max_iter=1000)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    y_pred_lr = lr_model.predict(X_test)\n",
    "    \n",
    "    # Evaluación Regresión Logística\n",
    "    precision_lr = precision_score(y_test, y_pred_lr, pos_label='positive', average='binary')\n",
    "    recall_lr = recall_score(y_test, y_pred_lr, pos_label='positive', average='binary')\n",
    "    f1_lr = f1_score(y_test, y_pred_lr, pos_label='positive', average='binary')\n",
    "    accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "    \n",
    "    # Almacenar resultados de Regresión Logística\n",
    "    results_lr_lexicon[category] = {\n",
    "        'precision': precision_lr,\n",
    "        'recall': recall_lr,\n",
    "        'f1_score': f1_lr,\n",
    "        'accuracy': accuracy_lr\n",
    "    }\n",
    "    \n",
    "    # Imprimir resultados para la categoría\n",
    "    print(f\"Resultados Naive Bayes para {category}:\")\n",
    "    print(results_nb_lexicon[category])\n",
    "    \n",
    "    print(f\"Resultados Regresión Logística para {category}:\")\n",
    "    print(results_lr_lexicon[category])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como análisis de resultados, se tiene que:\n",
    "\n",
    "### Resultados de Modelos Basados en Lexicones\n",
    "\n",
    "| Categoría    | Modelo               | Precisión | Recall | F1-Score | Acurracy |\n",
    "|--------------|----------------------|-----------|--------|----------|-----------|\n",
    "| **Books**    | Naive Bayes           | 0.6197    | 0.7214 | 0.6667   | 0.6375    |\n",
    "| **Books**    | Regresión Logística   | 0.6468    | 0.6468 | 0.6468   | 0.645     |\n",
    "| **DVD**      | Naive Bayes           | 0.6798    | 0.6866 | 0.6832   | 0.68      |\n",
    "| **DVD**      | Regresión Logística   | 0.7072    | 0.6368 | 0.6702   | 0.685     |\n",
    "| **Electronics** | Naive Bayes        | 0.6795    | 0.7910 | 0.7310   | 0.7075    |\n",
    "| **Electronics** | Regresión Logística | 0.6889    | 0.7711 | 0.7277   | 0.71      |\n",
    "| **Kitchen**  | Naive Bayes           | 0.6923    | 0.8060 | 0.7448   | 0.7225    |\n",
    "| **Kitchen**  | Regresión Logística   | 0.7340    | 0.7413 | 0.7376   | 0.735     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis de estos, permite determinar que:\n",
    "\n",
    "##### Books: \n",
    "Es la categoría más desafiante, con menor F1-score (0.667 para NB y 0.647 para LR). La mayor dificultad puede estar relacionada con la gran variabilidad de términos y la subjetividad de las reseñas.\n",
    "##### DVD: \n",
    "Muestra un rendimiento moderado, con Naive Bayes superando a Regresión Logística en F1-score. Naive Bayes presenta un mejor recall, capturando más ejemplos de la clase positiva.\n",
    "##### Electronics:\n",
    "Ambos modelos obtuvieron buenos resultados, con un F1-score de aproximadamente 0.73. La categoría parece estar mejor definida, facilitando la predicción de sentimientos.\n",
    "##### Kitchen:\n",
    "Tiene el mejor rendimiento, con un F1-score cercano a 0.75 en Naive Bayes y 0.74 en Regresión Logística. Esto sugiere que las reseñas en esta categoría pueden ser más fáciles de clasificar debido a una menor ambigüedad en el lenguaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En conclusión,\n",
    "\n",
    "Se puede decir que para la Comparación de Modelos, Naive Bayes tiende a obtener mejor recall, mientras que Regresión Logística logra un balance más uniforme entre precisión y recall. Dependiendo del problema (priorizar falsos positivos o negativos), uno u otro modelo puede ser más adecuado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación final de los Modelos\n",
    "\n",
    "Ahora se procede a evaluar el rendimiento de cada modelo en el conjunto de prueba (test_dfs) y reportar los resultados usando las métricas Precision, Recall, F1 Score, Accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB vs LR (Naive Bayes vs Logistic Regression)\n",
    "\n",
    "Al comparar Naive Bayes (NB) con Regresión Logística (LR), observamos que:\n",
    "\n",
    "_Naive Bayes_ tiende a funcionar bien con datos que tienen independencia condicional entre las características. Este modelo asume que todas las palabras son independientes entre sí dentro de una reseña, lo cual no siempre es cierto en lenguaje natural.\n",
    "\n",
    "_Regresión Logística_ generalmente tiene mejor capacidad de modelado de relaciones complejas entre palabras, lo que le permite capturar interacciones entre las características de forma más precisa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisión: LR mostró una mayor precisión en general para todas las categorías en comparación con NB. El mayor aumento en precisión se observó en la categoría Kitchen, donde LR alcanzó 0.7340 frente a 0.6923 de NB.\n",
    "\n",
    "Recall: NB tiene un mejor recall en algunas categorías como Electronics y Kitchen, lo que indica que identifica más instancias positivas correctamente, aunque a costa de una mayor tasa de falsos positivos.\n",
    "\n",
    "F1-Score: En promedio, LR tiene F1-Scores más balanceados, lo que refleja un equilibrio entre precisión y recall.\n",
    "\n",
    "Accuracy: LR muestra un rendimiento ligeramente superior en términos de exactitud en todas las categorías, especialmente en Books y DVD.\n",
    "\n",
    "En los modelos basados en lexicones, la representación de características afecta de manera significativa los resultados. NB mostró variaciones notables con lexicones, especialmente debido a la forma en que evalúa la independencia de características. LR se beneficia de la representación detallada de lexicones, capturando relaciones no lineales entre palabras.\n",
    "\n",
    "Según las métricas, Books es la categoría con menor exactitud y F1-Score en ambos modelos. Esto sugiere que los textos en esta categoría pueden tener una estructura más compleja o ambigüedad en cuanto a sentimientos. Kitchen es la categoría más fácil de predecir, ya que tanto NB como LR tienen los F1-Scores y exactitudes más altas en esta categoría.\n",
    "\n",
    "Por tanto,\n",
    "\n",
    "Logistic Regression es más robusto en general cuando se usa con representaciones detalladas de características como lexicones.\n",
    "\n",
    "Naive Bayes tiende a ser más útil en situaciones donde las relaciones entre palabras son menos complejas, pero se ve superado por LR en este contexto de análisis de sentimientos.\n",
    "\n",
    "Al basarse en lexicones, LR muestra un mejor rendimiento al manejar relaciones más detalladas entre palabras y sentimientos, reflejando una comprensión más profunda del contexto en cada categoría."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representación de características\n",
    "\n",
    "_TF_ = En términos de métricas como precisión y exactitud, el modelo basado en TF muestra resultados sólidos en las categorías con vocabulario consistente (DVD, Electronics). TF tiende a captar mejor palabras comunes en cada categoría, pero puede ser sensible a documentos largos, donde las palabras frecuentes dominan sobre las características importantes.\n",
    "\n",
    "_TFIDF_ = La representación TFIDF mejora la clasificación en términos de precisión y F1-Score al capturar términos distintivos para cada clase. Los modelos con TFIDF tienden a ser más precisos en textos largos y complejos, especialmente en categorías como Books, donde el contexto es crucial.\n",
    "\n",
    "_Lexicones_ = Los modelos basados en lexicones muestran un comportamiento intermedio, capturando características de sentimiento de manera directa.\n",
    "Funcionan bien en textos con lenguaje sencillo y directo, pero tienen limitaciones en categorías con matices más complejos (e.g., Books). Los lexicones pueden carecer de cobertura completa para términos específicos del dominio, lo cual se observa en categorías como Electronics.\n",
    "\n",
    "Entonces,\n",
    "\n",
    "TFIDF supera a TF en la mayoría de las categorías, ya que resuelve el problema de palabras frecuentes irrelevantes en cada documento, ofreciendo un mejor balance entre precisión y recall.\n",
    "\n",
    "TF y TFIDF permiten una representación más flexible y adaptable a características específicas del texto, mientras que los lexicones proporcionan una evaluación directa de sentimientos, pero dependen de la calidad y cobertura del lexicón, para este ejercicio, TFIDF se mostró como la representación más efectiva, especialmente para Regresión Logística, debido a su capacidad para capturar características distintivas del lenguaje en categorías con estructura compleja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis por categorías\n",
    "\n",
    "Para cada una de las características, podemos decir que:\n",
    "\n",
    "_Books =_ Presenta una dificultad notable para los modelos tanto en Naive Bayes como en Regresión Logística, con métricas de F1-Score relativamente bajas en comparación con otras categorías. Los textos en esta categoría suelen tener un lenguaje más complejo, con uso de figuras retóricas y mayor subjetividad, lo cual dificulta la detección de sentimientos mediante métodos basados en palabras individuales. Los modelos basados en TFIDF lograron captar mejor las características distintivas del lenguaje en esta categoría, mientras que los lexicones presentaron un rendimiento inferior debido a la complejidad y variabilidad del vocabulario utilizado.\n",
    "\n",
    "_DVD =_ Los modelos basados en TF y TFIDF alcanzaron un desempeño consistente, pero las métricas de recall en Regresión Logística muestran cierta dificultad para captar todos los aspectos del sentimiento. Lacategoría DVD incluye reseñas que a menudo mezclan críticas técnicas con opiniones personales, haciendo que los modelos de sentimientos puros no siempre identifiquen correctamente los contextos en los que las palabras se usan.\n",
    "\n",
    "_Electronics =_ Esta categoría mostró el mejor rendimiento general en todos los modelos, especialmente en términos de recall y accuracy. La terminología en esta categoría es más directa y descriptiva, facilitando la identificación de sentimientos positivos o negativos asociados a características técnicas y funcionalidades de productos.\n",
    "\n",
    "_Kitchen =_ En esta categoria, vemos una similitud con la categoria Electronics, los modelos logran captar de manera efectiva los sentimientos, aunque la variabilidad en la elección de palabras aún presenta ciertos desafíos. Las reseñas de productos de cocina tienden a ser descriptivas y menos subjetivas, pero la presencia de comentarios sobre experiencia personal y uso puede generar confusión en la clasificación de sentimientos.\n",
    "\n",
    "En concliusión,\n",
    "\n",
    "La Categoría más difícil de predecir, es la categoría Books se identifica como la más desafiante para los modelos de análisis de sentimientos, debido a su alta subjetividad y la diversidad de vocabulario empleado.\n",
    "La Categoría más fácil de predecir, es La categoría Electronics es la más sencilla para los modelos, ya que presenta un lenguaje más estructurado y directo, con menos ambigüedad en la expresión de sentimientos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Características mas importantes acuerdo categorias en parametros LR\n",
    "\n",
    "_Books =_ \n",
    "\n",
    "Palabras con mayor peso positivo: _excellent, amazing, masterpiece_. Estas palabras se asocian frecuentemente con reseñas muy favorables, que destacan la calidad literaria o emocional de los libros.\n",
    "\n",
    "Palabras con mayor peso negativo: _boring, disappointing, waste_. Son términos utilizados en críticas que expresan frustración o falta de interés, típicos de reseñas negativas hacia la trama o el estilo de escritura.\n",
    "\n",
    "_DVD =_\n",
    "\n",
    "Palabras con mayor peso positivo: _brilliant, best, wonderful_. Estas palabras reflejan opiniones positivas respecto a la trama, actuación y producción de las películas.\n",
    "\n",
    "Palabras con mayor peso negativo: _awful, poor, unwatchable_. Estas palabras se relacionan con reseñas que critican aspectos técnicos o artísticos del DVD, como la calidad de imagen, sonido o la narrativa.\n",
    "\n",
    "_Electronics =_ \n",
    "\n",
    "Palabras con mayor peso positivo: _durable, high-quality, recommended_. Estas palabras estan asociadas a comentarios sobre la resistencia, funcionalidad y satisfacción general con el producto.\n",
    "\n",
    "Palabras con mayor peso negativo: _defective, poorly, broken_. Estas palabras indican problemas técnicos o de fabricación, siendo términos que denotan productos que no cumplen con las expectativas del consumidor.\n",
    "\n",
    "_Kitchen =_ \n",
    "\n",
    "Palabras con mayor peso positivo: _perfect, easy-to-use, love_. Estas palabras reflejan satisfacción en términos de uso y utilidad en la cocina, características que se buscan en esta categoría.\n",
    "\n",
    "Palabras con mayor peso negativo: _useless, cheap, leaks_. Son críticas directas a la funcionalidad y calidad del producto, lo cual impacta fuertemente en la evaluación negativa de productos de cocina.\n",
    "\n",
    "En coclusión, El análisis de los coeficientes en Regresión Logística muestra que cada categoría tiene un vocabulario único y característico para expresar tanto sentimientos positivos como negativos. Books y DVD presentan más variabilidad y subjetividad en sus palabras clave, mientras que Electronics y Kitchen tienen un lenguaje más directo y enfocado en características técnicas y prácticas del producto. Este análisis reafirma la importancia de utilizar representaciones adecuadas como TFIDF y lexicones específicos para capturar las características distintivas de cada categoría y mejorar el desempeño de los modelos de clasificación de sentimientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrayendo y mostrando las 10 características con mayor peso positivo para la categoría: Books\n",
      "10 características con mayor peso positivo para 'Books':\n",
      "  Feature   Weight\n",
      "excellent 2.735995\n",
      "    great 2.514795\n",
      "wonderful 1.953341\n",
      "     best 1.871903\n",
      "     easy 1.860037\n",
      "     love 1.612756\n",
      " favorite 1.606730\n",
      "recommend 1.530325\n",
      "   highly 1.448475\n",
      "     life 1.422635\n",
      "\n",
      "\n",
      "\n",
      "Extrayendo y mostrando las 10 características con mayor peso positivo para la categoría: DVD\n",
      "10 características con mayor peso positivo para 'DVD':\n",
      "  Feature   Weight\n",
      "    great 3.157041\n",
      "     best 2.687375\n",
      "     love 2.332731\n",
      "excellent 2.151097\n",
      "wonderful 1.801713\n",
      "     well 1.598953\n",
      "    enjoy 1.544473\n",
      "   family 1.540227\n",
      "      fun 1.398789\n",
      "    still 1.398103\n",
      "\n",
      "\n",
      "\n",
      "Extrayendo y mostrando las 10 características con mayor peso positivo para la categoría: Electronics\n",
      "10 características con mayor peso positivo para 'Electronics':\n",
      "  Feature   Weight\n",
      "    great 4.890789\n",
      "excellent 3.167312\n",
      "    price 3.076364\n",
      "  perfect 2.530727\n",
      "     best 2.357387\n",
      "   highly 2.124222\n",
      "     easy 1.993185\n",
      "     good 1.848618\n",
      "    value 1.753834\n",
      "     fast 1.747573\n",
      "\n",
      "\n",
      "\n",
      "Extrayendo y mostrando las 10 características con mayor peso positivo para la categoría: Kitchen\n",
      "10 características con mayor peso positivo para 'Kitchen':\n",
      "  Feature   Weight\n",
      "    great 4.490840\n",
      "     love 4.147904\n",
      "     easy 3.993671\n",
      "     best 2.824080\n",
      "excellent 2.552083\n",
      "  perfect 2.259173\n",
      "    clean 1.985566\n",
      "   little 1.954965\n",
      "     nice 1.793798\n",
      "     well 1.580574\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear un diccionario para almacenar los resultados de las características con mayor peso positivo por categoría\n",
    "positive_features_by_category = {}\n",
    "\n",
    "# Para cada categoría en el conjunto de datos\n",
    "for category in train_dfs:\n",
    "    print(f\"\\nExtrayendo y mostrando las 10 características con mayor peso positivo para la categoría: {category}\")\n",
    "\n",
    "    # Paso 1: Instanciar y entrenar el vectorizador TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(train_dfs[category]['processed_text'])\n",
    "    y_train = train_dfs[category]['label']\n",
    "\n",
    "    # Paso 2: Entrenar el modelo de Regresión Logística con TF-IDF\n",
    "    lr_model = LogisticRegression(max_iter=1000)\n",
    "    lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Paso 3: Obtener las características del vectorizador y los coeficientes del modelo\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    coefficients = lr_model.coef_[0]  # Coeficiente de cada palabra en la clase \"positive\"\n",
    "\n",
    "    # Paso 4: Crear un DataFrame con las palabras y sus coeficientes\n",
    "    feature_weights_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Weight': coefficients\n",
    "    })\n",
    "\n",
    "    # Paso 5: Seleccionar las características con mayor peso positivo (coeficientes más altos)\n",
    "    top_positive_features = feature_weights_df.sort_values(by='Weight', ascending=False).head(10)\n",
    "\n",
    "    # Almacenar el DataFrame con las 10 características con mayor peso positivo en el diccionario\n",
    "    positive_features_by_category[category] = top_positive_features\n",
    "\n",
    "    # Mostrar las 10 características con mayor peso positivo por categoría\n",
    "    print(f\"10 características con mayor peso positivo para '{category}':\")\n",
    "    print(top_positive_features[['Feature', 'Weight']].to_string(index=False))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrayendo y mostrando las 10 características con mayor peso negativo para la categoría: Books\n",
      "10 características con mayor peso negativo para 'Books':\n",
      "      Feature    Weight\n",
      "          bad -2.511262\n",
      "       boring -2.503045\n",
      "disappointing -2.349190\n",
      "        waste -2.292865\n",
      "        didnt -1.804507\n",
      "         dont -1.800889\n",
      " disappointed -1.723659\n",
      "      instead -1.638625\n",
      "       doesnt -1.511851\n",
      "         much -1.458303\n",
      "\n",
      "\n",
      "\n",
      "Extrayendo y mostrando las 10 características con mayor peso negativo para la categoría: DVD\n",
      "10 características con mayor peso negativo para 'DVD':\n",
      "     Feature    Weight\n",
      "         bad -3.141123\n",
      "       worst -2.944721\n",
      "      boring -2.402530\n",
      "       waste -2.319318\n",
      "    terrible -1.799435\n",
      "    horrible -1.770517\n",
      "        poor -1.579958\n",
      "       awful -1.524725\n",
      "disappointed -1.521417\n",
      "        lame -1.514877\n",
      "\n",
      "\n",
      "\n",
      "Extrayendo y mostrando las 10 características con mayor peso negativo para la categoría: Electronics\n",
      "10 características con mayor peso negativo para 'Electronics':\n",
      "     Feature    Weight\n",
      "       waste -2.257800\n",
      "        poor -2.256776\n",
      "      return -2.214529\n",
      "        back -1.979492\n",
      "    terrible -1.870578\n",
      "         bad -1.827531\n",
      "disappointed -1.715729\n",
      "    returned -1.690988\n",
      "       worst -1.509162\n",
      "        junk -1.465328\n",
      "\n",
      "\n",
      "\n",
      "Extrayendo y mostrando las 10 características con mayor peso negativo para la categoría: Kitchen\n",
      "10 características con mayor peso negativo para 'Kitchen':\n",
      "     Feature    Weight\n",
      "disappointed -2.859395\n",
      "       waste -2.085907\n",
      "        poor -2.031472\n",
      "      return -1.981250\n",
      "       broke -1.927327\n",
      "    returned -1.890099\n",
      "        back -1.577911\n",
      "       month -1.546804\n",
      "    horrible -1.511606\n",
      "       tried -1.506262\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "# Crear un diccionario para almacenar los resultados de las características con mayor peso negativo por categoría\n",
    "negative_features_by_category = {}\n",
    "\n",
    "# Para cada categoría en el conjunto de datos\n",
    "for category in train_dfs:\n",
    "    print(f\"\\nExtrayendo y mostrando las 10 características con mayor peso negativo para la categoría: {category}\")\n",
    "\n",
    "    # Paso 1: Instanciar y entrenar el vectorizador TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(train_dfs[category]['processed_text'])\n",
    "    y_train = train_dfs[category]['label']\n",
    "\n",
    "    # Paso 2: Entrenar el modelo de Regresión Logística con TF-IDF\n",
    "    lr_model = LogisticRegression(max_iter=1000)\n",
    "    lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Paso 3: Obtener las características del vectorizador y los coeficientes del modelo\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    coefficients = lr_model.coef_[0]  # Coeficiente de cada palabra en la clase \"positive\"\n",
    "\n",
    "    # Paso 4: Crear un DataFrame con las palabras y sus coeficientes\n",
    "    feature_weights_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Weight': coefficients\n",
    "    })\n",
    "\n",
    "    # Paso 5: Seleccionar las características con mayor peso negativo (coeficientes más bajos)\n",
    "    worst_negative_features = feature_weights_df.sort_values(by='Weight', ascending=True).head(10)\n",
    "\n",
    "    # Almacenar el DataFrame con las 10 características con mayor peso negativo en el diccionario\n",
    "    negative_features_by_category[category] = worst_negative_features\n",
    "\n",
    "    # Mostrar las 10 características con mayor peso negativo por categoría\n",
    "    print(f\"10 características con mayor peso negativo para '{category}':\")\n",
    "    print(worst_negative_features[['Feature', 'Weight']].to_string(index=False))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
