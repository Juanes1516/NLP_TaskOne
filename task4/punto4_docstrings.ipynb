{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 4\n",
    "\n",
    "Repite el punto III, pero en lugar de usar tus embeddings, utiliza los embeddings preentrenados de Google-Word2Vec o Glove con diferentes dimensionalidades (al menos 3). Puedes descargar estos embeddings desde diferentes fuentes como el repositorio de datos de Gensim (Gensim Pretrained Models), la página web de Stanford (Stanford Glove Project), o TensorFlow Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importación de bibliotecas y dependencias a usar en el ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import string\n",
    "from sklearn.calibration import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import gensim.downloader\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se cargan los embeddings preentrenados de GloVe (Global Vectors for Word Representation) utilizando la biblioteca Gensim. Los embeddings de GloVe son vectores numéricos que representan palabras, entrenados en grandes cantidades de texto para capturar relaciones semánticas entre palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## Glove pre-trained embeddings with different dimensionalities (at least 3)\n",
    "###############\n",
    "glove_vectors100 = gensim.downloader.load('glove-wiki-gigaword-100')\n",
    "glove_vectors200 = gensim.downloader.load('glove-wiki-gigaword-200')\n",
    "glove_vectors300 = gensim.downloader.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente implementación, carga los libros considerados desde un directorio, limpia su contenido eliminando secciones innecesarias, los divide en segmentos de palabras, y crea un dataset que puede ser usado para procesar un conjunto de libros del Proyecto Gutenberg y crear un dataset que pueda ser utilizado para entrenar los modelos considerados en el ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "## CREANDO DATASET\n",
    "###########\n",
    "\n",
    "# Función para limpiar el texto del Proyecto Gutenberg\n",
    "def clean_gutenberg_text(text):\n",
    "    text = re.sub(r'^.*?\\*\\*\\* START OF THE PROJECT GUTENBERG EBOOK.*?\\*\\*\\*', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'\\*\\*\\* END OF THE PROJECT GUTENBERG EBOOK.*?$', '', text, flags=re.DOTALL)\n",
    "    authors = r'William Oberfield|James Branch Cabell|Wilhelm Raabe'\n",
    "    text = re.sub(r'(?i)\\b(?:' + authors + r')\\b.*?(?=\\n)', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'(Produced by.*?Distributed Proofreaders|Title:.*?Author:.*?Release date:.*?Language:.*?Credits:.*?Project Gutenberg Distributed Proofreaders)', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'(CONTENTS.*?THE AFTERWORD|BIBLIOGRAPHY|INDEX)', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Función para dividir el texto en segmentos de longitud definida\n",
    "def split_into_segments(text, segment_size=200):\n",
    "    words = text.split() \n",
    "    segments = [' '.join(words[i:i + segment_size]) for i in range(0, len(words), segment_size)]\n",
    "    return segments\n",
    "\n",
    "# Función para cargar los datos de libros desde un directorio\n",
    "def load_books_data(base_path='books', segment_size=200):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    authors = os.listdir(base_path)\n",
    "\n",
    "    # Recorrer cada autor en el directorio\n",
    "    for author in authors:\n",
    "        author_path = os.path.join(base_path, author)\n",
    "        # Recorrer cada archivo de libro del autor\n",
    "        for book_file in os.listdir(author_path):\n",
    "            # Leer el archivo de libro\n",
    "            with open(os.path.join(author_path, book_file), 'r', encoding='utf-8') as f:\n",
    "                book_text = f.read()\n",
    "                clean_text = clean_gutenberg_text(book_text)\n",
    "                segments = split_into_segments(clean_text, segment_size)\n",
    "                texts.extend(segments)\n",
    "                labels.extend([author] * len(segments))\n",
    "    \n",
    "    return texts, labels\n",
    "\n",
    "# Función para crear un DataFrame a partir de los textos y etiquetas\n",
    "def create_dataset(texts, authors):\n",
    "    df = pd.DataFrame({'text': texts, 'author': authors})\n",
    "    return df\n",
    "\n",
    "# Cargar los libros y etiquetas\n",
    "texts, labels = load_books_data()\n",
    "# Crear un dataset con los textos y etiquetas\n",
    "dataset = create_dataset(texts, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Esta implementación, define tres arquitecturas diferentes de redes neuronales para el procesamiento de texto utilizando embeddings preentrenados. Estas redes están diseñadas para tareas de clasificación multiclase (probablemente con tres clases, dado que la capa de salida tiene 3 neuronas con activación softmax). A continuación, se desglosan cada uno de los modelos:\n",
    "\n",
    "1. build_simple_model: Es el modelo más básico, con una capa de embeddings, una capa de promedio global, y dos capas densas antes de la salida.\n",
    "2. build_deep_model: Es más profundo, con más capas densas, y utiliza Dropout para prevenir el sobreajuste.\n",
    "3. build_batchnorm_model: Añade Batch Normalization para estabilizar el entrenamiento y mejorar la generalización.\n",
    "\n",
    "Todos los modelos usan una arquitectura secuencial para clasificar los datos en 3 clases con softmax en la capa de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## MODELOS \n",
    "############\n",
    "\n",
    "# Construye un modelo simple con una capa de embeddings y algunas capas densas\n",
    "def build_simple_model(vocab_size, embedding_size, embedding_matrix):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=200, weights=[embedding_matrix], trainable=False))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model , \"simple\"\n",
    "\n",
    "# Construye un modelo más profundo con más capas densas y Dropout para regularización\n",
    "def build_deep_model(vocab_size, embedding_size, embedding_matrix):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=200, weights=[embedding_matrix], trainable=False))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model, \"deep\"\n",
    "\n",
    "# Construye un modelo con Batch Normalization y Dropout para mejorar la estabilidad del entrenamiento\n",
    "def build_batchnorm_model(vocab_size, embedding_size, embedding_matrix):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=200, weights=[embedding_matrix], trainable=False))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model , \"batchNorm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta implementación, define una función para compilar y entrenar un modelo de redes neuronales en Keras, con la capacidad de almacenar el mejor modelo durante el proceso de entrenamiento. Esta, entrena el modelo, guarda la mejor versión según la precisión y retorna el historial de entrenamiento para análisis futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "## FUNCIÓN DE COMPILACIÓN\n",
    "#############\n",
    "def compile_and_train_model(model, X_train, y_train, X_val, y_val, size, arquitectureLabel):\n",
    "  # Compilar el modelo usando la pérdida de 'sparse_categorical_crossentropy' y el optimizador 'adam'\n",
    "  model.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy']\n",
    "  )\n",
    "  # Definir un callback para guardar el mejor modelo basado en la precisión durante el entrenamiento\n",
    "  checkpoint_callback = ModelCheckpoint(\n",
    "    f'best_model_{size}_{arquitectureLabel}.keras',\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1 \n",
    "  )\n",
    "\n",
    "  # Entrenar el modelo con los datos de entrenamiento (X_train, y_train) y validación (X_val, y_val)\n",
    "  history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_val, y_val), \n",
    "    epochs=50, \n",
    "    batch_size=32,\n",
    "    callbacks=[checkpoint_callback]\n",
    "  )\n",
    "  return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta implementación, entrena tres arquitecturas de modelos de clasificación de texto utilizando embeddings preentrenados de GloVe con diferentes tamaños (100, 200, 300). Luego, evalúa el rendimiento de cada modelo en un conjunto de prueba, calculando precisión, recall y F1. Finalmente, guarda y muestra los resultados obtenidos, donde se ejecuta un proceso de entrenamiento y evaluación de modelos de clasificación de texto utilizando embeddings preentrenados de GloVe (100, 200 y 300 dimensiones) y tres arquitecturas de redes neuronales (simple, profunda y con BatchNorm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con embeddings de tamaño: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4267 - loss: 0.9962\n",
      "Epoch 1: accuracy improved from -inf to 0.49728, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 385ms/step - accuracy: 0.4284 - loss: 0.9942 - val_accuracy: 0.5342 - val_loss: 0.8893\n",
      "Epoch 2/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5138 - loss: 0.8108\n",
      "Epoch 2: accuracy improved from 0.49728 to 0.52211, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 117ms/step - accuracy: 0.5144 - loss: 0.8107 - val_accuracy: 0.5404 - val_loss: 0.8861\n",
      "Epoch 3/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5952 - loss: 0.7997\n",
      "Epoch 3: accuracy improved from 0.52211 to 0.61443, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.5957 - loss: 0.7994 - val_accuracy: 0.5404 - val_loss: 0.8589\n",
      "Epoch 4/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5921 - loss: 0.7758 \n",
      "Epoch 4: accuracy improved from 0.61443 to 0.67417, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.6034 - loss: 0.7732 - val_accuracy: 0.6522 - val_loss: 0.8212\n",
      "Epoch 5/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7396 - loss: 0.7168\n",
      "Epoch 5: accuracy improved from 0.67417 to 0.76028, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.7401 - loss: 0.7164 - val_accuracy: 0.5590 - val_loss: 0.7915\n",
      "Epoch 6/50\n",
      "\u001b[1m29/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7393 - loss: 0.6394\n",
      "Epoch 6: accuracy improved from 0.76028 to 0.78976, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.7530 - loss: 0.6352 - val_accuracy: 0.7578 - val_loss: 0.6970\n",
      "Epoch 7/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7940 - loss: 0.5707\n",
      "Epoch 7: accuracy improved from 0.78976 to 0.82079, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.7978 - loss: 0.5673 - val_accuracy: 0.7391 - val_loss: 0.6553\n",
      "Epoch 8/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8262 - loss: 0.4995\n",
      "Epoch 8: accuracy improved from 0.82079 to 0.82622, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.8262 - loss: 0.4994 - val_accuracy: 0.8012 - val_loss: 0.5954\n",
      "Epoch 9/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.5013\n",
      "Epoch 9: accuracy did not improve from 0.82622\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7958 - loss: 0.4995 - val_accuracy: 0.7888 - val_loss: 0.6103\n",
      "Epoch 10/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8252 - loss: 0.4785\n",
      "Epoch 10: accuracy improved from 0.82622 to 0.84096, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.8282 - loss: 0.4759 - val_accuracy: 0.8075 - val_loss: 0.5644\n",
      "Epoch 11/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8131 - loss: 0.4783\n",
      "Epoch 11: accuracy did not improve from 0.84096\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8136 - loss: 0.4775 - val_accuracy: 0.8075 - val_loss: 0.5734\n",
      "Epoch 12/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8262 - loss: 0.4723\n",
      "Epoch 12: accuracy did not improve from 0.84096\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8272 - loss: 0.4698 - val_accuracy: 0.8012 - val_loss: 0.5544\n",
      "Epoch 13/50\n",
      "\u001b[1m29/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8394 - loss: 0.4438\n",
      "Epoch 13: accuracy improved from 0.84096 to 0.84562, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.8412 - loss: 0.4416 - val_accuracy: 0.8075 - val_loss: 0.5433\n",
      "Epoch 14/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8396 - loss: 0.4371\n",
      "Epoch 14: accuracy improved from 0.84562 to 0.84639, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.8397 - loss: 0.4370 - val_accuracy: 0.8012 - val_loss: 0.5401\n",
      "Epoch 15/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8688 - loss: 0.3880\n",
      "Epoch 15: accuracy improved from 0.84639 to 0.85182, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.8680 - loss: 0.3897 - val_accuracy: 0.8075 - val_loss: 0.5646\n",
      "Epoch 16/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8485 - loss: 0.4284\n",
      "Epoch 16: accuracy did not improve from 0.85182\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8489 - loss: 0.4280 - val_accuracy: 0.8137 - val_loss: 0.5295\n",
      "Epoch 17/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8552 - loss: 0.4060\n",
      "Epoch 17: accuracy improved from 0.85182 to 0.85570, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.8551 - loss: 0.4060 - val_accuracy: 0.8012 - val_loss: 0.5590\n",
      "Epoch 18/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8569 - loss: 0.4334\n",
      "Epoch 18: accuracy improved from 0.85570 to 0.86113, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.8571 - loss: 0.4322 - val_accuracy: 0.7950 - val_loss: 0.5379\n",
      "Epoch 19/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4661\n",
      "Epoch 19: accuracy improved from 0.86113 to 0.86656, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.8472 - loss: 0.4560 - val_accuracy: 0.8075 - val_loss: 0.5442\n",
      "Epoch 20/50\n",
      "\u001b[1m28/41\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8714 - loss: 0.3912\n",
      "Epoch 20: accuracy did not improve from 0.86656\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8682 - loss: 0.3927 - val_accuracy: 0.8075 - val_loss: 0.5394\n",
      "Epoch 21/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8633 - loss: 0.3784\n",
      "Epoch 21: accuracy did not improve from 0.86656\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8633 - loss: 0.3798 - val_accuracy: 0.8012 - val_loss: 0.5237\n",
      "Epoch 22/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8596 - loss: 0.4044\n",
      "Epoch 22: accuracy improved from 0.86656 to 0.87044, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.8598 - loss: 0.4040 - val_accuracy: 0.8075 - val_loss: 0.5181\n",
      "Epoch 23/50\n",
      "\u001b[1m28/41\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8488 - loss: 0.4081\n",
      "Epoch 23: accuracy did not improve from 0.87044\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8478 - loss: 0.4089 - val_accuracy: 0.7888 - val_loss: 0.5725\n",
      "Epoch 24/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.4122\n",
      "Epoch 24: accuracy did not improve from 0.87044\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8607 - loss: 0.4079 - val_accuracy: 0.8075 - val_loss: 0.5302\n",
      "Epoch 25/50\n",
      "\u001b[1m28/41\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8813 - loss: 0.3705\n",
      "Epoch 25: accuracy did not improve from 0.87044\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8768 - loss: 0.3735 - val_accuracy: 0.8447 - val_loss: 0.5050\n",
      "Epoch 26/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8609 - loss: 0.3918\n",
      "Epoch 26: accuracy did not improve from 0.87044\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8614 - loss: 0.3909 - val_accuracy: 0.8012 - val_loss: 0.5566\n",
      "Epoch 27/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8429 - loss: 0.4172\n",
      "Epoch 27: accuracy did not improve from 0.87044\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8452 - loss: 0.4143 - val_accuracy: 0.8385 - val_loss: 0.5062\n",
      "Epoch 28/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8776 - loss: 0.3627\n",
      "Epoch 28: accuracy improved from 0.87044 to 0.87122, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8751 - loss: 0.3662 - val_accuracy: 0.8447 - val_loss: 0.4948\n",
      "Epoch 29/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8888 - loss: 0.3389\n",
      "Epoch 29: accuracy improved from 0.87122 to 0.87199, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.8884 - loss: 0.3396 - val_accuracy: 0.8385 - val_loss: 0.5135\n",
      "Epoch 30/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8558 - loss: 0.3936\n",
      "Epoch 30: accuracy did not improve from 0.87199\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8583 - loss: 0.3907 - val_accuracy: 0.8137 - val_loss: 0.5096\n",
      "Epoch 31/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8908 - loss: 0.3562\n",
      "Epoch 31: accuracy improved from 0.87199 to 0.88130, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.8882 - loss: 0.3567 - val_accuracy: 0.8385 - val_loss: 0.4999\n",
      "Epoch 32/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8825 - loss: 0.3740\n",
      "Epoch 32: accuracy did not improve from 0.88130\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8822 - loss: 0.3727 - val_accuracy: 0.8385 - val_loss: 0.4956\n",
      "Epoch 33/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8811 - loss: 0.3752\n",
      "Epoch 33: accuracy improved from 0.88130 to 0.88363, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.8819 - loss: 0.3713 - val_accuracy: 0.8385 - val_loss: 0.4944\n",
      "Epoch 34/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8548 - loss: 0.3885\n",
      "Epoch 34: accuracy did not improve from 0.88363\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8586 - loss: 0.3830 - val_accuracy: 0.8447 - val_loss: 0.5051\n",
      "Epoch 35/50\n",
      "\u001b[1m29/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8740 - loss: 0.3636\n",
      "Epoch 35: accuracy did not improve from 0.88363\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8733 - loss: 0.3631 - val_accuracy: 0.8385 - val_loss: 0.4934\n",
      "Epoch 36/50\n",
      "\u001b[1m28/41\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8792 - loss: 0.3336\n",
      "Epoch 36: accuracy did not improve from 0.88363\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8762 - loss: 0.3395 - val_accuracy: 0.8385 - val_loss: 0.4982\n",
      "Epoch 37/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8673 - loss: 0.3588\n",
      "Epoch 37: accuracy did not improve from 0.88363\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8695 - loss: 0.3581 - val_accuracy: 0.8385 - val_loss: 0.4967\n",
      "Epoch 38/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8545 - loss: 0.4160\n",
      "Epoch 38: accuracy did not improve from 0.88363\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8596 - loss: 0.4000 - val_accuracy: 0.8199 - val_loss: 0.4904\n",
      "Epoch 39/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8770 - loss: 0.3606\n",
      "Epoch 39: accuracy did not improve from 0.88363\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8771 - loss: 0.3602 - val_accuracy: 0.8509 - val_loss: 0.4849\n",
      "Epoch 40/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8944 - loss: 0.3243\n",
      "Epoch 40: accuracy did not improve from 0.88363\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8900 - loss: 0.3312 - val_accuracy: 0.8385 - val_loss: 0.4921\n",
      "Epoch 41/50\n",
      "\u001b[1m28/41\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8751 - loss: 0.3552\n",
      "Epoch 41: accuracy did not improve from 0.88363\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8764 - loss: 0.3523 - val_accuracy: 0.8447 - val_loss: 0.4825\n",
      "Epoch 42/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8908 - loss: 0.3537\n",
      "Epoch 42: accuracy improved from 0.88363 to 0.88518, saving model to best_model_100_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.8902 - loss: 0.3530 - val_accuracy: 0.7888 - val_loss: 0.5530\n",
      "Epoch 43/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8747 - loss: 0.3474\n",
      "Epoch 43: accuracy did not improve from 0.88518\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8753 - loss: 0.3465 - val_accuracy: 0.8137 - val_loss: 0.4888\n",
      "Epoch 44/50\n",
      "\u001b[1m28/41\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8678 - loss: 0.3579\n",
      "Epoch 44: accuracy did not improve from 0.88518\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8704 - loss: 0.3510 - val_accuracy: 0.8261 - val_loss: 0.4819\n",
      "Epoch 45/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8803 - loss: 0.3509\n",
      "Epoch 45: accuracy did not improve from 0.88518\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8804 - loss: 0.3507 - val_accuracy: 0.8323 - val_loss: 0.4739\n",
      "Epoch 46/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8622 - loss: 0.3664\n",
      "Epoch 46: accuracy did not improve from 0.88518\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8660 - loss: 0.3588 - val_accuracy: 0.8137 - val_loss: 0.5296\n",
      "Epoch 47/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8643 - loss: 0.3730\n",
      "Epoch 47: accuracy did not improve from 0.88518\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8670 - loss: 0.3669 - val_accuracy: 0.7826 - val_loss: 0.5687\n",
      "Epoch 48/50\n",
      "\u001b[1m29/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8639 - loss: 0.3622\n",
      "Epoch 48: accuracy did not improve from 0.88518\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8684 - loss: 0.3564 - val_accuracy: 0.8261 - val_loss: 0.4964\n",
      "Epoch 49/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8820 - loss: 0.3333\n",
      "Epoch 49: accuracy did not improve from 0.88518\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8820 - loss: 0.3334 - val_accuracy: 0.8509 - val_loss: 0.4731\n",
      "Epoch 50/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8961 - loss: 0.2988\n",
      "Epoch 50: accuracy did not improve from 0.88518\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8928 - loss: 0.3047 - val_accuracy: 0.8137 - val_loss: 0.4897\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9069 - loss: 0.2791\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000172AD460D60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Entrenando con embeddings de tamaño: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4819 - loss: 0.9409\n",
      "Epoch 1: accuracy improved from -inf to 0.50272, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - accuracy: 0.4843 - loss: 0.9340 - val_accuracy: 0.5342 - val_loss: 0.8827\n",
      "Epoch 2/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5075 - loss: 0.8376\n",
      "Epoch 2: accuracy improved from 0.50272 to 0.50349, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.5068 - loss: 0.8389 - val_accuracy: 0.5342 - val_loss: 0.8809\n",
      "Epoch 3/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5204 - loss: 0.8387\n",
      "Epoch 3: accuracy improved from 0.50349 to 0.53530, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.5217 - loss: 0.8377 - val_accuracy: 0.5342 - val_loss: 0.8780\n",
      "Epoch 4/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5648 - loss: 0.8085\n",
      "Epoch 4: accuracy improved from 0.53530 to 0.57486, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.5656 - loss: 0.8079 - val_accuracy: 0.7391 - val_loss: 0.8054\n",
      "Epoch 5/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7362 - loss: 0.6869\n",
      "Epoch 5: accuracy improved from 0.57486 to 0.72537, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.7348 - loss: 0.6868 - val_accuracy: 0.8012 - val_loss: 0.6543\n",
      "Epoch 6/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7686 - loss: 0.6139\n",
      "Epoch 6: accuracy improved from 0.72537 to 0.78898, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.7711 - loss: 0.6081 - val_accuracy: 0.7329 - val_loss: 0.6976\n",
      "Epoch 7/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8066 - loss: 0.5372\n",
      "Epoch 7: accuracy improved from 0.78898 to 0.81846, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.8086 - loss: 0.5347 - val_accuracy: 0.8012 - val_loss: 0.5664\n",
      "Epoch 8/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8338 - loss: 0.4736\n",
      "Epoch 8: accuracy improved from 0.81846 to 0.83476, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.8339 - loss: 0.4743 - val_accuracy: 0.8012 - val_loss: 0.5433\n",
      "Epoch 9/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8504 - loss: 0.4473\n",
      "Epoch 9: accuracy improved from 0.83476 to 0.84872, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.8504 - loss: 0.4473 - val_accuracy: 0.8075 - val_loss: 0.5663\n",
      "Epoch 10/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8353 - loss: 0.4596\n",
      "Epoch 10: accuracy did not improve from 0.84872\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8360 - loss: 0.4582 - val_accuracy: 0.8137 - val_loss: 0.5649\n",
      "Epoch 11/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8542 - loss: 0.4024\n",
      "Epoch 11: accuracy did not improve from 0.84872\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8526 - loss: 0.4129 - val_accuracy: 0.7578 - val_loss: 0.5948\n",
      "Epoch 12/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8086 - loss: 0.4980\n",
      "Epoch 12: accuracy did not improve from 0.84872\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8095 - loss: 0.4965 - val_accuracy: 0.8385 - val_loss: 0.5219\n",
      "Epoch 13/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8643 - loss: 0.4149\n",
      "Epoch 13: accuracy improved from 0.84872 to 0.85648, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.8630 - loss: 0.4151 - val_accuracy: 0.8137 - val_loss: 0.5220\n",
      "Epoch 14/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8693 - loss: 0.4083\n",
      "Epoch 14: accuracy improved from 0.85648 to 0.85881, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.8679 - loss: 0.4076 - val_accuracy: 0.8137 - val_loss: 0.5463\n",
      "Epoch 15/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8629 - loss: 0.3961\n",
      "Epoch 15: accuracy improved from 0.85881 to 0.86501, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.8633 - loss: 0.3992 - val_accuracy: 0.7578 - val_loss: 0.5835\n",
      "Epoch 16/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8731 - loss: 0.3865\n",
      "Epoch 16: accuracy did not improve from 0.86501\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8727 - loss: 0.3866 - val_accuracy: 0.8199 - val_loss: 0.5250\n",
      "Epoch 17/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8759 - loss: 0.3452\n",
      "Epoch 17: accuracy did not improve from 0.86501\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8732 - loss: 0.3559 - val_accuracy: 0.8199 - val_loss: 0.5218\n",
      "Epoch 18/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8739 - loss: 0.3605\n",
      "Epoch 18: accuracy did not improve from 0.86501\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8723 - loss: 0.3637 - val_accuracy: 0.7391 - val_loss: 0.6785\n",
      "Epoch 19/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8604 - loss: 0.4086\n",
      "Epoch 19: accuracy did not improve from 0.86501\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8605 - loss: 0.4044 - val_accuracy: 0.7950 - val_loss: 0.6070\n",
      "Epoch 20/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8516 - loss: 0.3871\n",
      "Epoch 20: accuracy did not improve from 0.86501\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8516 - loss: 0.3886 - val_accuracy: 0.8323 - val_loss: 0.5542\n",
      "Epoch 21/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8580 - loss: 0.4469\n",
      "Epoch 21: accuracy improved from 0.86501 to 0.87898, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.8599 - loss: 0.4413 - val_accuracy: 0.8385 - val_loss: 0.5383\n",
      "Epoch 22/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8635 - loss: 0.4006\n",
      "Epoch 22: accuracy did not improve from 0.87898\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8638 - loss: 0.3986 - val_accuracy: 0.8075 - val_loss: 0.5345\n",
      "Epoch 23/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8759 - loss: 0.3752\n",
      "Epoch 23: accuracy did not improve from 0.87898\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8760 - loss: 0.3718 - val_accuracy: 0.8199 - val_loss: 0.4988\n",
      "Epoch 24/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8915 - loss: 0.3529\n",
      "Epoch 24: accuracy did not improve from 0.87898\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8909 - loss: 0.3534 - val_accuracy: 0.8137 - val_loss: 0.5141\n",
      "Epoch 25/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8811 - loss: 0.3406\n",
      "Epoch 25: accuracy did not improve from 0.87898\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8809 - loss: 0.3410 - val_accuracy: 0.7453 - val_loss: 0.6463\n",
      "Epoch 26/50\n",
      "\u001b[1m26/41\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8533 - loss: 0.3859\n",
      "Epoch 26: accuracy did not improve from 0.87898\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8605 - loss: 0.3821 - val_accuracy: 0.8261 - val_loss: 0.4947\n",
      "Epoch 27/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8888 - loss: 0.3168\n",
      "Epoch 27: accuracy improved from 0.87898 to 0.88285, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.8884 - loss: 0.3191 - val_accuracy: 0.8261 - val_loss: 0.4928\n",
      "Epoch 28/50\n",
      "\u001b[1m28/41\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8801 - loss: 0.3625\n",
      "Epoch 28: accuracy did not improve from 0.88285\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8804 - loss: 0.3589 - val_accuracy: 0.8323 - val_loss: 0.4905\n",
      "Epoch 29/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8747 - loss: 0.3759\n",
      "Epoch 29: accuracy did not improve from 0.88285\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8743 - loss: 0.3760 - val_accuracy: 0.8385 - val_loss: 0.5138\n",
      "Epoch 30/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8862 - loss: 0.3332\n",
      "Epoch 30: accuracy did not improve from 0.88285\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8858 - loss: 0.3334 - val_accuracy: 0.8137 - val_loss: 0.5617\n",
      "Epoch 31/50\n",
      "\u001b[1m27/41\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8898 - loss: 0.2930\n",
      "Epoch 31: accuracy did not improve from 0.88285\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8845 - loss: 0.3087 - val_accuracy: 0.8199 - val_loss: 0.5059\n",
      "Epoch 32/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8840 - loss: 0.3403\n",
      "Epoch 32: accuracy improved from 0.88285 to 0.88441, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8842 - loss: 0.3384 - val_accuracy: 0.8385 - val_loss: 0.4840\n",
      "Epoch 33/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8545 - loss: 0.3707\n",
      "Epoch 33: accuracy did not improve from 0.88441\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8587 - loss: 0.3675 - val_accuracy: 0.8261 - val_loss: 0.4980\n",
      "Epoch 34/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8838 - loss: 0.3317\n",
      "Epoch 34: accuracy improved from 0.88441 to 0.88984, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.8840 - loss: 0.3316 - val_accuracy: 0.8261 - val_loss: 0.4777\n",
      "Epoch 35/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8883 - loss: 0.3394\n",
      "Epoch 35: accuracy did not improve from 0.88984\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8859 - loss: 0.3389 - val_accuracy: 0.8447 - val_loss: 0.4814\n",
      "Epoch 36/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8911 - loss: 0.3294\n",
      "Epoch 36: accuracy did not improve from 0.88984\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8890 - loss: 0.3282 - val_accuracy: 0.7888 - val_loss: 0.5164\n",
      "Epoch 37/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8773 - loss: 0.3358\n",
      "Epoch 37: accuracy did not improve from 0.88984\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8779 - loss: 0.3354 - val_accuracy: 0.8261 - val_loss: 0.4961\n",
      "Epoch 38/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8933 - loss: 0.3175\n",
      "Epoch 38: accuracy improved from 0.88984 to 0.89604, saving model to best_model_100_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.8941 - loss: 0.3176 - val_accuracy: 0.8447 - val_loss: 0.6664\n",
      "Epoch 39/50\n",
      "\u001b[1m28/41\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8927 - loss: 0.3037\n",
      "Epoch 39: accuracy did not improve from 0.89604\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8884 - loss: 0.3116 - val_accuracy: 0.8323 - val_loss: 0.5312\n",
      "Epoch 40/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8857 - loss: 0.2961\n",
      "Epoch 40: accuracy did not improve from 0.89604\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8836 - loss: 0.3026 - val_accuracy: 0.7950 - val_loss: 0.5841\n",
      "Epoch 41/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9028 - loss: 0.2959\n",
      "Epoch 41: accuracy did not improve from 0.89604\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8997 - loss: 0.2992 - val_accuracy: 0.8323 - val_loss: 0.5367\n",
      "Epoch 42/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8710 - loss: 0.3440\n",
      "Epoch 42: accuracy did not improve from 0.89604\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8715 - loss: 0.3411 - val_accuracy: 0.8323 - val_loss: 0.5380\n",
      "Epoch 43/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8660 - loss: 0.3455\n",
      "Epoch 43: accuracy did not improve from 0.89604\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8670 - loss: 0.3430 - val_accuracy: 0.8075 - val_loss: 0.5397\n",
      "Epoch 44/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8881 - loss: 0.3279\n",
      "Epoch 44: accuracy did not improve from 0.89604\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8880 - loss: 0.3270 - val_accuracy: 0.7578 - val_loss: 0.6345\n",
      "Epoch 45/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8601 - loss: 0.3498\n",
      "Epoch 45: accuracy did not improve from 0.89604\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8623 - loss: 0.3451 - val_accuracy: 0.7950 - val_loss: 0.5083\n",
      "Epoch 46/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8695 - loss: 0.3268\n",
      "Epoch 46: accuracy did not improve from 0.89604\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8697 - loss: 0.3265 - val_accuracy: 0.7950 - val_loss: 0.5275\n",
      "Epoch 47/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8580 - loss: 0.3587\n",
      "Epoch 47: accuracy did not improve from 0.89604\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8608 - loss: 0.3546 - val_accuracy: 0.8199 - val_loss: 0.5602\n",
      "Epoch 48/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8958 - loss: 0.2863\n",
      "Epoch 48: accuracy did not improve from 0.89604\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8949 - loss: 0.2872 - val_accuracy: 0.8137 - val_loss: 0.5154\n",
      "Epoch 49/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8925 - loss: 0.2886\n",
      "Epoch 49: accuracy did not improve from 0.89604\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8923 - loss: 0.2888 - val_accuracy: 0.8509 - val_loss: 0.6363\n",
      "Epoch 50/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8514 - loss: 0.3743\n",
      "Epoch 50: accuracy did not improve from 0.89604\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8534 - loss: 0.3697 - val_accuracy: 0.8509 - val_loss: 0.5038\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9125 - loss: 0.2490\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Entrenando con embeddings de tamaño: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3818 - loss: 1.3453\n",
      "Epoch 1: accuracy improved from -inf to 0.42514, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.3898 - loss: 1.3192 - val_accuracy: 0.3913 - val_loss: 1.0014\n",
      "Epoch 2/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5779 - loss: 0.9298\n",
      "Epoch 2: accuracy improved from 0.42514 to 0.64469, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.5912 - loss: 0.9061 - val_accuracy: 0.5342 - val_loss: 0.9450\n",
      "Epoch 3/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7349 - loss: 0.6932\n",
      "Epoch 3: accuracy improved from 0.64469 to 0.74864, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.7370 - loss: 0.6856 - val_accuracy: 0.7640 - val_loss: 0.8422\n",
      "Epoch 4/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7539 - loss: 0.6055\n",
      "Epoch 4: accuracy did not improve from 0.74864\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7529 - loss: 0.6077 - val_accuracy: 0.8261 - val_loss: 0.7735\n",
      "Epoch 5/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.5497\n",
      "Epoch 5: accuracy improved from 0.74864 to 0.79441, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.7936 - loss: 0.5500 - val_accuracy: 0.6522 - val_loss: 0.7077\n",
      "Epoch 6/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7762 - loss: 0.5969\n",
      "Epoch 6: accuracy improved from 0.79441 to 0.79984, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7815 - loss: 0.5823 - val_accuracy: 0.6211 - val_loss: 0.7287\n",
      "Epoch 7/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7979 - loss: 0.5032\n",
      "Epoch 7: accuracy did not improve from 0.79984\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7971 - loss: 0.5055 - val_accuracy: 0.5528 - val_loss: 0.7469\n",
      "Epoch 8/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7943 - loss: 0.5856\n",
      "Epoch 8: accuracy improved from 0.79984 to 0.81536, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.7989 - loss: 0.5702 - val_accuracy: 0.7516 - val_loss: 0.6844\n",
      "Epoch 9/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7949 - loss: 0.5313\n",
      "Epoch 9: accuracy improved from 0.81536 to 0.82079, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.8010 - loss: 0.5207 - val_accuracy: 0.5652 - val_loss: 0.7848\n",
      "Epoch 10/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8212 - loss: 0.4823\n",
      "Epoch 10: accuracy improved from 0.82079 to 0.82855, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.8214 - loss: 0.4821 - val_accuracy: 0.8012 - val_loss: 0.6255\n",
      "Epoch 11/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8409 - loss: 0.4680\n",
      "Epoch 11: accuracy did not improve from 0.82855\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8373 - loss: 0.4706 - val_accuracy: 0.7267 - val_loss: 0.6852\n",
      "Epoch 12/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8221 - loss: 0.4616\n",
      "Epoch 12: accuracy did not improve from 0.82855\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8227 - loss: 0.4639 - val_accuracy: 0.6708 - val_loss: 0.7220\n",
      "Epoch 13/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8232 - loss: 0.4829\n",
      "Epoch 13: accuracy improved from 0.82855 to 0.83476, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8259 - loss: 0.4788 - val_accuracy: 0.7888 - val_loss: 0.6355\n",
      "Epoch 14/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8379 - loss: 0.4428\n",
      "Epoch 14: accuracy did not improve from 0.83476\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8373 - loss: 0.4436 - val_accuracy: 0.5714 - val_loss: 1.0655\n",
      "Epoch 15/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8215 - loss: 0.4742\n",
      "Epoch 15: accuracy improved from 0.83476 to 0.84717, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.8290 - loss: 0.4632 - val_accuracy: 0.8385 - val_loss: 0.5519\n",
      "Epoch 16/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8562 - loss: 0.4259\n",
      "Epoch 16: accuracy improved from 0.84717 to 0.85958, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.8568 - loss: 0.4247 - val_accuracy: 0.8261 - val_loss: 0.6053\n",
      "Epoch 17/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8465 - loss: 0.4441\n",
      "Epoch 17: accuracy did not improve from 0.85958\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8473 - loss: 0.4427 - val_accuracy: 0.8012 - val_loss: 0.5894\n",
      "Epoch 18/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8585 - loss: 0.3737\n",
      "Epoch 18: accuracy did not improve from 0.85958\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8577 - loss: 0.3837 - val_accuracy: 0.6957 - val_loss: 0.7042\n",
      "Epoch 19/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8550 - loss: 0.3972\n",
      "Epoch 19: accuracy did not improve from 0.85958\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8549 - loss: 0.3979 - val_accuracy: 0.6398 - val_loss: 0.8045\n",
      "Epoch 20/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8144 - loss: 0.4589\n",
      "Epoch 20: accuracy did not improve from 0.85958\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8160 - loss: 0.4578 - val_accuracy: 0.8509 - val_loss: 0.5483\n",
      "Epoch 21/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8544 - loss: 0.4143\n",
      "Epoch 21: accuracy did not improve from 0.85958\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8540 - loss: 0.4141 - val_accuracy: 0.8323 - val_loss: 0.5603\n",
      "Epoch 22/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8516 - loss: 0.4354\n",
      "Epoch 22: accuracy did not improve from 0.85958\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8524 - loss: 0.4339 - val_accuracy: 0.7640 - val_loss: 0.6288\n",
      "Epoch 23/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8684 - loss: 0.3887\n",
      "Epoch 23: accuracy improved from 0.85958 to 0.86268, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.8678 - loss: 0.3899 - val_accuracy: 0.8261 - val_loss: 0.5751\n",
      "Epoch 24/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8525 - loss: 0.4085\n",
      "Epoch 24: accuracy did not improve from 0.86268\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8532 - loss: 0.4082 - val_accuracy: 0.8261 - val_loss: 0.5465\n",
      "Epoch 25/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8763 - loss: 0.3529\n",
      "Epoch 25: accuracy did not improve from 0.86268\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8746 - loss: 0.3572 - val_accuracy: 0.8012 - val_loss: 0.6498\n",
      "Epoch 26/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8376 - loss: 0.4322\n",
      "Epoch 26: accuracy did not improve from 0.86268\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8403 - loss: 0.4276 - val_accuracy: 0.8137 - val_loss: 0.7648\n",
      "Epoch 27/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8828 - loss: 0.3636\n",
      "Epoch 27: accuracy improved from 0.86268 to 0.86656, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.8807 - loss: 0.3694 - val_accuracy: 0.7702 - val_loss: 0.5333\n",
      "Epoch 28/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8526 - loss: 0.4016\n",
      "Epoch 28: accuracy improved from 0.86656 to 0.86811, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.8537 - loss: 0.4001 - val_accuracy: 0.8447 - val_loss: 0.5740\n",
      "Epoch 29/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8866 - loss: 0.3626\n",
      "Epoch 29: accuracy improved from 0.86811 to 0.87665, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.8846 - loss: 0.3670 - val_accuracy: 0.8261 - val_loss: 0.5158\n",
      "Epoch 30/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8503 - loss: 0.4057\n",
      "Epoch 30: accuracy did not improve from 0.87665\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8533 - loss: 0.4006 - val_accuracy: 0.7950 - val_loss: 0.6070\n",
      "Epoch 31/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8760 - loss: 0.3841\n",
      "Epoch 31: accuracy improved from 0.87665 to 0.87742, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.8761 - loss: 0.3830 - val_accuracy: 0.6957 - val_loss: 0.8037\n",
      "Epoch 32/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8851 - loss: 0.3469\n",
      "Epoch 32: accuracy did not improve from 0.87742\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8846 - loss: 0.3479 - val_accuracy: 0.7826 - val_loss: 0.5688\n",
      "Epoch 33/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8709 - loss: 0.4031\n",
      "Epoch 33: accuracy did not improve from 0.87742\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8712 - loss: 0.3956 - val_accuracy: 0.6708 - val_loss: 0.8674\n",
      "Epoch 34/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8461 - loss: 0.4243\n",
      "Epoch 34: accuracy did not improve from 0.87742\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8491 - loss: 0.4163 - val_accuracy: 0.6522 - val_loss: 1.0544\n",
      "Epoch 35/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8763 - loss: 0.3310\n",
      "Epoch 35: accuracy did not improve from 0.87742\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8749 - loss: 0.3392 - val_accuracy: 0.8012 - val_loss: 0.5127\n",
      "Epoch 36/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8664 - loss: 0.3691\n",
      "Epoch 36: accuracy improved from 0.87742 to 0.87820, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.8688 - loss: 0.3663 - val_accuracy: 0.8385 - val_loss: 0.4912\n",
      "Epoch 37/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8534 - loss: 0.3952\n",
      "Epoch 37: accuracy did not improve from 0.87820\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8549 - loss: 0.3900 - val_accuracy: 0.8385 - val_loss: 0.5175\n",
      "Epoch 38/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8605 - loss: 0.3739\n",
      "Epoch 38: accuracy did not improve from 0.87820\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8600 - loss: 0.3758 - val_accuracy: 0.6832 - val_loss: 1.0125\n",
      "Epoch 39/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8624 - loss: 0.3816\n",
      "Epoch 39: accuracy did not improve from 0.87820\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8649 - loss: 0.3773 - val_accuracy: 0.7764 - val_loss: 0.5633\n",
      "Epoch 40/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8899 - loss: 0.3308\n",
      "Epoch 40: accuracy improved from 0.87820 to 0.88208, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.8881 - loss: 0.3299 - val_accuracy: 0.7640 - val_loss: 0.5863\n",
      "Epoch 41/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8882 - loss: 0.3046\n",
      "Epoch 41: accuracy did not improve from 0.88208\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8863 - loss: 0.3104 - val_accuracy: 0.8385 - val_loss: 0.5679\n",
      "Epoch 42/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8766 - loss: 0.3204\n",
      "Epoch 42: accuracy did not improve from 0.88208\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8740 - loss: 0.3277 - val_accuracy: 0.6957 - val_loss: 0.8800\n",
      "Epoch 43/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8893 - loss: 0.3150\n",
      "Epoch 43: accuracy did not improve from 0.88208\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8879 - loss: 0.3191 - val_accuracy: 0.8571 - val_loss: 0.4389\n",
      "Epoch 44/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8749 - loss: 0.3635\n",
      "Epoch 44: accuracy improved from 0.88208 to 0.88673, saving model to best_model_100_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8773 - loss: 0.3556 - val_accuracy: 0.7578 - val_loss: 0.5735\n",
      "Epoch 45/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8754 - loss: 0.3208\n",
      "Epoch 45: accuracy did not improve from 0.88673\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8757 - loss: 0.3227 - val_accuracy: 0.6957 - val_loss: 0.8313\n",
      "Epoch 46/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8630 - loss: 0.3690\n",
      "Epoch 46: accuracy did not improve from 0.88673\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8639 - loss: 0.3672 - val_accuracy: 0.7578 - val_loss: 0.6522\n",
      "Epoch 47/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8866 - loss: 0.3131\n",
      "Epoch 47: accuracy did not improve from 0.88673\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8850 - loss: 0.3153 - val_accuracy: 0.8012 - val_loss: 0.5497\n",
      "Epoch 48/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8658 - loss: 0.3506\n",
      "Epoch 48: accuracy did not improve from 0.88673\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8654 - loss: 0.3519 - val_accuracy: 0.7516 - val_loss: 0.5927\n",
      "Epoch 49/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9006 - loss: 0.2931\n",
      "Epoch 49: accuracy did not improve from 0.88673\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8994 - loss: 0.2952 - val_accuracy: 0.8509 - val_loss: 0.5360\n",
      "Epoch 50/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8787 - loss: 0.3230\n",
      "Epoch 50: accuracy did not improve from 0.88673\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8789 - loss: 0.3238 - val_accuracy: 0.7329 - val_loss: 0.6931\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8199 - loss: 0.4368 \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con embeddings de tamaño: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5006 - loss: 0.9719\n",
      "Epoch 1: accuracy improved from -inf to 0.60047, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 226ms/step - accuracy: 0.5229 - loss: 0.9468 - val_accuracy: 0.5342 - val_loss: 0.8648\n",
      "Epoch 2/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5990 - loss: 0.7707\n",
      "Epoch 2: accuracy improved from 0.60047 to 0.67804, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.6128 - loss: 0.7651 - val_accuracy: 0.7143 - val_loss: 0.7753\n",
      "Epoch 3/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8034 - loss: 0.6533\n",
      "Epoch 3: accuracy improved from 0.67804 to 0.79907, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.8015 - loss: 0.6501 - val_accuracy: 0.7702 - val_loss: 0.6891\n",
      "Epoch 4/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7717 - loss: 0.5852\n",
      "Epoch 4: accuracy improved from 0.79907 to 0.80993, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 0.7778 - loss: 0.5796 - val_accuracy: 0.8075 - val_loss: 0.6277\n",
      "Epoch 5/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8438 - loss: 0.4793\n",
      "Epoch 5: accuracy improved from 0.80993 to 0.83398, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - accuracy: 0.8411 - loss: 0.4817 - val_accuracy: 0.8137 - val_loss: 0.5835\n",
      "Epoch 6/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8184 - loss: 0.4956\n",
      "Epoch 6: accuracy improved from 0.83398 to 0.83863, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.8226 - loss: 0.4861 - val_accuracy: 0.8261 - val_loss: 0.5658\n",
      "Epoch 7/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8252 - loss: 0.4506\n",
      "Epoch 7: accuracy did not improve from 0.83863\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8275 - loss: 0.4464 - val_accuracy: 0.8075 - val_loss: 0.5409\n",
      "Epoch 8/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 0.4405\n",
      "Epoch 8: accuracy improved from 0.83863 to 0.84096, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - accuracy: 0.8351 - loss: 0.4378 - val_accuracy: 0.8199 - val_loss: 0.5331\n",
      "Epoch 9/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8619 - loss: 0.3712\n",
      "Epoch 9: accuracy improved from 0.84096 to 0.84717, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - accuracy: 0.8605 - loss: 0.3742 - val_accuracy: 0.8571 - val_loss: 0.5117\n",
      "Epoch 10/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8440 - loss: 0.4015\n",
      "Epoch 10: accuracy improved from 0.84717 to 0.86036, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 0.8448 - loss: 0.4011 - val_accuracy: 0.8012 - val_loss: 0.5213\n",
      "Epoch 11/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8551 - loss: 0.3755\n",
      "Epoch 11: accuracy improved from 0.86036 to 0.86191, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - accuracy: 0.8570 - loss: 0.3774 - val_accuracy: 0.8137 - val_loss: 0.5054\n",
      "Epoch 12/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8690 - loss: 0.3623\n",
      "Epoch 12: accuracy improved from 0.86191 to 0.86967, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - accuracy: 0.8691 - loss: 0.3636 - val_accuracy: 0.8261 - val_loss: 0.5131\n",
      "Epoch 13/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8729 - loss: 0.3542\n",
      "Epoch 13: accuracy did not improve from 0.86967\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8713 - loss: 0.3569 - val_accuracy: 0.8261 - val_loss: 0.4793\n",
      "Epoch 14/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8506 - loss: 0.3864\n",
      "Epoch 14: accuracy did not improve from 0.86967\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8525 - loss: 0.3830 - val_accuracy: 0.8261 - val_loss: 0.4984\n",
      "Epoch 15/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8856 - loss: 0.3369\n",
      "Epoch 15: accuracy did not improve from 0.86967\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8808 - loss: 0.3452 - val_accuracy: 0.8075 - val_loss: 0.5116\n",
      "Epoch 16/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8685 - loss: 0.3870\n",
      "Epoch 16: accuracy improved from 0.86967 to 0.87975, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.8702 - loss: 0.3797 - val_accuracy: 0.8634 - val_loss: 0.4710\n",
      "Epoch 17/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8825 - loss: 0.3429\n",
      "Epoch 17: accuracy did not improve from 0.87975\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8824 - loss: 0.3427 - val_accuracy: 0.8509 - val_loss: 0.4511\n",
      "Epoch 18/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8841 - loss: 0.3331\n",
      "Epoch 18: accuracy did not improve from 0.87975\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8835 - loss: 0.3328 - val_accuracy: 0.8447 - val_loss: 0.4517\n",
      "Epoch 19/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8944 - loss: 0.3212\n",
      "Epoch 19: accuracy improved from 0.87975 to 0.89294, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - accuracy: 0.8943 - loss: 0.3214 - val_accuracy: 0.8447 - val_loss: 0.4424\n",
      "Epoch 20/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9012 - loss: 0.2974\n",
      "Epoch 20: accuracy did not improve from 0.89294\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8975 - loss: 0.3027 - val_accuracy: 0.8385 - val_loss: 0.4429\n",
      "Epoch 21/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9040 - loss: 0.2945\n",
      "Epoch 21: accuracy improved from 0.89294 to 0.89449, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.9035 - loss: 0.2954 - val_accuracy: 0.8571 - val_loss: 0.4334\n",
      "Epoch 22/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8833 - loss: 0.3280 \n",
      "Epoch 22: accuracy did not improve from 0.89449\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8837 - loss: 0.3264 - val_accuracy: 0.8447 - val_loss: 0.4336\n",
      "Epoch 23/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8844 - loss: 0.3071\n",
      "Epoch 23: accuracy did not improve from 0.89449\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8832 - loss: 0.3081 - val_accuracy: 0.8634 - val_loss: 0.4365\n",
      "Epoch 24/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8980 - loss: 0.2839\n",
      "Epoch 24: accuracy did not improve from 0.89449\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8962 - loss: 0.2893 - val_accuracy: 0.8385 - val_loss: 0.4483\n",
      "Epoch 25/50\n",
      "\u001b[1m29/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8755 - loss: 0.3522\n",
      "Epoch 25: accuracy improved from 0.89449 to 0.90225, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.8843 - loss: 0.3343 - val_accuracy: 0.8385 - val_loss: 0.4587\n",
      "Epoch 26/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8841 - loss: 0.2976\n",
      "Epoch 26: accuracy did not improve from 0.90225\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8855 - loss: 0.2971 - val_accuracy: 0.8571 - val_loss: 0.4077\n",
      "Epoch 27/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8908 - loss: 0.2953\n",
      "Epoch 27: accuracy did not improve from 0.90225\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8913 - loss: 0.2934 - val_accuracy: 0.8323 - val_loss: 0.4772\n",
      "Epoch 28/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9024 - loss: 0.2633\n",
      "Epoch 28: accuracy did not improve from 0.90225\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9010 - loss: 0.2662 - val_accuracy: 0.8571 - val_loss: 0.4003\n",
      "Epoch 29/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9025 - loss: 0.2637\n",
      "Epoch 29: accuracy did not improve from 0.90225\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9014 - loss: 0.2673 - val_accuracy: 0.8509 - val_loss: 0.4025\n",
      "Epoch 30/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8837 - loss: 0.3139\n",
      "Epoch 30: accuracy did not improve from 0.90225\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8851 - loss: 0.3094 - val_accuracy: 0.8447 - val_loss: 0.4053\n",
      "Epoch 31/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8953 - loss: 0.2756\n",
      "Epoch 31: accuracy improved from 0.90225 to 0.90303, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - accuracy: 0.8958 - loss: 0.2746 - val_accuracy: 0.8509 - val_loss: 0.3970\n",
      "Epoch 32/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8998 - loss: 0.2687\n",
      "Epoch 32: accuracy improved from 0.90303 to 0.90846, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - accuracy: 0.9013 - loss: 0.2661 - val_accuracy: 0.8509 - val_loss: 0.3986\n",
      "Epoch 33/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9002 - loss: 0.2696\n",
      "Epoch 33: accuracy did not improve from 0.90846\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9006 - loss: 0.2675 - val_accuracy: 0.8509 - val_loss: 0.3892\n",
      "Epoch 34/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9005 - loss: 0.2529\n",
      "Epoch 34: accuracy did not improve from 0.90846\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8998 - loss: 0.2538 - val_accuracy: 0.8385 - val_loss: 0.4162\n",
      "Epoch 35/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9001 - loss: 0.2705\n",
      "Epoch 35: accuracy did not improve from 0.90846\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9001 - loss: 0.2689 - val_accuracy: 0.8571 - val_loss: 0.3897\n",
      "Epoch 36/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9011 - loss: 0.2494\n",
      "Epoch 36: accuracy did not improve from 0.90846\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9018 - loss: 0.2487 - val_accuracy: 0.8323 - val_loss: 0.3944\n",
      "Epoch 37/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8958 - loss: 0.2670\n",
      "Epoch 37: accuracy did not improve from 0.90846\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8969 - loss: 0.2636 - val_accuracy: 0.8509 - val_loss: 0.3678\n",
      "Epoch 38/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8901 - loss: 0.2834\n",
      "Epoch 38: accuracy did not improve from 0.90846\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8912 - loss: 0.2817 - val_accuracy: 0.8447 - val_loss: 0.3701\n",
      "Epoch 39/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9072 - loss: 0.2486\n",
      "Epoch 39: accuracy did not improve from 0.90846\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9072 - loss: 0.2482 - val_accuracy: 0.8447 - val_loss: 0.3926\n",
      "Epoch 40/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9123 - loss: 0.2389\n",
      "Epoch 40: accuracy improved from 0.90846 to 0.91156, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9124 - loss: 0.2359 - val_accuracy: 0.8509 - val_loss: 0.3778\n",
      "Epoch 41/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9239 - loss: 0.2048\n",
      "Epoch 41: accuracy improved from 0.91156 to 0.92242, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.9238 - loss: 0.2067 - val_accuracy: 0.8571 - val_loss: 0.3606\n",
      "Epoch 42/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8979 - loss: 0.2477\n",
      "Epoch 42: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9014 - loss: 0.2429 - val_accuracy: 0.8509 - val_loss: 0.3788\n",
      "Epoch 43/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8817 - loss: 0.2646\n",
      "Epoch 43: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8850 - loss: 0.2596 - val_accuracy: 0.8509 - val_loss: 0.3530\n",
      "Epoch 44/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9226 - loss: 0.2146\n",
      "Epoch 44: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9194 - loss: 0.2182 - val_accuracy: 0.8509 - val_loss: 0.3908\n",
      "Epoch 45/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8919 - loss: 0.2757\n",
      "Epoch 45: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8940 - loss: 0.2699 - val_accuracy: 0.8634 - val_loss: 0.3686\n",
      "Epoch 46/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9052 - loss: 0.2298\n",
      "Epoch 46: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9063 - loss: 0.2283 - val_accuracy: 0.8696 - val_loss: 0.3275\n",
      "Epoch 47/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8995 - loss: 0.2294\n",
      "Epoch 47: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9014 - loss: 0.2280 - val_accuracy: 0.8634 - val_loss: 0.3552\n",
      "Epoch 48/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9153 - loss: 0.2133\n",
      "Epoch 48: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9148 - loss: 0.2146 - val_accuracy: 0.8571 - val_loss: 0.3691\n",
      "Epoch 49/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9147 - loss: 0.1997\n",
      "Epoch 49: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9150 - loss: 0.2016 - val_accuracy: 0.8509 - val_loss: 0.3118\n",
      "Epoch 50/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9313 - loss: 0.1668\n",
      "Epoch 50: accuracy improved from 0.92242 to 0.92630, saving model to best_model_200_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.9309 - loss: 0.1699 - val_accuracy: 0.8696 - val_loss: 0.3118\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9347 - loss: 0.2244\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Entrenando con embeddings de tamaño: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4780 - loss: 0.9367\n",
      "Epoch 1: accuracy improved from -inf to 0.49806, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 117ms/step - accuracy: 0.4817 - loss: 0.9263 - val_accuracy: 0.5342 - val_loss: 0.8572\n",
      "Epoch 2/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5560 - loss: 0.8265\n",
      "Epoch 2: accuracy improved from 0.49806 to 0.61133, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - accuracy: 0.5664 - loss: 0.8156 - val_accuracy: 0.7267 - val_loss: 0.7923\n",
      "Epoch 3/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7572 - loss: 0.6516\n",
      "Epoch 3: accuracy improved from 0.61133 to 0.76649, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.7574 - loss: 0.6506 - val_accuracy: 0.7888 - val_loss: 0.5891\n",
      "Epoch 4/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8200 - loss: 0.5006\n",
      "Epoch 4: accuracy improved from 0.76649 to 0.82467, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.8204 - loss: 0.4998 - val_accuracy: 0.7888 - val_loss: 0.5302\n",
      "Epoch 5/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8359 - loss: 0.4731\n",
      "Epoch 5: accuracy improved from 0.82467 to 0.82700, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.8347 - loss: 0.4735 - val_accuracy: 0.8323 - val_loss: 0.5198\n",
      "Epoch 6/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8435 - loss: 0.4384\n",
      "Epoch 6: accuracy improved from 0.82700 to 0.84872, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.8436 - loss: 0.4381 - val_accuracy: 0.8075 - val_loss: 0.5401\n",
      "Epoch 7/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8669 - loss: 0.4143\n",
      "Epoch 7: accuracy improved from 0.84872 to 0.85337, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - accuracy: 0.8653 - loss: 0.4155 - val_accuracy: 0.7950 - val_loss: 0.5744\n",
      "Epoch 8/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8555 - loss: 0.4095\n",
      "Epoch 8: accuracy did not improve from 0.85337\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8551 - loss: 0.4108 - val_accuracy: 0.8261 - val_loss: 0.4914\n",
      "Epoch 9/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8613 - loss: 0.3875\n",
      "Epoch 9: accuracy improved from 0.85337 to 0.86656, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.8615 - loss: 0.3873 - val_accuracy: 0.8447 - val_loss: 0.4762\n",
      "Epoch 10/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8653 - loss: 0.3827\n",
      "Epoch 10: accuracy did not improve from 0.86656\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8648 - loss: 0.3823 - val_accuracy: 0.8137 - val_loss: 0.4989\n",
      "Epoch 11/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8377 - loss: 0.4072\n",
      "Epoch 11: accuracy did not improve from 0.86656\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8412 - loss: 0.4020 - val_accuracy: 0.8509 - val_loss: 0.4602\n",
      "Epoch 12/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8841 - loss: 0.3377\n",
      "Epoch 12: accuracy improved from 0.86656 to 0.87587, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.8839 - loss: 0.3378 - val_accuracy: 0.8509 - val_loss: 0.4439\n",
      "Epoch 13/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8803 - loss: 0.3241\n",
      "Epoch 13: accuracy improved from 0.87587 to 0.88285, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - accuracy: 0.8805 - loss: 0.3242 - val_accuracy: 0.8509 - val_loss: 0.4615\n",
      "Epoch 14/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8882 - loss: 0.2992\n",
      "Epoch 14: accuracy did not improve from 0.88285\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8869 - loss: 0.3031 - val_accuracy: 0.8571 - val_loss: 0.4413\n",
      "Epoch 15/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8607 - loss: 0.3877\n",
      "Epoch 15: accuracy did not improve from 0.88285\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8627 - loss: 0.3821 - val_accuracy: 0.8571 - val_loss: 0.4447\n",
      "Epoch 16/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8936 - loss: 0.2999\n",
      "Epoch 16: accuracy did not improve from 0.88285\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8906 - loss: 0.3040 - val_accuracy: 0.8385 - val_loss: 0.4472\n",
      "Epoch 17/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8754 - loss: 0.3122\n",
      "Epoch 17: accuracy did not improve from 0.88285\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8751 - loss: 0.3143 - val_accuracy: 0.8509 - val_loss: 0.4785\n",
      "Epoch 18/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8809 - loss: 0.3051\n",
      "Epoch 18: accuracy improved from 0.88285 to 0.88441, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - accuracy: 0.8813 - loss: 0.3053 - val_accuracy: 0.8323 - val_loss: 0.4114\n",
      "Epoch 19/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8771 - loss: 0.3141\n",
      "Epoch 19: accuracy improved from 0.88441 to 0.89139, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 0.8794 - loss: 0.3111 - val_accuracy: 0.8447 - val_loss: 0.4715\n",
      "Epoch 20/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8910 - loss: 0.2930\n",
      "Epoch 20: accuracy improved from 0.89139 to 0.89372, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - accuracy: 0.8910 - loss: 0.2930 - val_accuracy: 0.8385 - val_loss: 0.4002\n",
      "Epoch 21/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8912 - loss: 0.2898\n",
      "Epoch 21: accuracy did not improve from 0.89372\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8910 - loss: 0.2910 - val_accuracy: 0.8323 - val_loss: 0.4645\n",
      "Epoch 22/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8728 - loss: 0.3315\n",
      "Epoch 22: accuracy improved from 0.89372 to 0.90303, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - accuracy: 0.8771 - loss: 0.3213 - val_accuracy: 0.8634 - val_loss: 0.4007\n",
      "Epoch 23/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8848 - loss: 0.2777\n",
      "Epoch 23: accuracy improved from 0.90303 to 0.90613, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.8868 - loss: 0.2744 - val_accuracy: 0.8447 - val_loss: 0.4300\n",
      "Epoch 24/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9262 - loss: 0.2040\n",
      "Epoch 24: accuracy improved from 0.90613 to 0.91001, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - accuracy: 0.9254 - loss: 0.2059 - val_accuracy: 0.8509 - val_loss: 0.3794\n",
      "Epoch 25/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9030 - loss: 0.2529\n",
      "Epoch 25: accuracy did not improve from 0.91001\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9033 - loss: 0.2523 - val_accuracy: 0.8696 - val_loss: 0.3514\n",
      "Epoch 26/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9228 - loss: 0.2067\n",
      "Epoch 26: accuracy improved from 0.91001 to 0.91466, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.9218 - loss: 0.2099 - val_accuracy: 0.8509 - val_loss: 0.3403\n",
      "Epoch 27/50\n",
      "\u001b[1m29/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8862 - loss: 0.2496\n",
      "Epoch 27: accuracy did not improve from 0.91466\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8854 - loss: 0.2566 - val_accuracy: 0.8571 - val_loss: 0.4930\n",
      "Epoch 28/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9201 - loss: 0.2407\n",
      "Epoch 28: accuracy improved from 0.91466 to 0.92397, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - accuracy: 0.9203 - loss: 0.2404 - val_accuracy: 0.8571 - val_loss: 0.3553\n",
      "Epoch 29/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9127 - loss: 0.2189\n",
      "Epoch 29: accuracy did not improve from 0.92397\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9132 - loss: 0.2187 - val_accuracy: 0.8696 - val_loss: 0.3784\n",
      "Epoch 30/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9205 - loss: 0.1880\n",
      "Epoch 30: accuracy did not improve from 0.92397\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9202 - loss: 0.1897 - val_accuracy: 0.8571 - val_loss: 0.4925\n",
      "Epoch 31/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8945 - loss: 0.2657\n",
      "Epoch 31: accuracy did not improve from 0.92397\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8962 - loss: 0.2629 - val_accuracy: 0.8696 - val_loss: 0.3396\n",
      "Epoch 32/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9075 - loss: 0.2477\n",
      "Epoch 32: accuracy did not improve from 0.92397\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9078 - loss: 0.2470 - val_accuracy: 0.8758 - val_loss: 0.3256\n",
      "Epoch 33/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9266 - loss: 0.1931\n",
      "Epoch 33: accuracy did not improve from 0.92397\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9248 - loss: 0.1972 - val_accuracy: 0.8261 - val_loss: 0.5829\n",
      "Epoch 34/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9088 - loss: 0.2557\n",
      "Epoch 34: accuracy did not improve from 0.92397\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9092 - loss: 0.2541 - val_accuracy: 0.8509 - val_loss: 0.4242\n",
      "Epoch 35/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9003 - loss: 0.2202\n",
      "Epoch 35: accuracy did not improve from 0.92397\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9010 - loss: 0.2204 - val_accuracy: 0.8634 - val_loss: 0.3092\n",
      "Epoch 36/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9238 - loss: 0.2021\n",
      "Epoch 36: accuracy did not improve from 0.92397\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9238 - loss: 0.2019 - val_accuracy: 0.8696 - val_loss: 0.3414\n",
      "Epoch 37/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8832 - loss: 0.2814\n",
      "Epoch 37: accuracy did not improve from 0.92397\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8837 - loss: 0.2806 - val_accuracy: 0.8696 - val_loss: 0.3391\n",
      "Epoch 38/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9174 - loss: 0.2058\n",
      "Epoch 38: accuracy did not improve from 0.92397\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9177 - loss: 0.2049 - val_accuracy: 0.8820 - val_loss: 0.3066\n",
      "Epoch 39/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9327 - loss: 0.1809\n",
      "Epoch 39: accuracy improved from 0.92397 to 0.93018, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.9326 - loss: 0.1811 - val_accuracy: 0.8509 - val_loss: 0.4144\n",
      "Epoch 40/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9254 - loss: 0.1850\n",
      "Epoch 40: accuracy did not improve from 0.93018\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9249 - loss: 0.1872 - val_accuracy: 0.8447 - val_loss: 0.3906\n",
      "Epoch 41/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9403 - loss: 0.1765\n",
      "Epoch 41: accuracy did not improve from 0.93018\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9396 - loss: 0.1772 - val_accuracy: 0.8696 - val_loss: 0.3081\n",
      "Epoch 42/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9252 - loss: 0.1909\n",
      "Epoch 42: accuracy did not improve from 0.93018\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9253 - loss: 0.1909 - val_accuracy: 0.8509 - val_loss: 0.3624\n",
      "Epoch 43/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9303 - loss: 0.1773\n",
      "Epoch 43: accuracy improved from 0.93018 to 0.93095, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9304 - loss: 0.1772 - val_accuracy: 0.8385 - val_loss: 0.5679\n",
      "Epoch 44/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9316 - loss: 0.1768\n",
      "Epoch 44: accuracy did not improve from 0.93095\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9315 - loss: 0.1770 - val_accuracy: 0.8447 - val_loss: 0.3417\n",
      "Epoch 45/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9208 - loss: 0.2599\n",
      "Epoch 45: accuracy did not improve from 0.93095\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9197 - loss: 0.2615 - val_accuracy: 0.8323 - val_loss: 0.5009\n",
      "Epoch 46/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9087 - loss: 0.2441\n",
      "Epoch 46: accuracy did not improve from 0.93095\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9106 - loss: 0.2373 - val_accuracy: 0.8509 - val_loss: 0.4308\n",
      "Epoch 47/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9328 - loss: 0.1887\n",
      "Epoch 47: accuracy did not improve from 0.93095\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9322 - loss: 0.1889 - val_accuracy: 0.8509 - val_loss: 0.4499\n",
      "Epoch 48/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9309 - loss: 0.1877\n",
      "Epoch 48: accuracy improved from 0.93095 to 0.93794, saving model to best_model_200_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9321 - loss: 0.1867 - val_accuracy: 0.8571 - val_loss: 0.4361\n",
      "Epoch 49/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9347 - loss: 0.1583\n",
      "Epoch 49: accuracy did not improve from 0.93794\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9345 - loss: 0.1599 - val_accuracy: 0.8509 - val_loss: 0.4168\n",
      "Epoch 50/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9504 - loss: 0.1342\n",
      "Epoch 50: accuracy did not improve from 0.93794\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9490 - loss: 0.1376 - val_accuracy: 0.8634 - val_loss: 0.3327\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9378 - loss: 0.1931\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Entrenando con embeddings de tamaño: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1268 - loss: 2.0527\n",
      "Epoch 1: accuracy improved from -inf to 0.20481, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 121ms/step - accuracy: 0.1287 - loss: 2.0446 - val_accuracy: 0.6460 - val_loss: 0.9819\n",
      "Epoch 2/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5413 - loss: 0.9454\n",
      "Epoch 2: accuracy improved from 0.20481 to 0.62839, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.5567 - loss: 0.9313 - val_accuracy: 0.7826 - val_loss: 0.8907\n",
      "Epoch 3/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7806 - loss: 0.6400 \n",
      "Epoch 3: accuracy improved from 0.62839 to 0.79209, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - accuracy: 0.7815 - loss: 0.6382 - val_accuracy: 0.7267 - val_loss: 0.8473\n",
      "Epoch 4/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8187 - loss: 0.5316\n",
      "Epoch 4: accuracy improved from 0.79209 to 0.82234, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - accuracy: 0.8190 - loss: 0.5314 - val_accuracy: 0.8261 - val_loss: 0.7537\n",
      "Epoch 5/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8366 - loss: 0.4587\n",
      "Epoch 5: accuracy improved from 0.82234 to 0.83088, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - accuracy: 0.8353 - loss: 0.4604 - val_accuracy: 0.8571 - val_loss: 0.7014\n",
      "Epoch 6/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8544 - loss: 0.4062\n",
      "Epoch 6: accuracy improved from 0.83088 to 0.83398, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.8510 - loss: 0.4150 - val_accuracy: 0.8509 - val_loss: 0.6341\n",
      "Epoch 7/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8373 - loss: 0.4482\n",
      "Epoch 7: accuracy improved from 0.83398 to 0.84329, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.8379 - loss: 0.4467 - val_accuracy: 0.7826 - val_loss: 0.6532\n",
      "Epoch 8/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8486 - loss: 0.4291\n",
      "Epoch 8: accuracy improved from 0.84329 to 0.85027, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.8487 - loss: 0.4273 - val_accuracy: 0.8571 - val_loss: 0.5564\n",
      "Epoch 9/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8338 - loss: 0.4122\n",
      "Epoch 9: accuracy improved from 0.85027 to 0.85415, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.8371 - loss: 0.4101 - val_accuracy: 0.6894 - val_loss: 0.6525\n",
      "Epoch 10/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8515 - loss: 0.3993\n",
      "Epoch 10: accuracy improved from 0.85415 to 0.86889, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.8541 - loss: 0.3964 - val_accuracy: 0.8199 - val_loss: 0.5009\n",
      "Epoch 11/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8577 - loss: 0.3705\n",
      "Epoch 11: accuracy did not improve from 0.86889\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8577 - loss: 0.3724 - val_accuracy: 0.8199 - val_loss: 0.5041\n",
      "Epoch 12/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8743 - loss: 0.3968\n",
      "Epoch 12: accuracy improved from 0.86889 to 0.87432, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 0.8744 - loss: 0.3952 - val_accuracy: 0.8571 - val_loss: 0.5536\n",
      "Epoch 13/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8649 - loss: 0.3624\n",
      "Epoch 13: accuracy did not improve from 0.87432\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8660 - loss: 0.3612 - val_accuracy: 0.8571 - val_loss: 0.4926\n",
      "Epoch 14/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8788 - loss: 0.3192\n",
      "Epoch 14: accuracy did not improve from 0.87432\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8779 - loss: 0.3266 - val_accuracy: 0.8447 - val_loss: 0.5229\n",
      "Epoch 15/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8692 - loss: 0.3622\n",
      "Epoch 15: accuracy did not improve from 0.87432\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8696 - loss: 0.3627 - val_accuracy: 0.8509 - val_loss: 0.4531\n",
      "Epoch 16/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8673 - loss: 0.3772\n",
      "Epoch 16: accuracy improved from 0.87432 to 0.87665, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.8678 - loss: 0.3764 - val_accuracy: 0.8696 - val_loss: 0.4475\n",
      "Epoch 17/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8640 - loss: 0.3693\n",
      "Epoch 17: accuracy did not improve from 0.87665\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8644 - loss: 0.3689 - val_accuracy: 0.7453 - val_loss: 0.9317\n",
      "Epoch 18/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8771 - loss: 0.3445\n",
      "Epoch 18: accuracy improved from 0.87665 to 0.88751, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.8790 - loss: 0.3395 - val_accuracy: 0.8634 - val_loss: 0.4332\n",
      "Epoch 19/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8981 - loss: 0.2969\n",
      "Epoch 19: accuracy improved from 0.88751 to 0.88906, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.8958 - loss: 0.3016 - val_accuracy: 0.8696 - val_loss: 0.4653\n",
      "Epoch 20/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8783 - loss: 0.3176\n",
      "Epoch 20: accuracy did not improve from 0.88906\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8779 - loss: 0.3188 - val_accuracy: 0.8571 - val_loss: 0.4225\n",
      "Epoch 21/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8561 - loss: 0.3549\n",
      "Epoch 21: accuracy did not improve from 0.88906\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8586 - loss: 0.3511 - val_accuracy: 0.8509 - val_loss: 0.4299\n",
      "Epoch 22/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8884 - loss: 0.2998\n",
      "Epoch 22: accuracy did not improve from 0.88906\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8876 - loss: 0.3010 - val_accuracy: 0.8509 - val_loss: 0.4297\n",
      "Epoch 23/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8959 - loss: 0.3168\n",
      "Epoch 23: accuracy did not improve from 0.88906\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8925 - loss: 0.3214 - val_accuracy: 0.8385 - val_loss: 0.4718\n",
      "Epoch 24/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9048 - loss: 0.2806\n",
      "Epoch 24: accuracy improved from 0.88906 to 0.89604, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - accuracy: 0.9044 - loss: 0.2810 - val_accuracy: 0.8509 - val_loss: 0.4553\n",
      "Epoch 25/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9008 - loss: 0.2752\n",
      "Epoch 25: accuracy improved from 0.89604 to 0.89992, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.9005 - loss: 0.2750 - val_accuracy: 0.8385 - val_loss: 0.4806\n",
      "Epoch 26/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8931 - loss: 0.2682\n",
      "Epoch 26: accuracy did not improve from 0.89992\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8929 - loss: 0.2695 - val_accuracy: 0.8075 - val_loss: 0.7033\n",
      "Epoch 27/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9042 - loss: 0.2435\n",
      "Epoch 27: accuracy did not improve from 0.89992\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9029 - loss: 0.2478 - val_accuracy: 0.8323 - val_loss: 0.4274\n",
      "Epoch 28/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9073 - loss: 0.2300\n",
      "Epoch 28: accuracy improved from 0.89992 to 0.90380, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9069 - loss: 0.2337 - val_accuracy: 0.8634 - val_loss: 0.5176\n",
      "Epoch 29/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9149 - loss: 0.2167\n",
      "Epoch 29: accuracy improved from 0.90380 to 0.90458, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - accuracy: 0.9133 - loss: 0.2217 - val_accuracy: 0.8323 - val_loss: 0.3972\n",
      "Epoch 30/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8962 - loss: 0.2763\n",
      "Epoch 30: accuracy did not improve from 0.90458\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8971 - loss: 0.2726 - val_accuracy: 0.7516 - val_loss: 0.8602\n",
      "Epoch 31/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9158 - loss: 0.2433\n",
      "Epoch 31: accuracy did not improve from 0.90458\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9138 - loss: 0.2466 - val_accuracy: 0.7205 - val_loss: 1.1587\n",
      "Epoch 32/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9012 - loss: 0.2780\n",
      "Epoch 32: accuracy did not improve from 0.90458\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9005 - loss: 0.2782 - val_accuracy: 0.8012 - val_loss: 0.5952\n",
      "Epoch 33/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9109 - loss: 0.2323\n",
      "Epoch 33: accuracy did not improve from 0.90458\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9100 - loss: 0.2338 - val_accuracy: 0.7764 - val_loss: 0.7049\n",
      "Epoch 34/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9156 - loss: 0.2152\n",
      "Epoch 34: accuracy improved from 0.90458 to 0.90613, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - accuracy: 0.9138 - loss: 0.2159 - val_accuracy: 0.8509 - val_loss: 0.3907\n",
      "Epoch 35/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9290 - loss: 0.1912\n",
      "Epoch 35: accuracy improved from 0.90613 to 0.92242, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9287 - loss: 0.1918 - val_accuracy: 0.8509 - val_loss: 0.4841\n",
      "Epoch 36/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9061 - loss: 0.2285\n",
      "Epoch 36: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9062 - loss: 0.2285 - val_accuracy: 0.8261 - val_loss: 0.4842\n",
      "Epoch 37/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9172 - loss: 0.2118\n",
      "Epoch 37: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9156 - loss: 0.2197 - val_accuracy: 0.8447 - val_loss: 0.4343\n",
      "Epoch 38/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9091 - loss: 0.2263\n",
      "Epoch 38: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9071 - loss: 0.2300 - val_accuracy: 0.8758 - val_loss: 0.3266\n",
      "Epoch 39/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8741 - loss: 0.2728\n",
      "Epoch 39: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8745 - loss: 0.2725 - val_accuracy: 0.7888 - val_loss: 0.5519\n",
      "Epoch 40/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9126 - loss: 0.2175\n",
      "Epoch 40: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9136 - loss: 0.2170 - val_accuracy: 0.8634 - val_loss: 0.4811\n",
      "Epoch 41/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9174 - loss: 0.1998\n",
      "Epoch 41: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9155 - loss: 0.2045 - val_accuracy: 0.8447 - val_loss: 0.5210\n",
      "Epoch 42/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9222 - loss: 0.1826\n",
      "Epoch 42: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9221 - loss: 0.1838 - val_accuracy: 0.8075 - val_loss: 0.5494\n",
      "Epoch 43/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9041 - loss: 0.2319\n",
      "Epoch 43: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9033 - loss: 0.2343 - val_accuracy: 0.8075 - val_loss: 0.6048\n",
      "Epoch 44/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9117 - loss: 0.2111\n",
      "Epoch 44: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9118 - loss: 0.2112 - val_accuracy: 0.8882 - val_loss: 0.3710\n",
      "Epoch 45/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9398 - loss: 0.1837\n",
      "Epoch 45: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9372 - loss: 0.1867 - val_accuracy: 0.8385 - val_loss: 0.6427\n",
      "Epoch 46/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8849 - loss: 0.2899\n",
      "Epoch 46: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8852 - loss: 0.2893 - val_accuracy: 0.2671 - val_loss: 3.1544\n",
      "Epoch 47/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8878 - loss: 0.2788\n",
      "Epoch 47: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8945 - loss: 0.2678 - val_accuracy: 0.8820 - val_loss: 0.2799\n",
      "Epoch 48/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9234 - loss: 0.1933\n",
      "Epoch 48: accuracy did not improve from 0.92242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9225 - loss: 0.1956 - val_accuracy: 0.8137 - val_loss: 0.6448\n",
      "Epoch 49/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9243 - loss: 0.1755\n",
      "Epoch 49: accuracy improved from 0.92242 to 0.92785, saving model to best_model_200_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.9248 - loss: 0.1779 - val_accuracy: 0.8261 - val_loss: 0.5265\n",
      "Epoch 50/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9292 - loss: 0.1824\n",
      "Epoch 50: accuracy did not improve from 0.92785\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9285 - loss: 0.1824 - val_accuracy: 0.8199 - val_loss: 0.6397\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9111 - loss: 0.3433 \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con embeddings de tamaño: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5103 - loss: 0.9865\n",
      "Epoch 1: accuracy improved from -inf to 0.54538, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 293ms/step - accuracy: 0.5127 - loss: 0.9805 - val_accuracy: 0.8075 - val_loss: 0.8442\n",
      "Epoch 2/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7071 - loss: 0.7614\n",
      "Epoch 2: accuracy improved from 0.54538 to 0.69899, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 175ms/step - accuracy: 0.7070 - loss: 0.7608 - val_accuracy: 0.8137 - val_loss: 0.7727\n",
      "Epoch 3/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7922 - loss: 0.6721\n",
      "Epoch 3: accuracy improved from 0.69899 to 0.81071, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 196ms/step - accuracy: 0.7927 - loss: 0.6711 - val_accuracy: 0.8137 - val_loss: 0.6662\n",
      "Epoch 4/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8032 - loss: 0.5799\n",
      "Epoch 4: accuracy improved from 0.81071 to 0.83165, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 172ms/step - accuracy: 0.8071 - loss: 0.5718 - val_accuracy: 0.7888 - val_loss: 0.5928\n",
      "Epoch 5/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8506 - loss: 0.4648\n",
      "Epoch 5: accuracy improved from 0.83165 to 0.84329, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 193ms/step - accuracy: 0.8498 - loss: 0.4625 - val_accuracy: 0.8075 - val_loss: 0.5534\n",
      "Epoch 6/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8501 - loss: 0.4377\n",
      "Epoch 6: accuracy improved from 0.84329 to 0.84794, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - accuracy: 0.8499 - loss: 0.4357 - val_accuracy: 0.8261 - val_loss: 0.5499\n",
      "Epoch 7/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8481 - loss: 0.4053\n",
      "Epoch 7: accuracy improved from 0.84794 to 0.85337, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 233ms/step - accuracy: 0.8484 - loss: 0.4052 - val_accuracy: 0.8137 - val_loss: 0.5239\n",
      "Epoch 8/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8543 - loss: 0.4260\n",
      "Epoch 8: accuracy improved from 0.85337 to 0.86734, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 191ms/step - accuracy: 0.8553 - loss: 0.4230 - val_accuracy: 0.8199 - val_loss: 0.5132\n",
      "Epoch 9/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8664 - loss: 0.3824\n",
      "Epoch 9: accuracy did not improve from 0.86734\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8664 - loss: 0.3820 - val_accuracy: 0.8261 - val_loss: 0.4845\n",
      "Epoch 10/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8565 - loss: 0.3882\n",
      "Epoch 10: accuracy improved from 0.86734 to 0.87122, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 210ms/step - accuracy: 0.8588 - loss: 0.3853 - val_accuracy: 0.8323 - val_loss: 0.4892\n",
      "Epoch 11/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8721 - loss: 0.3410\n",
      "Epoch 11: accuracy improved from 0.87122 to 0.87355, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 193ms/step - accuracy: 0.8719 - loss: 0.3445 - val_accuracy: 0.8199 - val_loss: 0.5369\n",
      "Epoch 12/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8762 - loss: 0.3630\n",
      "Epoch 12: accuracy improved from 0.87355 to 0.87742, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - accuracy: 0.8764 - loss: 0.3617 - val_accuracy: 0.8447 - val_loss: 0.4630\n",
      "Epoch 13/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8907 - loss: 0.3268\n",
      "Epoch 13: accuracy improved from 0.87742 to 0.88596, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 176ms/step - accuracy: 0.8902 - loss: 0.3270 - val_accuracy: 0.8323 - val_loss: 0.4684\n",
      "Epoch 14/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9019 - loss: 0.3044\n",
      "Epoch 14: accuracy improved from 0.88596 to 0.88906, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 208ms/step - accuracy: 0.9004 - loss: 0.3060 - val_accuracy: 0.8385 - val_loss: 0.4541\n",
      "Epoch 15/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9061 - loss: 0.2927\n",
      "Epoch 15: accuracy improved from 0.88906 to 0.89682, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 224ms/step - accuracy: 0.9052 - loss: 0.2940 - val_accuracy: 0.8634 - val_loss: 0.4413\n",
      "Epoch 16/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8928 - loss: 0.2967\n",
      "Epoch 16: accuracy did not improve from 0.89682\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8924 - loss: 0.2983 - val_accuracy: 0.8447 - val_loss: 0.4283\n",
      "Epoch 17/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8984 - loss: 0.2728\n",
      "Epoch 17: accuracy did not improve from 0.89682\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8981 - loss: 0.2758 - val_accuracy: 0.8447 - val_loss: 0.4188\n",
      "Epoch 18/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9093 - loss: 0.2739\n",
      "Epoch 18: accuracy improved from 0.89682 to 0.90225, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 177ms/step - accuracy: 0.9085 - loss: 0.2754 - val_accuracy: 0.8571 - val_loss: 0.4289\n",
      "Epoch 19/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9047 - loss: 0.2877\n",
      "Epoch 19: accuracy improved from 0.90225 to 0.90613, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 204ms/step - accuracy: 0.9046 - loss: 0.2874 - val_accuracy: 0.8571 - val_loss: 0.4281\n",
      "Epoch 20/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8935 - loss: 0.2882\n",
      "Epoch 20: accuracy did not improve from 0.90613\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8945 - loss: 0.2871 - val_accuracy: 0.8261 - val_loss: 0.4482\n",
      "Epoch 21/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8850 - loss: 0.3010\n",
      "Epoch 21: accuracy did not improve from 0.90613\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8854 - loss: 0.3003 - val_accuracy: 0.8323 - val_loss: 0.5029\n",
      "Epoch 22/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8967 - loss: 0.2870\n",
      "Epoch 22: accuracy did not improve from 0.90613\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8967 - loss: 0.2867 - val_accuracy: 0.8571 - val_loss: 0.3951\n",
      "Epoch 23/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9098 - loss: 0.2574\n",
      "Epoch 23: accuracy did not improve from 0.90613\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9095 - loss: 0.2572 - val_accuracy: 0.8509 - val_loss: 0.4327\n",
      "Epoch 24/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9178 - loss: 0.2377\n",
      "Epoch 24: accuracy improved from 0.90613 to 0.90768, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 174ms/step - accuracy: 0.9166 - loss: 0.2393 - val_accuracy: 0.8634 - val_loss: 0.3915\n",
      "Epoch 25/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9213 - loss: 0.2190\n",
      "Epoch 25: accuracy improved from 0.90768 to 0.91078, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - accuracy: 0.9206 - loss: 0.2203 - val_accuracy: 0.8509 - val_loss: 0.3767\n",
      "Epoch 26/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9160 - loss: 0.2314\n",
      "Epoch 26: accuracy improved from 0.91078 to 0.91699, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - accuracy: 0.9165 - loss: 0.2312 - val_accuracy: 0.8758 - val_loss: 0.3659\n",
      "Epoch 27/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9171 - loss: 0.2187\n",
      "Epoch 27: accuracy did not improve from 0.91699\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9171 - loss: 0.2200 - val_accuracy: 0.8696 - val_loss: 0.3745\n",
      "Epoch 28/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9265 - loss: 0.2055\n",
      "Epoch 28: accuracy improved from 0.91699 to 0.91932, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 169ms/step - accuracy: 0.9260 - loss: 0.2069 - val_accuracy: 0.8634 - val_loss: 0.3827\n",
      "Epoch 29/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9077 - loss: 0.2287\n",
      "Epoch 29: accuracy did not improve from 0.91932\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9082 - loss: 0.2281 - val_accuracy: 0.8634 - val_loss: 0.3564\n",
      "Epoch 30/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9235 - loss: 0.2124\n",
      "Epoch 30: accuracy did not improve from 0.91932\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9231 - loss: 0.2123 - val_accuracy: 0.8820 - val_loss: 0.3400\n",
      "Epoch 31/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9304 - loss: 0.1951\n",
      "Epoch 31: accuracy improved from 0.91932 to 0.92630, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - accuracy: 0.9300 - loss: 0.1952 - val_accuracy: 0.8820 - val_loss: 0.3202\n",
      "Epoch 32/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9190 - loss: 0.2170\n",
      "Epoch 32: accuracy did not improve from 0.92630\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9191 - loss: 0.2160 - val_accuracy: 0.8820 - val_loss: 0.3429\n",
      "Epoch 33/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9405 - loss: 0.1693\n",
      "Epoch 33: accuracy improved from 0.92630 to 0.93251, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - accuracy: 0.9394 - loss: 0.1718 - val_accuracy: 0.8696 - val_loss: 0.3193\n",
      "Epoch 34/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9340 - loss: 0.1794\n",
      "Epoch 34: accuracy did not improve from 0.93251\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9334 - loss: 0.1799 - val_accuracy: 0.8882 - val_loss: 0.2976\n",
      "Epoch 35/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9404 - loss: 0.1672\n",
      "Epoch 35: accuracy improved from 0.93251 to 0.93561, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 159ms/step - accuracy: 0.9401 - loss: 0.1675 - val_accuracy: 0.8882 - val_loss: 0.3057\n",
      "Epoch 36/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9530 - loss: 0.1585\n",
      "Epoch 36: accuracy improved from 0.93561 to 0.94492, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.9525 - loss: 0.1589 - val_accuracy: 0.8820 - val_loss: 0.3189\n",
      "Epoch 37/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9198 - loss: 0.2051\n",
      "Epoch 37: accuracy did not improve from 0.94492\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9213 - loss: 0.2025 - val_accuracy: 0.8385 - val_loss: 0.4596\n",
      "Epoch 38/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9232 - loss: 0.2149\n",
      "Epoch 38: accuracy did not improve from 0.94492\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9242 - loss: 0.2112 - val_accuracy: 0.8634 - val_loss: 0.2878\n",
      "Epoch 39/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9357 - loss: 0.1740\n",
      "Epoch 39: accuracy did not improve from 0.94492\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9360 - loss: 0.1711 - val_accuracy: 0.8820 - val_loss: 0.2776\n",
      "Epoch 40/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9129 - loss: 0.1893\n",
      "Epoch 40: accuracy did not improve from 0.94492\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9200 - loss: 0.1823 - val_accuracy: 0.9006 - val_loss: 0.2789\n",
      "Epoch 41/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9432 - loss: 0.1441\n",
      "Epoch 41: accuracy improved from 0.94492 to 0.94802, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.9442 - loss: 0.1449 - val_accuracy: 0.8944 - val_loss: 0.2631\n",
      "Epoch 42/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9441 - loss: 0.1452\n",
      "Epoch 42: accuracy improved from 0.94802 to 0.94880, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - accuracy: 0.9453 - loss: 0.1438 - val_accuracy: 0.8944 - val_loss: 0.2803\n",
      "Epoch 43/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9421 - loss: 0.1488\n",
      "Epoch 43: accuracy did not improve from 0.94880\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9419 - loss: 0.1485 - val_accuracy: 0.8944 - val_loss: 0.2486\n",
      "Epoch 44/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9528 - loss: 0.1548\n",
      "Epoch 44: accuracy improved from 0.94880 to 0.95112, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - accuracy: 0.9524 - loss: 0.1544 - val_accuracy: 0.8944 - val_loss: 0.2660\n",
      "Epoch 45/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9569 - loss: 0.1260\n",
      "Epoch 45: accuracy improved from 0.95112 to 0.95268, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - accuracy: 0.9567 - loss: 0.1265 - val_accuracy: 0.8882 - val_loss: 0.2509\n",
      "Epoch 46/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9440 - loss: 0.1317\n",
      "Epoch 46: accuracy did not improve from 0.95268\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9433 - loss: 0.1336 - val_accuracy: 0.8944 - val_loss: 0.2549\n",
      "Epoch 47/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9486 - loss: 0.1422\n",
      "Epoch 47: accuracy did not improve from 0.95268\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9485 - loss: 0.1420 - val_accuracy: 0.8634 - val_loss: 0.3293\n",
      "Epoch 48/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9410 - loss: 0.1517\n",
      "Epoch 48: accuracy did not improve from 0.95268\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9433 - loss: 0.1473 - val_accuracy: 0.8882 - val_loss: 0.2621\n",
      "Epoch 49/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9666 - loss: 0.1055\n",
      "Epoch 49: accuracy improved from 0.95268 to 0.96199, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.9663 - loss: 0.1064 - val_accuracy: 0.9006 - val_loss: 0.2314\n",
      "Epoch 50/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9638 - loss: 0.1173\n",
      "Epoch 50: accuracy did not improve from 0.96199\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9636 - loss: 0.1175 - val_accuracy: 0.8758 - val_loss: 0.2695\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9389 - loss: 0.1670\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Entrenando con embeddings de tamaño: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4874 - loss: 0.9324\n",
      "Epoch 1: accuracy improved from -inf to 0.52754, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 167ms/step - accuracy: 0.4937 - loss: 0.9204 - val_accuracy: 0.4037 - val_loss: 0.9125\n",
      "Epoch 2/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5455 - loss: 0.8163\n",
      "Epoch 2: accuracy improved from 0.52754 to 0.61753, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 237ms/step - accuracy: 0.5472 - loss: 0.8152 - val_accuracy: 0.7516 - val_loss: 0.7368\n",
      "Epoch 3/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7658 - loss: 0.6044\n",
      "Epoch 3: accuracy improved from 0.61753 to 0.78355, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 263ms/step - accuracy: 0.7662 - loss: 0.6037 - val_accuracy: 0.8012 - val_loss: 0.5604\n",
      "Epoch 4/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8243 - loss: 0.4695\n",
      "Epoch 4: accuracy improved from 0.78355 to 0.83398, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.8255 - loss: 0.4685 - val_accuracy: 0.8137 - val_loss: 0.5484\n",
      "Epoch 5/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8404 - loss: 0.4236\n",
      "Epoch 5: accuracy improved from 0.83398 to 0.84329, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.8404 - loss: 0.4254 - val_accuracy: 0.8075 - val_loss: 0.5224\n",
      "Epoch 6/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8536 - loss: 0.3973\n",
      "Epoch 6: accuracy improved from 0.84329 to 0.86579, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 186ms/step - accuracy: 0.8544 - loss: 0.3962 - val_accuracy: 0.8261 - val_loss: 0.5121\n",
      "Epoch 7/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8637 - loss: 0.4110\n",
      "Epoch 7: accuracy did not improve from 0.86579\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8638 - loss: 0.4096 - val_accuracy: 0.8385 - val_loss: 0.4672\n",
      "Epoch 8/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8926 - loss: 0.3543\n",
      "Epoch 8: accuracy improved from 0.86579 to 0.87820, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - accuracy: 0.8919 - loss: 0.3556 - val_accuracy: 0.8323 - val_loss: 0.5093\n",
      "Epoch 9/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8511 - loss: 0.4036\n",
      "Epoch 9: accuracy did not improve from 0.87820\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8533 - loss: 0.3983 - val_accuracy: 0.8447 - val_loss: 0.4507\n",
      "Epoch 10/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8851 - loss: 0.3241\n",
      "Epoch 10: accuracy improved from 0.87820 to 0.88829, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 181ms/step - accuracy: 0.8851 - loss: 0.3240 - val_accuracy: 0.8385 - val_loss: 0.4661\n",
      "Epoch 11/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9037 - loss: 0.3156\n",
      "Epoch 11: accuracy did not improve from 0.88829\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9020 - loss: 0.3170 - val_accuracy: 0.8571 - val_loss: 0.4231\n",
      "Epoch 12/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8730 - loss: 0.3414\n",
      "Epoch 12: accuracy improved from 0.88829 to 0.88984, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 179ms/step - accuracy: 0.8749 - loss: 0.3374 - val_accuracy: 0.8447 - val_loss: 0.4298\n",
      "Epoch 13/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8978 - loss: 0.2798\n",
      "Epoch 13: accuracy improved from 0.88984 to 0.90303, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 189ms/step - accuracy: 0.8982 - loss: 0.2789 - val_accuracy: 0.8261 - val_loss: 0.4785\n",
      "Epoch 14/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9011 - loss: 0.2615\n",
      "Epoch 14: accuracy did not improve from 0.90303\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9000 - loss: 0.2634 - val_accuracy: 0.8696 - val_loss: 0.3697\n",
      "Epoch 15/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8909 - loss: 0.2702\n",
      "Epoch 15: accuracy did not improve from 0.90303\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8914 - loss: 0.2692 - val_accuracy: 0.8571 - val_loss: 0.3849\n",
      "Epoch 16/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9356 - loss: 0.2029\n",
      "Epoch 16: accuracy improved from 0.90303 to 0.91699, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 193ms/step - accuracy: 0.9330 - loss: 0.2090 - val_accuracy: 0.8323 - val_loss: 0.4150\n",
      "Epoch 17/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9014 - loss: 0.2650\n",
      "Epoch 17: accuracy did not improve from 0.91699\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9018 - loss: 0.2646 - val_accuracy: 0.8447 - val_loss: 0.4027\n",
      "Epoch 18/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8991 - loss: 0.2498\n",
      "Epoch 18: accuracy did not improve from 0.91699\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8995 - loss: 0.2492 - val_accuracy: 0.8758 - val_loss: 0.3363\n",
      "Epoch 19/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9323 - loss: 0.2002\n",
      "Epoch 19: accuracy improved from 0.91699 to 0.93173, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - accuracy: 0.9323 - loss: 0.2000 - val_accuracy: 0.8447 - val_loss: 0.3752\n",
      "Epoch 20/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9051 - loss: 0.2486\n",
      "Epoch 20: accuracy did not improve from 0.93173\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9077 - loss: 0.2418 - val_accuracy: 0.8820 - val_loss: 0.3029\n",
      "Epoch 21/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9393 - loss: 0.1803\n",
      "Epoch 21: accuracy improved from 0.93173 to 0.93638, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 183ms/step - accuracy: 0.9392 - loss: 0.1796 - val_accuracy: 0.8882 - val_loss: 0.2871\n",
      "Epoch 22/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9236 - loss: 0.1971\n",
      "Epoch 22: accuracy did not improve from 0.93638\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9246 - loss: 0.1929 - val_accuracy: 0.9068 - val_loss: 0.2690\n",
      "Epoch 23/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9439 - loss: 0.1480\n",
      "Epoch 23: accuracy did not improve from 0.93638\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9436 - loss: 0.1492 - val_accuracy: 0.8571 - val_loss: 0.3082\n",
      "Epoch 24/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9203 - loss: 0.1966\n",
      "Epoch 24: accuracy did not improve from 0.93638\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9213 - loss: 0.1948 - val_accuracy: 0.9006 - val_loss: 0.2804\n",
      "Epoch 25/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9559 - loss: 0.1385\n",
      "Epoch 25: accuracy improved from 0.93638 to 0.94414, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - accuracy: 0.9553 - loss: 0.1399 - val_accuracy: 0.8696 - val_loss: 0.3654\n",
      "Epoch 26/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9445 - loss: 0.1525\n",
      "Epoch 26: accuracy did not improve from 0.94414\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9439 - loss: 0.1541 - val_accuracy: 0.8758 - val_loss: 0.3038\n",
      "Epoch 27/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9556 - loss: 0.1342\n",
      "Epoch 27: accuracy improved from 0.94414 to 0.95190, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 158ms/step - accuracy: 0.9554 - loss: 0.1344 - val_accuracy: 0.8944 - val_loss: 0.2445\n",
      "Epoch 28/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9529 - loss: 0.1257\n",
      "Epoch 28: accuracy improved from 0.95190 to 0.95268, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.9529 - loss: 0.1268 - val_accuracy: 0.9068 - val_loss: 0.2736\n",
      "Epoch 29/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9427 - loss: 0.1329\n",
      "Epoch 29: accuracy improved from 0.95268 to 0.95811, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - accuracy: 0.9451 - loss: 0.1319 - val_accuracy: 0.8758 - val_loss: 0.3211\n",
      "Epoch 30/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9649 - loss: 0.0937\n",
      "Epoch 30: accuracy did not improve from 0.95811\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9645 - loss: 0.0947 - val_accuracy: 0.9068 - val_loss: 0.2485\n",
      "Epoch 31/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9596 - loss: 0.1137\n",
      "Epoch 31: accuracy improved from 0.95811 to 0.96199, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - accuracy: 0.9600 - loss: 0.1137 - val_accuracy: 0.9255 - val_loss: 0.3104\n",
      "Epoch 32/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9587 - loss: 0.1412\n",
      "Epoch 32: accuracy did not improve from 0.96199\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9579 - loss: 0.1407 - val_accuracy: 0.8820 - val_loss: 0.2807\n",
      "Epoch 33/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9377 - loss: 0.1542\n",
      "Epoch 33: accuracy did not improve from 0.96199\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.1547 - val_accuracy: 0.9193 - val_loss: 0.2945\n",
      "Epoch 34/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9631 - loss: 0.1192\n",
      "Epoch 34: accuracy improved from 0.96199 to 0.96354, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - accuracy: 0.9631 - loss: 0.1186 - val_accuracy: 0.8882 - val_loss: 0.3345\n",
      "Epoch 35/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9427 - loss: 0.1543\n",
      "Epoch 35: accuracy did not improve from 0.96354\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9432 - loss: 0.1528 - val_accuracy: 0.9193 - val_loss: 0.3187\n",
      "Epoch 36/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9619 - loss: 0.1016\n",
      "Epoch 36: accuracy did not improve from 0.96354\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9611 - loss: 0.1031 - val_accuracy: 0.8758 - val_loss: 0.3684\n",
      "Epoch 37/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9565 - loss: 0.1255\n",
      "Epoch 37: accuracy did not improve from 0.96354\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9564 - loss: 0.1259 - val_accuracy: 0.9193 - val_loss: 0.2480\n",
      "Epoch 38/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9623 - loss: 0.1041\n",
      "Epoch 38: accuracy improved from 0.96354 to 0.96974, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 161ms/step - accuracy: 0.9634 - loss: 0.1020 - val_accuracy: 0.8944 - val_loss: 0.3145\n",
      "Epoch 39/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9565 - loss: 0.1300\n",
      "Epoch 39: accuracy did not improve from 0.96974\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9593 - loss: 0.1246 - val_accuracy: 0.9130 - val_loss: 0.2576\n",
      "Epoch 40/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9751 - loss: 0.0791\n",
      "Epoch 40: accuracy did not improve from 0.96974\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9739 - loss: 0.0815 - val_accuracy: 0.8944 - val_loss: 0.2602\n",
      "Epoch 41/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9589 - loss: 0.1010\n",
      "Epoch 41: accuracy did not improve from 0.96974\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9594 - loss: 0.1010 - val_accuracy: 0.9068 - val_loss: 0.2934\n",
      "Epoch 42/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9736 - loss: 0.0785\n",
      "Epoch 42: accuracy did not improve from 0.96974\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9727 - loss: 0.0794 - val_accuracy: 0.9068 - val_loss: 0.2820\n",
      "Epoch 43/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9703 - loss: 0.0869\n",
      "Epoch 43: accuracy improved from 0.96974 to 0.97207, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - accuracy: 0.9706 - loss: 0.0858 - val_accuracy: 0.9006 - val_loss: 0.3176\n",
      "Epoch 44/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9721 - loss: 0.0751\n",
      "Epoch 44: accuracy did not improve from 0.97207\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9720 - loss: 0.0773 - val_accuracy: 0.9006 - val_loss: 0.2475\n",
      "Epoch 45/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9644 - loss: 0.0988\n",
      "Epoch 45: accuracy did not improve from 0.97207\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9647 - loss: 0.0975 - val_accuracy: 0.9006 - val_loss: 0.2762\n",
      "Epoch 46/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9598 - loss: 0.1086\n",
      "Epoch 46: accuracy did not improve from 0.97207\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9592 - loss: 0.1103 - val_accuracy: 0.8696 - val_loss: 0.3495\n",
      "Epoch 47/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9755 - loss: 0.0763\n",
      "Epoch 47: accuracy improved from 0.97207 to 0.97595, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - accuracy: 0.9756 - loss: 0.0760 - val_accuracy: 0.9130 - val_loss: 0.2777\n",
      "Epoch 48/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9724 - loss: 0.0740\n",
      "Epoch 48: accuracy improved from 0.97595 to 0.97905, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - accuracy: 0.9727 - loss: 0.0735 - val_accuracy: 0.9068 - val_loss: 0.3495\n",
      "Epoch 49/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9682 - loss: 0.0812\n",
      "Epoch 49: accuracy did not improve from 0.97905\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9690 - loss: 0.0805 - val_accuracy: 0.8758 - val_loss: 0.3749\n",
      "Epoch 50/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9311 - loss: 0.1643\n",
      "Epoch 50: accuracy did not improve from 0.97905\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9343 - loss: 0.1581 - val_accuracy: 0.8820 - val_loss: 0.3221\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9026 - loss: 0.2641\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Entrenando con embeddings de tamaño: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.4332 - loss: 1.1896\n",
      "Epoch 1: accuracy improved from -inf to 0.55547, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 426ms/step - accuracy: 0.4446 - loss: 1.1707 - val_accuracy: 0.5342 - val_loss: 0.9520\n",
      "Epoch 2/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7452 - loss: 0.6753\n",
      "Epoch 2: accuracy improved from 0.55547 to 0.74399, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 240ms/step - accuracy: 0.7450 - loss: 0.6727 - val_accuracy: 0.8012 - val_loss: 0.8606\n",
      "Epoch 3/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8068 - loss: 0.5112\n",
      "Epoch 3: accuracy improved from 0.74399 to 0.80217, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 244ms/step - accuracy: 0.8059 - loss: 0.5129 - val_accuracy: 0.7950 - val_loss: 0.8266\n",
      "Epoch 4/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8189 - loss: 0.4876\n",
      "Epoch 4: accuracy improved from 0.80217 to 0.82545, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - accuracy: 0.8194 - loss: 0.4867 - val_accuracy: 0.7205 - val_loss: 0.7924\n",
      "Epoch 5/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8314 - loss: 0.4472\n",
      "Epoch 5: accuracy improved from 0.82545 to 0.84019, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.8322 - loss: 0.4469 - val_accuracy: 0.7205 - val_loss: 0.6934\n",
      "Epoch 6/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8594 - loss: 0.4132\n",
      "Epoch 6: accuracy improved from 0.84019 to 0.85570, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 177ms/step - accuracy: 0.8592 - loss: 0.4141 - val_accuracy: 0.8323 - val_loss: 0.5916\n",
      "Epoch 7/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8689 - loss: 0.3852\n",
      "Epoch 7: accuracy improved from 0.85570 to 0.86811, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 195ms/step - accuracy: 0.8685 - loss: 0.3863 - val_accuracy: 0.8137 - val_loss: 0.5438\n",
      "Epoch 8/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9001 - loss: 0.3086\n",
      "Epoch 8: accuracy did not improve from 0.86811\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8986 - loss: 0.3123 - val_accuracy: 0.8385 - val_loss: 0.4953\n",
      "Epoch 9/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8845 - loss: 0.3240\n",
      "Epoch 9: accuracy improved from 0.86811 to 0.87898, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - accuracy: 0.8843 - loss: 0.3245 - val_accuracy: 0.8447 - val_loss: 0.4816\n",
      "Epoch 10/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8891 - loss: 0.3416\n",
      "Epoch 10: accuracy improved from 0.87898 to 0.88984, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 187ms/step - accuracy: 0.8892 - loss: 0.3399 - val_accuracy: 0.7516 - val_loss: 0.5880\n",
      "Epoch 11/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8880 - loss: 0.3333\n",
      "Epoch 11: accuracy did not improve from 0.88984\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8872 - loss: 0.3343 - val_accuracy: 0.8323 - val_loss: 0.5072\n",
      "Epoch 12/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8690 - loss: 0.3686\n",
      "Epoch 12: accuracy did not improve from 0.88984\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8705 - loss: 0.3651 - val_accuracy: 0.8696 - val_loss: 0.4743\n",
      "Epoch 13/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8939 - loss: 0.3151\n",
      "Epoch 13: accuracy did not improve from 0.88984\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8932 - loss: 0.3157 - val_accuracy: 0.8509 - val_loss: 0.4247\n",
      "Epoch 14/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8730 - loss: 0.3523\n",
      "Epoch 14: accuracy did not improve from 0.88984\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8752 - loss: 0.3464 - val_accuracy: 0.8323 - val_loss: 0.4044\n",
      "Epoch 15/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8932 - loss: 0.3182\n",
      "Epoch 15: accuracy improved from 0.88984 to 0.90225, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 167ms/step - accuracy: 0.8942 - loss: 0.3150 - val_accuracy: 0.8634 - val_loss: 0.5002\n",
      "Epoch 16/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9253 - loss: 0.2283\n",
      "Epoch 16: accuracy did not improve from 0.90225\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9214 - loss: 0.2348 - val_accuracy: 0.8385 - val_loss: 0.5306\n",
      "Epoch 17/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8879 - loss: 0.2912\n",
      "Epoch 17: accuracy did not improve from 0.90225\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8892 - loss: 0.2901 - val_accuracy: 0.7826 - val_loss: 0.7009\n",
      "Epoch 18/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9002 - loss: 0.2915\n",
      "Epoch 18: accuracy improved from 0.90225 to 0.91078, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 195ms/step - accuracy: 0.9014 - loss: 0.2906 - val_accuracy: 0.8571 - val_loss: 0.3795\n",
      "Epoch 19/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9109 - loss: 0.2752\n",
      "Epoch 19: accuracy did not improve from 0.91078\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9090 - loss: 0.2775 - val_accuracy: 0.5901 - val_loss: 1.7791\n",
      "Epoch 20/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8889 - loss: 0.2776\n",
      "Epoch 20: accuracy did not improve from 0.91078\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8891 - loss: 0.2789 - val_accuracy: 0.7453 - val_loss: 0.9556\n",
      "Epoch 21/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8962 - loss: 0.3207\n",
      "Epoch 21: accuracy did not improve from 0.91078\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8969 - loss: 0.3173 - val_accuracy: 0.8634 - val_loss: 0.4575\n",
      "Epoch 22/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8932 - loss: 0.2878\n",
      "Epoch 22: accuracy did not improve from 0.91078\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8931 - loss: 0.2882 - val_accuracy: 0.7391 - val_loss: 0.9740\n",
      "Epoch 23/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9179 - loss: 0.2185\n",
      "Epoch 23: accuracy improved from 0.91078 to 0.92785, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 192ms/step - accuracy: 0.9192 - loss: 0.2160 - val_accuracy: 0.8634 - val_loss: 0.4365\n",
      "Epoch 24/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9296 - loss: 0.1922\n",
      "Epoch 24: accuracy did not improve from 0.92785\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9292 - loss: 0.1936 - val_accuracy: 0.8696 - val_loss: 0.5090\n",
      "Epoch 25/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9294 - loss: 0.2299\n",
      "Epoch 25: accuracy did not improve from 0.92785\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9291 - loss: 0.2289 - val_accuracy: 0.8634 - val_loss: 0.5338\n",
      "Epoch 26/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9158 - loss: 0.2225\n",
      "Epoch 26: accuracy did not improve from 0.92785\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9159 - loss: 0.2229 - val_accuracy: 0.8634 - val_loss: 0.3731\n",
      "Epoch 27/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9078 - loss: 0.2291\n",
      "Epoch 27: accuracy did not improve from 0.92785\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9080 - loss: 0.2280 - val_accuracy: 0.8199 - val_loss: 0.6900\n",
      "Epoch 28/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9266 - loss: 0.2162\n",
      "Epoch 28: accuracy did not improve from 0.92785\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9266 - loss: 0.2159 - val_accuracy: 0.7578 - val_loss: 0.5109\n",
      "Epoch 29/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9569 - loss: 0.1647\n",
      "Epoch 29: accuracy improved from 0.92785 to 0.94414, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 195ms/step - accuracy: 0.9547 - loss: 0.1680 - val_accuracy: 0.8758 - val_loss: 0.2829\n",
      "Epoch 30/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9363 - loss: 0.1617\n",
      "Epoch 30: accuracy did not improve from 0.94414\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9368 - loss: 0.1612 - val_accuracy: 0.8385 - val_loss: 0.4417\n",
      "Epoch 31/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9156 - loss: 0.2165\n",
      "Epoch 31: accuracy did not improve from 0.94414\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9157 - loss: 0.2163 - val_accuracy: 0.8571 - val_loss: 0.4334\n",
      "Epoch 32/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9448 - loss: 0.1465\n",
      "Epoch 32: accuracy improved from 0.94414 to 0.94569, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 170ms/step - accuracy: 0.9452 - loss: 0.1462 - val_accuracy: 0.8634 - val_loss: 0.3413\n",
      "Epoch 33/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9293 - loss: 0.1935\n",
      "Epoch 33: accuracy did not improve from 0.94569\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9289 - loss: 0.1933 - val_accuracy: 0.8696 - val_loss: 0.3532\n",
      "Epoch 34/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9407 - loss: 0.1425\n",
      "Epoch 34: accuracy did not improve from 0.94569\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9408 - loss: 0.1433 - val_accuracy: 0.8820 - val_loss: 0.2784\n",
      "Epoch 35/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9574 - loss: 0.1259\n",
      "Epoch 35: accuracy improved from 0.94569 to 0.94957, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 181ms/step - accuracy: 0.9562 - loss: 0.1323 - val_accuracy: 0.7950 - val_loss: 0.5355\n",
      "Epoch 36/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9601 - loss: 0.1276\n",
      "Epoch 36: accuracy did not improve from 0.94957\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9579 - loss: 0.1324 - val_accuracy: 0.7453 - val_loss: 0.7951\n",
      "Epoch 37/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9342 - loss: 0.1697\n",
      "Epoch 37: accuracy did not improve from 0.94957\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9344 - loss: 0.1694 - val_accuracy: 0.8634 - val_loss: 0.2864\n",
      "Epoch 38/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9643 - loss: 0.1083\n",
      "Epoch 38: accuracy did not improve from 0.94957\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9632 - loss: 0.1110 - val_accuracy: 0.8696 - val_loss: 0.3412\n",
      "Epoch 39/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9275 - loss: 0.1914\n",
      "Epoch 39: accuracy did not improve from 0.94957\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9276 - loss: 0.1904 - val_accuracy: 0.8385 - val_loss: 0.4727\n",
      "Epoch 40/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9216 - loss: 0.2138\n",
      "Epoch 40: accuracy did not improve from 0.94957\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9213 - loss: 0.2135 - val_accuracy: 0.9006 - val_loss: 0.2872\n",
      "Epoch 41/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9273 - loss: 0.1832\n",
      "Epoch 41: accuracy did not improve from 0.94957\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9276 - loss: 0.1834 - val_accuracy: 0.8385 - val_loss: 0.5298\n",
      "Epoch 42/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8836 - loss: 0.2797\n",
      "Epoch 42: accuracy did not improve from 0.94957\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8851 - loss: 0.2788 - val_accuracy: 0.8882 - val_loss: 0.2558\n",
      "Epoch 43/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9126 - loss: 0.1901\n",
      "Epoch 43: accuracy did not improve from 0.94957\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9133 - loss: 0.1899 - val_accuracy: 0.8820 - val_loss: 0.3281\n",
      "Epoch 44/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9288 - loss: 0.1797\n",
      "Epoch 44: accuracy did not improve from 0.94957\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9287 - loss: 0.1798 - val_accuracy: 0.7702 - val_loss: 0.6893\n",
      "Epoch 45/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9535 - loss: 0.1157\n",
      "Epoch 45: accuracy did not improve from 0.94957\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9520 - loss: 0.1187 - val_accuracy: 0.5776 - val_loss: 1.5609\n",
      "Epoch 46/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9250 - loss: 0.2073\n",
      "Epoch 46: accuracy did not improve from 0.94957\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9254 - loss: 0.2055 - val_accuracy: 0.1118 - val_loss: 4.5921\n",
      "Epoch 47/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9390 - loss: 0.1541\n",
      "Epoch 47: accuracy did not improve from 0.94957\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9386 - loss: 0.1558 - val_accuracy: 0.7888 - val_loss: 0.6074\n",
      "Epoch 48/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9395 - loss: 0.1748\n",
      "Epoch 48: accuracy did not improve from 0.94957\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9400 - loss: 0.1729 - val_accuracy: 0.8137 - val_loss: 0.5875\n",
      "Epoch 49/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9240 - loss: 0.1637\n",
      "Epoch 49: accuracy did not improve from 0.94957\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9240 - loss: 0.1639 - val_accuracy: 0.8447 - val_loss: 0.4566\n",
      "Epoch 50/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9497 - loss: 0.1329\n",
      "Epoch 50: accuracy did not improve from 0.94957\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9485 - loss: 0.1356 - val_accuracy: 0.9068 - val_loss: 0.1972\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9299 - loss: 0.2386\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Results for embeddings size 100_simple:\n",
      "Accuracy: 0.9012345671653748\n",
      "Precision: 0.8767976979847346\n",
      "Recall: 0.9012345679012346\n",
      "F1 Score: 0.8870378471209617\n",
      "Results for embeddings size 100_deep:\n",
      "Accuracy: 0.9074074029922485\n",
      "Precision: 0.8825315737193132\n",
      "Recall: 0.9074074074074074\n",
      "F1 Score: 0.8931713608580291\n",
      "Results for embeddings size 100_batchNorm:\n",
      "Accuracy: 0.8024691343307495\n",
      "Precision: 0.8229950818026698\n",
      "Recall: 0.8024691358024691\n",
      "F1 Score: 0.7803771283522063\n",
      "Results for embeddings size 200_simple:\n",
      "Accuracy: 0.9382715821266174\n",
      "Precision: 0.9358190035273369\n",
      "Recall: 0.9382716049382716\n",
      "F1 Score: 0.9354254660912209\n",
      "Results for embeddings size 200_deep:\n",
      "Accuracy: 0.9444444179534912\n",
      "Precision: 0.9438727992821561\n",
      "Recall: 0.9444444444444444\n",
      "F1 Score: 0.9434441943819288\n",
      "Results for embeddings size 200_batchNorm:\n",
      "Accuracy: 0.895061731338501\n",
      "Precision: 0.8777316257067035\n",
      "Recall: 0.8950617283950617\n",
      "F1 Score: 0.8799725651577505\n",
      "Results for embeddings size 300_simple:\n",
      "Accuracy: 0.9444444179534912\n",
      "Precision: 0.945425194931774\n",
      "Recall: 0.9444444444444444\n",
      "F1 Score: 0.9430523644681352\n",
      "Results for embeddings size 300_deep:\n",
      "Accuracy: 0.9197530746459961\n",
      "Precision: 0.9245691474607137\n",
      "Recall: 0.9197530864197531\n",
      "F1 Score: 0.9198139025725232\n",
      "Results for embeddings size 300_batchNorm:\n",
      "Accuracy: 0.9382715821266174\n",
      "Precision: 0.9383221850613155\n",
      "Recall: 0.9382716049382716\n",
      "F1 Score: 0.9382584728807563\n"
     ]
    }
   ],
   "source": [
    "####### \n",
    "## EJECUCIÓN\n",
    "####### \n",
    "\n",
    "results = {} \n",
    "embeddings = {'100': glove_vectors100, '200': glove_vectors200, '300': glove_vectors300}  # Incluye 100 y 200 dimensiones\n",
    "\n",
    "for size, glove_vector in embeddings.items():  # Ciclamos por cada embedding\n",
    "    size = int(size)\n",
    "    word2vecModel = glove_vector  # Usamos el embedding correspondiente\n",
    "    vocab_size = len(word2vecModel.key_to_index)  # Tamaño del vocabulario\n",
    "    tokenizer = Tokenizer(num_words=vocab_size)\n",
    "    \n",
    "    # Cargamos y procesamos los datos\n",
    "    texts, labels = load_books_data()\n",
    "    dataset = create_dataset(texts, labels)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        dataset['text'], dataset['author'], test_size=0.2, random_state=42)\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    encoder = LabelEncoder()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_val = encoder.transform(y_val)\n",
    "    y_test = encoder.transform(y_test)\n",
    "\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_val = tokenizer.texts_to_sequences(X_val)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "    max_length = 200\n",
    "    X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
    "    X_val = pad_sequences(X_val, maxlen=max_length, padding='post')\n",
    "    X_test = pad_sequences(X_test, maxlen=max_length, padding='post')\n",
    "\n",
    "    # Construir la matriz de embeddings\n",
    "    embedding_matrix = np.zeros((vocab_size, size))\n",
    "    for word, index in word2vecModel.key_to_index.items():\n",
    "        embedding_matrix[index] = word2vecModel[word]\n",
    "    \n",
    "    # Entrenar y evaluar cada arquitectura\n",
    "    for modelToTrain in [build_simple_model, build_deep_model, build_batchnorm_model]:\n",
    "        print(f\"Entrenando con embeddings de tamaño: {size}\")\n",
    "        \n",
    "        model, arquitectureLabel = modelToTrain(vocab_size, size, embedding_matrix)\n",
    "        history = compile_and_train_model(model, X_train, y_train, X_val, y_val, size, arquitectureLabel)\n",
    "\n",
    "        # Evaluación del modelo en el conjunto de prueba\n",
    "        test_loss, test_accuracy = history.model.evaluate(X_test, y_test)\n",
    "        \n",
    "        # Predicciones\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # Calcular precisión, recall y f1\n",
    "        precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "        # Guardar los resultados\n",
    "        results[f\"{size}_{arquitectureLabel}\"] = {\n",
    "            \"accuracy\": test_accuracy,\n",
    "            \"loss\": test_loss,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1\n",
    "        }\n",
    "\n",
    "# Mostrar resultados finales\n",
    "for size, metrics in results.items():\n",
    "    print(f\"Results for embeddings size {size}:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']}\")\n",
    "    print(f\"Precision: {metrics['precision']}\")\n",
    "    print(f\"Recall: {metrics['recall']}\")\n",
    "    print(f\"F1 Score: {metrics['f1_score']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la evidencia de las metricas de evaluación para cada modelo considerando las dimensiones parametrizadas en un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100_simple</th>\n",
       "      <td>0.901235</td>\n",
       "      <td>0.291391</td>\n",
       "      <td>0.876798</td>\n",
       "      <td>0.901235</td>\n",
       "      <td>0.887038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100_deep</th>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.237394</td>\n",
       "      <td>0.882532</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100_batchNorm</th>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.463522</td>\n",
       "      <td>0.822995</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.780377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200_simple</th>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.208503</td>\n",
       "      <td>0.935819</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.935425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200_deep</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.177741</td>\n",
       "      <td>0.943873</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.943444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200_batchNorm</th>\n",
       "      <td>0.895062</td>\n",
       "      <td>0.346304</td>\n",
       "      <td>0.877732</td>\n",
       "      <td>0.895062</td>\n",
       "      <td>0.879973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300_simple</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.153524</td>\n",
       "      <td>0.945425</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.943052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300_deep</th>\n",
       "      <td>0.919753</td>\n",
       "      <td>0.220006</td>\n",
       "      <td>0.924569</td>\n",
       "      <td>0.919753</td>\n",
       "      <td>0.919814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300_batchNorm</th>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.207567</td>\n",
       "      <td>0.938322</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.938258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy      loss  precision    recall  f1_score\n",
       "100_simple     0.901235  0.291391   0.876798  0.901235  0.887038\n",
       "100_deep       0.907407  0.237394   0.882532  0.907407  0.893171\n",
       "100_batchNorm  0.802469  0.463522   0.822995  0.802469  0.780377\n",
       "200_simple     0.938272  0.208503   0.935819  0.938272  0.935425\n",
       "200_deep       0.944444  0.177741   0.943873  0.944444  0.943444\n",
       "200_batchNorm  0.895062  0.346304   0.877732  0.895062  0.879973\n",
       "300_simple     0.944444  0.153524   0.945425  0.944444  0.943052\n",
       "300_deep       0.919753  0.220006   0.924569  0.919753  0.919814\n",
       "300_batchNorm  0.938272  0.207567   0.938322  0.938272  0.938258"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convertir los resultados a un DataFrame\n",
    "df_results = pd.DataFrame(results).T\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "pd.DataFrame(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se generan las graficas de evaluación de metricas de los modelos considerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Función para graficar los resultados\n",
    "def plot_metrics(results):\n",
    "    # Extraer los tamaños de embedding y arquitecturas\n",
    "    sizes = list(results.keys())\n",
    "    accuracies = [results[size][\"accuracy\"] for size in sizes]\n",
    "    precisions = [results[size][\"precision\"] for size in sizes]\n",
    "    recalls = [results[size][\"recall\"] for size in sizes]\n",
    "    f1_scores = [results[size][\"f1_score\"] for size in sizes]\n",
    "\n",
    "    # Crear la figura y los ejes para las gráficas\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Graficar la métrica de exactitud\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.bar(sizes, accuracies, color='b')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Graficar la métrica de precisión\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.bar(sizes, precisions, color='g')\n",
    "    plt.title('Precision')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Graficar la métrica de recall\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.bar(sizes, recalls, color='r')\n",
    "    plt.title('Recall')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Graficar la métrica de F1 Score\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.bar(sizes, f1_scores, color='y')\n",
    "    plt.title('F1 Score')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Graficar resultados\n",
    "plot_metrics(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
