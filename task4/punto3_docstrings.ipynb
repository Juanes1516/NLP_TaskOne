{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 3\n",
    "\n",
    "Entrenar una red neuronal para clasificación de palabras. Utiliza los embeddings previamente generados para entrenar una red neuronal simple que clasifique palabras según su contexto o relación con los personajes principales en los textos. \n",
    "La arquitectura de la red debe incluir una capa de embeddings, seguida de capas de densidad totalmente conectadas (fully connected), con una función de activación relu en cada capa oculta, y una función de activación softmax en la capa de salida.\n",
    "Se deben dividir los datos en conjuntos de entrenamiento y prueba, y reportar las métricas de rendimiento (precisión, recall, y F1) para evaluar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importación de bibliotecas y dependencias a usar en el ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import string\n",
    "from sklearn.calibration import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación de esta función está diseñada para limpiar el texto de los libros del Proyecto Gutenberg, eliminando marcas específicas del Proyecto, los nombres de autores y otras secciones que no son relevantes para el análisis. Esto deja un texto más puro que puede ser procesado posteriormente para tareas como el análisis de texto, tokenización, o modelado de lenguaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gutenberg_text(text):\n",
    "    # Eliminar el encabezado del Proyecto Gutenberg que aparece al inicio del libro\n",
    "    text = re.sub(r'^.*?\\*\\*\\* START OF THE PROJECT GUTENBERG EBOOK.*?\\*\\*\\*', '', text, flags=re.DOTALL)\n",
    "    # Eliminar el pie del Proyecto Gutenberg que aparece al final del libro\n",
    "    text = re.sub(r'\\*\\*\\* END OF THE PROJECT GUTENBERG EBOOK.*?$', '', text, flags=re.DOTALL)\n",
    "    authors = r'William Oberfield|James Branch Cabell|Wilhelm Raabe'\n",
    "    # Eliminar menciones de autores específicos y las líneas relacionadas con ellos\n",
    "    text = re.sub(r'(?i)\\b(?:' + authors + r')\\b.*?(?=\\n)', '', text, flags=re.DOTALL)\n",
    "    # Eliminar las secciones de producción, metadatos y créditos del libro\n",
    "    text = re.sub(r'(Produced by.*?Distributed Proofreaders|Title:.*?Author:.*?Release date:.*?Language:.*?Credits:.*?Project Gutenberg Distributed Proofreaders)', '', text, flags=re.DOTALL)\n",
    "    # Eliminar las secciones de contenido, bibliografía e índice\n",
    "    text = re.sub(r'(CONTENTS.*?THE AFTERWORD|BIBLIOGRAPHY|INDEX)', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta implementación, cumple dos propósitos:\n",
    "\n",
    "1. La función load_embeddings carga los archivos de embeddings usando KeyedVectors.\n",
    "2. El diccionario embedding_file_paths guarda las rutas de los archivos de embeddings para tres tamaños (300, 400, 500 dimensiones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(file_path):\n",
    "    return KeyedVectors.load(file_path)\n",
    "\n",
    "embedding_file_paths = {\n",
    "    300: 'Books_300_G4.model',\n",
    "    400: 'Books_400_G4.model',\n",
    "    500: 'Books_500_G4.model', \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función split_into_segments toma un texto largo y lo divide en segmentos de un tamaño de palabras fijo.\n",
    "El tamaño de los segmentos se controla mediante el parámetro segment_size.\n",
    "Esta implementación es útil cuando se quiere dividir un texto largo en partes manejables para procesamiento posterior, como en tareas de NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_segments(text, segment_size=200):\n",
    "    words = text.split() \n",
    "    segments = [' '.join(words[i:i + segment_size]) for i in range(0, len(words), segment_size)]\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente implementación,recorre un directorio de libros organizados por autor, limpia el contenido de los libros, divide el texto en segmentos de tamaño fijo y devuelve una lista de segmentos junto con la lista de autores correspondientes a esos segmentos. Esto es útil para la preparación de datos en tareas de procesamiento de lenguaje natural (NLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_books_data(base_path='books', segment_size=200):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    # Obtiene la lista de autores (subdirectorios o archivos en la carpeta 'base_path')\n",
    "    authors = os.listdir(base_path)\n",
    "\n",
    "    for author in authors:\n",
    "        author_path = os.path.join(base_path, author)\n",
    "        for book_file in os.listdir(author_path):\n",
    "            # Abre el archivo de texto en modo lectura con codificación 'utf-8'.\n",
    "            with open(os.path.join(author_path, book_file), 'r', encoding='utf-8') as f:\n",
    "                book_text = f.read()\n",
    "                # Limpia el texto utilizando la función 'clean_gutenberg_text'.\n",
    "                clean_text = clean_gutenberg_text(book_text)\n",
    "                segments = split_into_segments(clean_text, segment_size)\n",
    "                texts.extend(segments)\n",
    "                # Añade la etiqueta del autor para cada segmento generado.\n",
    "                labels.extend([author] * len(segments))\n",
    "    \n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta implementación, realiza dos tareas clave: cargar embeddings y crear un conjunto de datos a partir de textos y autores.\n",
    "En sus funcionalidades, contempla:\n",
    "\n",
    "embeddings = {size: load_embeddings(path) for size, path in embedding_file_paths.items()}: Crea un diccionario con los tamaños de embeddings como claves y los embeddings cargados como valores.\n",
    "\n",
    "create_dataset(texts, authors): Crea un DataFrame con dos columnas, una para los textos y otra para los autores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga los embeddings para cada tamaño (300, 400, 500) usando los caminos de archivo especificados en 'embedding_file_paths'.\n",
    "# 'embedding_file_paths' es un diccionario donde las claves son los tamaños de embeddings (300, 400, 500) y los valores son las rutas de los archivos.\n",
    "# La comprensión del diccionario recorre cada par (tamaño, ruta), llama a 'load_embeddings' para cargar el archivo correspondiente y los almacena en 'embeddings'.\n",
    "embeddings = {size: load_embeddings(path) for size, path in embedding_file_paths.items()}\n",
    "\n",
    "# Función para crear un DataFrame con los textos y sus respectivos autores\n",
    "# 'texts' es una lista de segmentos de texto y 'authors' es una lista de autores correspondientes.\n",
    "def create_dataset(texts, authors):\n",
    "    df = pd.DataFrame({'text': texts, 'author': authors})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este implementación consta de dos partes, que utilizan funciones previamente definidas:\n",
    "\n",
    "texts, labels = load_books_data(): Carga y procesa los libros, devolviendo una lista de segmentos de texto y una lista de autores.\n",
    "\n",
    "dataset = create_dataset(texts, labels): Crea un DataFrame con los textos y autores para facilitar su manipulación posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = load_books_data()\n",
    "dataset = create_dataset(texts, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta implementación, crea un modelo secuencial que toma secuencias de palabras, las convierte en embeddings, reduce las secuencias a un solo vector promedio, y luego pasa el resultado a varias capas densas, finalizando con una capa softmax para la clasificación en 3 categorías. Los embeddings preentrenados se utilizan sin ser ajustados durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_model(vocab_size, embedding_size, embedding_matrix):\n",
    "    model = Sequential()\n",
    "    # Añade una capa de embeddings, que convierte índices de palabras en vectores densos\n",
    "    # input_dim: número de palabras únicas en el vocabulario\n",
    "    # output_dim: la dimensionalidad de los embeddings\n",
    "    # input_length: la longitud de las secuencias de entrada (200 palabras por texto)\n",
    "    # weights: matriz de embeddings preentrenados\n",
    "    # trainable=False: no se ajustan los embeddings durante el entrenamiento\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=200, weights=[embedding_matrix], trainable=False))\n",
    "    # GlobalAveragePooling1D: reduce cada secuencia de embeddings a un solo vector \n",
    "    # promediando los valores en cada dimensión    \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    # Añade una capa densa totalmente conectada con 64 unidades y activación ReLU\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    # Añade una capa densa con 32 unidades y activación ReLU\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    # Añade la capa de salida con 3 unidades, usando la activación softmax para clasificación multiclase\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model , \"simple\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es un modelo profundo que se caracteriza por tener varias capas densas (fully connected), además de mecanismos de regularización (Dropout) para evitar el sobreajuste durante el entrenamiento. El modelo utiliza embeddings preentrenados y, en lugar de entrenar los embeddings, se enfocan en ajustar las capas densas para mejorar la predicción. El uso de varias capas densas y Dropout es lo que define la profundidad del modelo y su capacidad de aprender características más complejas de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deep_model(vocab_size, embedding_size, embedding_matrix):\n",
    "    model = Sequential()\n",
    "    # Añade una capa de embedding. Convierte las palabras en vectores densos preentrenados.\n",
    "    # input_dim: número de palabras únicas en el vocabulario\n",
    "    # output_dim: la dimensión de los embeddings (embedding_size)\n",
    "    # input_length: longitud máxima de las secuencias de entrada (200 palabras por texto)\n",
    "    # weights: matriz de embeddings preentrenados\n",
    "    # trainable=False: evita que los embeddings se ajusten durante el entrenamiento    \n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=200, weights=[embedding_matrix], trainable=False))\n",
    "    # Reduce cada secuencia de embeddings a un solo vector promediando los valores (pooling global)\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    # Añade capas totalmente conectadas (densa) y activación ReLU\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    # Añade una capa Dropout para evitar sobreajuste, eliminando aleatoriamente el 30% de las conexiones\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    # Capa de salida con 3 unidades, usando activación softmax para clasificación multiclase\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model, \"deep\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta implementación, combina capas densas, Dropout y BatchNormalization, lo que le permite estabilizar el entrenamiento y mejorar la precisión, al mismo tiempo que regula el ajuste excesivo de los datos. Las capas de normalización por lotes son particularmente útiles en modelos más profundos para mejorar la capacidad de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batchnorm_model(vocab_size, embedding_size, embedding_matrix):\n",
    "    model = Sequential()\n",
    "    # Capa de embedding que transforma las palabras en vectores. \n",
    "    # input_dim: tamaño del vocabulario.\n",
    "    # output_dim: dimensión de los embeddings.\n",
    "    # input_length: longitud de las secuencias (200).\n",
    "    # weights: matriz de embeddings preentrenados.\n",
    "    # trainable=False: no ajusta los embeddings durante el entrenamiento.    \n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=200, weights=[embedding_matrix], trainable=False))\n",
    "    # Capa de pooling global que reduce la secuencia de vectores de embedding a un solo vector.    \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    # Añade capas totalmente conectadas (densa) y activación ReLU\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    # Añade una capa Dropout para evitar sobreajuste, eliminando aleatoriamente el 30% de las conexiones\n",
    "    model.add(Dropout(0.3))\n",
    "    # Añade una capa de normalización por lotes (BatchNormalization) que normaliza las salidas de la capa anterior.\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    # Capa de salida con 3 unidades, usando activación softmax para clasificación multiclase\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model , \"batchNorm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función, toma un modelo, lo compila utilizando la función de pérdida sparse_categorical_crossentropy y el optimizador Adam, y luego lo entrena durante 50 épocas. Además, guarda el mejor modelo entrenado en un archivo basado en el tamaño de los embeddings y la arquitectura del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar y entrenar el modelo\n",
    "def compile_and_train_model(model, X_train, y_train, X_val, y_val, size, arquitectureLabel):\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy', \n",
    "        optimizer='adam', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    # Definir un callback para guardar el mejor modelo durante el entrenamiento\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        f'best_model_{size}_{arquitectureLabel}.keras',\n",
    "        monitor='accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1 \n",
    "    )\n",
    "\n",
    "    # Entrenamiento del modelo\n",
    "    history = model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        validation_data=(X_val, y_val), \n",
    "        epochs=50, \n",
    "        batch_size=32,\n",
    "        callbacks=[checkpoint_callback]\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se entrenan tres arquitecturas de modelos usando embeddings preentrenados con diferentes tamaños (300, 400 y 500 dimensiones), evalúa su rendimiento en un conjunto de prueba y almacena los resultados. Luego, imprime los resultados de todas las combinaciones de tamaño de embedding y arquitectura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con embeddings de tamaño: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4240 - loss: 1.0161\n",
      "Epoch 1: accuracy improved from -inf to 0.49108, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.4353 - loss: 0.9987 - val_accuracy: 0.5342 - val_loss: 0.8979\n",
      "Epoch 2/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4698 - loss: 0.8110\n",
      "Epoch 2: accuracy did not improve from 0.49108\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4713 - loss: 0.8131 - val_accuracy: 0.5342 - val_loss: 0.9008\n",
      "Epoch 3/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5035 - loss: 0.8112\n",
      "Epoch 3: accuracy improved from 0.49108 to 0.51746, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5042 - loss: 0.8117 - val_accuracy: 0.5342 - val_loss: 0.8957\n",
      "Epoch 4/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5191 - loss: 0.8131\n",
      "Epoch 4: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5177 - loss: 0.8137 - val_accuracy: 0.3975 - val_loss: 0.9066\n",
      "Epoch 5/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5063 - loss: 0.8115\n",
      "Epoch 5: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5054 - loss: 0.8129 - val_accuracy: 0.5342 - val_loss: 0.8960\n",
      "Epoch 6/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5110 - loss: 0.8376\n",
      "Epoch 6: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5124 - loss: 0.8343 - val_accuracy: 0.5404 - val_loss: 0.9066\n",
      "Epoch 7/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4899 - loss: 0.8201\n",
      "Epoch 7: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4930 - loss: 0.8204 - val_accuracy: 0.5342 - val_loss: 0.8953\n",
      "Epoch 8/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5284 - loss: 0.8218\n",
      "Epoch 8: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5279 - loss: 0.8218 - val_accuracy: 0.5342 - val_loss: 0.9037\n",
      "Epoch 9/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5365 - loss: 0.8094\n",
      "Epoch 9: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5356 - loss: 0.8100 - val_accuracy: 0.5404 - val_loss: 0.8990\n",
      "Epoch 10/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4826 - loss: 0.8303\n",
      "Epoch 10: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4849 - loss: 0.8295 - val_accuracy: 0.5342 - val_loss: 0.8994\n",
      "Epoch 11/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4935 - loss: 0.8127\n",
      "Epoch 11: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4968 - loss: 0.8138 - val_accuracy: 0.5342 - val_loss: 0.8930\n",
      "Epoch 12/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5533 - loss: 0.8048\n",
      "Epoch 12: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5515 - loss: 0.8055 - val_accuracy: 0.3975 - val_loss: 0.9068\n",
      "Epoch 13/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4675 - loss: 0.8601\n",
      "Epoch 13: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4731 - loss: 0.8541 - val_accuracy: 0.5342 - val_loss: 0.9119\n",
      "Epoch 14/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5230 - loss: 0.8101\n",
      "Epoch 14: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5205 - loss: 0.8125 - val_accuracy: 0.3913 - val_loss: 0.9001\n",
      "Epoch 15/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5163 - loss: 0.8193\n",
      "Epoch 15: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5163 - loss: 0.8194 - val_accuracy: 0.3975 - val_loss: 0.9060\n",
      "Epoch 16/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4936 - loss: 0.8077\n",
      "Epoch 16: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4944 - loss: 0.8084 - val_accuracy: 0.5342 - val_loss: 0.8937\n",
      "Epoch 17/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5170 - loss: 0.8280\n",
      "Epoch 17: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5182 - loss: 0.8250 - val_accuracy: 0.5342 - val_loss: 0.9082\n",
      "Epoch 18/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5270 - loss: 0.8493\n",
      "Epoch 18: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5259 - loss: 0.8461 - val_accuracy: 0.5342 - val_loss: 0.9081\n",
      "Epoch 19/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5353 - loss: 0.8370\n",
      "Epoch 19: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5328 - loss: 0.8342 - val_accuracy: 0.5342 - val_loss: 0.9018\n",
      "Epoch 20/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5095 - loss: 0.8265\n",
      "Epoch 20: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5097 - loss: 0.8262 - val_accuracy: 0.5342 - val_loss: 0.8963\n",
      "Epoch 21/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5195 - loss: 0.8076\n",
      "Epoch 21: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5192 - loss: 0.8107 - val_accuracy: 0.5342 - val_loss: 0.8935\n",
      "Epoch 22/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5112 - loss: 0.7975\n",
      "Epoch 22: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5119 - loss: 0.8011 - val_accuracy: 0.5342 - val_loss: 0.8893\n",
      "Epoch 23/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5303 - loss: 0.8493\n",
      "Epoch 23: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5286 - loss: 0.8460 - val_accuracy: 0.5342 - val_loss: 0.9166\n",
      "Epoch 24/50\n",
      "\u001b[1m28/41\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5101 - loss: 0.8452\n",
      "Epoch 24: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5124 - loss: 0.8367 - val_accuracy: 0.5342 - val_loss: 0.8987\n",
      "Epoch 25/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5084 - loss: 0.8108\n",
      "Epoch 25: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5090 - loss: 0.8115 - val_accuracy: 0.5342 - val_loss: 0.8950\n",
      "Epoch 26/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5344 - loss: 0.8080\n",
      "Epoch 26: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5332 - loss: 0.8087 - val_accuracy: 0.5342 - val_loss: 0.8973\n",
      "Epoch 27/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4977 - loss: 0.8343\n",
      "Epoch 27: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4986 - loss: 0.8336 - val_accuracy: 0.5342 - val_loss: 0.9049\n",
      "Epoch 28/50\n",
      "\u001b[1m29/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5226 - loss: 0.8189\n",
      "Epoch 28: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5211 - loss: 0.8192 - val_accuracy: 0.5342 - val_loss: 0.8949\n",
      "Epoch 29/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5447 - loss: 0.7958\n",
      "Epoch 29: accuracy improved from 0.51746 to 0.51978, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5423 - loss: 0.7980 - val_accuracy: 0.4658 - val_loss: 0.8997\n",
      "Epoch 30/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5019 - loss: 0.8148\n",
      "Epoch 30: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5061 - loss: 0.8163 - val_accuracy: 0.5342 - val_loss: 0.8926\n",
      "Epoch 31/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5149 - loss: 0.8203\n",
      "Epoch 31: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5150 - loss: 0.8203 - val_accuracy: 0.5342 - val_loss: 0.9072\n",
      "Epoch 32/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5195 - loss: 0.8209\n",
      "Epoch 32: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5193 - loss: 0.8208 - val_accuracy: 0.5342 - val_loss: 0.8983\n",
      "Epoch 33/50\n",
      "\u001b[1m29/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5392 - loss: 0.8158\n",
      "Epoch 33: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5337 - loss: 0.8184 - val_accuracy: 0.5342 - val_loss: 0.8966\n",
      "Epoch 34/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5380 - loss: 0.8266\n",
      "Epoch 34: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5361 - loss: 0.8261 - val_accuracy: 0.5342 - val_loss: 0.8955\n",
      "Epoch 35/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5329 - loss: 0.8073\n",
      "Epoch 35: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5278 - loss: 0.8109 - val_accuracy: 0.3913 - val_loss: 0.9039\n",
      "Epoch 36/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5231 - loss: 0.8255\n",
      "Epoch 36: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5228 - loss: 0.8252 - val_accuracy: 0.5342 - val_loss: 0.9047\n",
      "Epoch 37/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5367 - loss: 0.8314\n",
      "Epoch 37: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5331 - loss: 0.8289 - val_accuracy: 0.5342 - val_loss: 0.8997\n",
      "Epoch 38/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5278 - loss: 0.8216\n",
      "Epoch 38: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5267 - loss: 0.8210 - val_accuracy: 0.5342 - val_loss: 0.9026\n",
      "Epoch 39/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4925 - loss: 0.8015\n",
      "Epoch 39: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4929 - loss: 0.8035 - val_accuracy: 0.5342 - val_loss: 0.8918\n",
      "Epoch 40/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5105 - loss: 0.8210\n",
      "Epoch 40: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5112 - loss: 0.8210 - val_accuracy: 0.5342 - val_loss: 0.8978\n",
      "Epoch 41/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5121 - loss: 0.8255\n",
      "Epoch 41: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5124 - loss: 0.8252 - val_accuracy: 0.5342 - val_loss: 0.8945\n",
      "Epoch 42/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5143 - loss: 0.8005\n",
      "Epoch 42: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5143 - loss: 0.8010 - val_accuracy: 0.5342 - val_loss: 0.8920\n",
      "Epoch 43/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5091 - loss: 0.8297\n",
      "Epoch 43: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5101 - loss: 0.8285 - val_accuracy: 0.5342 - val_loss: 0.9008\n",
      "Epoch 44/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5343 - loss: 0.8367\n",
      "Epoch 44: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5305 - loss: 0.8325 - val_accuracy: 0.5342 - val_loss: 0.9143\n",
      "Epoch 45/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5227 - loss: 0.8019\n",
      "Epoch 45: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5175 - loss: 0.8068 - val_accuracy: 0.5342 - val_loss: 0.8953\n",
      "Epoch 46/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5370 - loss: 0.8164\n",
      "Epoch 46: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5338 - loss: 0.8169 - val_accuracy: 0.5342 - val_loss: 0.8971\n",
      "Epoch 47/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5240 - loss: 0.8289\n",
      "Epoch 47: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5237 - loss: 0.8285 - val_accuracy: 0.5342 - val_loss: 0.8999\n",
      "Epoch 48/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5127 - loss: 0.8089\n",
      "Epoch 48: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5130 - loss: 0.8095 - val_accuracy: 0.5342 - val_loss: 0.8935\n",
      "Epoch 49/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5117 - loss: 0.8136\n",
      "Epoch 49: accuracy did not improve from 0.51978\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5123 - loss: 0.8142 - val_accuracy: 0.5342 - val_loss: 0.8927\n",
      "Epoch 50/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5184 - loss: 0.8058\n",
      "Epoch 50: accuracy improved from 0.51978 to 0.53064, saving model to best_model_300_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5193 - loss: 0.8068 - val_accuracy: 0.5342 - val_loss: 0.8914\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5877 - loss: 0.8211\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Entrenando con embeddings de tamaño: 300\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5115 - loss: 0.9294\n",
      "Epoch 1: accuracy improved from -inf to 0.50504, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5103 - loss: 0.9183 - val_accuracy: 0.5342 - val_loss: 0.8963\n",
      "Epoch 2/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5159 - loss: 0.8557\n",
      "Epoch 2: accuracy improved from 0.50504 to 0.51513, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5160 - loss: 0.8530 - val_accuracy: 0.3975 - val_loss: 0.9196\n",
      "Epoch 3/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5387 - loss: 0.8415\n",
      "Epoch 3: accuracy did not improve from 0.51513\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5307 - loss: 0.8398 - val_accuracy: 0.5342 - val_loss: 0.9055\n",
      "Epoch 4/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4936 - loss: 0.8543\n",
      "Epoch 4: accuracy did not improve from 0.51513\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4951 - loss: 0.8493 - val_accuracy: 0.5342 - val_loss: 0.9102\n",
      "Epoch 5/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5167 - loss: 0.8508\n",
      "Epoch 5: accuracy did not improve from 0.51513\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5142 - loss: 0.8485 - val_accuracy: 0.3975 - val_loss: 0.9121\n",
      "Epoch 6/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5335 - loss: 0.8205\n",
      "Epoch 6: accuracy improved from 0.51513 to 0.52056, saving model to best_model_300_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5316 - loss: 0.8219 - val_accuracy: 0.5342 - val_loss: 0.9049\n",
      "Epoch 7/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4833 - loss: 0.7934\n",
      "Epoch 7: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4853 - loss: 0.7997 - val_accuracy: 0.5342 - val_loss: 0.8835\n",
      "Epoch 8/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5424 - loss: 0.8295\n",
      "Epoch 8: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5366 - loss: 0.8307 - val_accuracy: 0.3975 - val_loss: 0.9036\n",
      "Epoch 9/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4666 - loss: 0.8515\n",
      "Epoch 9: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4755 - loss: 0.8463 - val_accuracy: 0.5342 - val_loss: 0.8981\n",
      "Epoch 10/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5299 - loss: 0.8217\n",
      "Epoch 10: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5283 - loss: 0.8222 - val_accuracy: 0.5342 - val_loss: 0.8998\n",
      "Epoch 11/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5404 - loss: 0.8560\n",
      "Epoch 11: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5354 - loss: 0.8508 - val_accuracy: 0.5342 - val_loss: 0.9273\n",
      "Epoch 12/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4914 - loss: 0.8412\n",
      "Epoch 12: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4921 - loss: 0.8391 - val_accuracy: 0.5342 - val_loss: 0.9104\n",
      "Epoch 13/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4965 - loss: 0.8295\n",
      "Epoch 13: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5001 - loss: 0.8294 - val_accuracy: 0.5342 - val_loss: 0.8935\n",
      "Epoch 14/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5119 - loss: 0.8170\n",
      "Epoch 14: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5097 - loss: 0.8194 - val_accuracy: 0.5342 - val_loss: 0.8979\n",
      "Epoch 15/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4984 - loss: 0.8457\n",
      "Epoch 15: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4992 - loss: 0.8424 - val_accuracy: 0.5342 - val_loss: 0.9120\n",
      "Epoch 16/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5340 - loss: 0.8018\n",
      "Epoch 16: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5309 - loss: 0.8060 - val_accuracy: 0.5342 - val_loss: 0.9058\n",
      "Epoch 17/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4951 - loss: 0.8335\n",
      "Epoch 17: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4952 - loss: 0.8327 - val_accuracy: 0.5342 - val_loss: 0.8980\n",
      "Epoch 18/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4833 - loss: 0.8285\n",
      "Epoch 18: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4839 - loss: 0.8288 - val_accuracy: 0.5342 - val_loss: 0.9006\n",
      "Epoch 19/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5290 - loss: 0.8208\n",
      "Epoch 19: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5276 - loss: 0.8225 - val_accuracy: 0.5342 - val_loss: 0.9019\n",
      "Epoch 20/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5193 - loss: 0.8206\n",
      "Epoch 20: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5174 - loss: 0.8210 - val_accuracy: 0.5342 - val_loss: 0.9062\n",
      "Epoch 21/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5080 - loss: 0.8118\n",
      "Epoch 21: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5086 - loss: 0.8134 - val_accuracy: 0.5342 - val_loss: 0.8989\n",
      "Epoch 22/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5012 - loss: 0.8201\n",
      "Epoch 22: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5029 - loss: 0.8207 - val_accuracy: 0.5342 - val_loss: 0.9049\n",
      "Epoch 23/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5122 - loss: 0.8240\n",
      "Epoch 23: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5121 - loss: 0.8242 - val_accuracy: 0.5342 - val_loss: 0.8921\n",
      "Epoch 24/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5230 - loss: 0.8195\n",
      "Epoch 24: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5212 - loss: 0.8226 - val_accuracy: 0.5342 - val_loss: 0.8949\n",
      "Epoch 25/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5201 - loss: 0.8366\n",
      "Epoch 25: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5183 - loss: 0.8342 - val_accuracy: 0.5342 - val_loss: 0.8994\n",
      "Epoch 26/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4889 - loss: 0.8599\n",
      "Epoch 26: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4929 - loss: 0.8543 - val_accuracy: 0.5342 - val_loss: 0.9002\n",
      "Epoch 27/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5320 - loss: 0.7999\n",
      "Epoch 27: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5278 - loss: 0.8044 - val_accuracy: 0.5342 - val_loss: 0.8919\n",
      "Epoch 28/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5175 - loss: 0.8380\n",
      "Epoch 28: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5171 - loss: 0.8366 - val_accuracy: 0.5342 - val_loss: 0.8977\n",
      "Epoch 29/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5143 - loss: 0.8079\n",
      "Epoch 29: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5139 - loss: 0.8109 - val_accuracy: 0.5342 - val_loss: 0.8902\n",
      "Epoch 30/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5044 - loss: 0.8242\n",
      "Epoch 30: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5044 - loss: 0.8251 - val_accuracy: 0.5342 - val_loss: 0.8955\n",
      "Epoch 31/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5389 - loss: 0.8255\n",
      "Epoch 31: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5384 - loss: 0.8253 - val_accuracy: 0.5342 - val_loss: 0.9008\n",
      "Epoch 32/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5117 - loss: 0.8313\n",
      "Epoch 32: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5125 - loss: 0.8316 - val_accuracy: 0.5342 - val_loss: 0.8982\n",
      "Epoch 33/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4793 - loss: 0.8326\n",
      "Epoch 33: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4861 - loss: 0.8297 - val_accuracy: 0.5342 - val_loss: 0.8964\n",
      "Epoch 34/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5267 - loss: 0.8086\n",
      "Epoch 34: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5253 - loss: 0.8102 - val_accuracy: 0.5342 - val_loss: 0.8951\n",
      "Epoch 35/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5066 - loss: 0.8452\n",
      "Epoch 35: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5077 - loss: 0.8419 - val_accuracy: 0.5342 - val_loss: 0.9106\n",
      "Epoch 36/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5101 - loss: 0.8521\n",
      "Epoch 36: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5112 - loss: 0.8461 - val_accuracy: 0.5342 - val_loss: 0.8991\n",
      "Epoch 37/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5330 - loss: 0.8077\n",
      "Epoch 37: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5270 - loss: 0.8103 - val_accuracy: 0.5342 - val_loss: 0.8964\n",
      "Epoch 38/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5355 - loss: 0.7970\n",
      "Epoch 38: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5338 - loss: 0.8007 - val_accuracy: 0.5342 - val_loss: 0.8937\n",
      "Epoch 39/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4869 - loss: 0.8247\n",
      "Epoch 39: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4877 - loss: 0.8248 - val_accuracy: 0.5342 - val_loss: 0.9035\n",
      "Epoch 40/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5165 - loss: 0.7898\n",
      "Epoch 40: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5168 - loss: 0.7952 - val_accuracy: 0.5342 - val_loss: 0.8930\n",
      "Epoch 41/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5138 - loss: 0.8130\n",
      "Epoch 41: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5137 - loss: 0.8143 - val_accuracy: 0.5342 - val_loss: 0.8936\n",
      "Epoch 42/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5372 - loss: 0.8196\n",
      "Epoch 42: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5347 - loss: 0.8197 - val_accuracy: 0.5342 - val_loss: 0.8956\n",
      "Epoch 43/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4958 - loss: 0.8383\n",
      "Epoch 43: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4984 - loss: 0.8362 - val_accuracy: 0.5342 - val_loss: 0.9058\n",
      "Epoch 44/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4972 - loss: 0.8342\n",
      "Epoch 44: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5005 - loss: 0.8323 - val_accuracy: 0.5342 - val_loss: 0.9032\n",
      "Epoch 45/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5147 - loss: 0.8487\n",
      "Epoch 45: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5147 - loss: 0.8446 - val_accuracy: 0.5342 - val_loss: 0.8967\n",
      "Epoch 46/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5273 - loss: 0.8257\n",
      "Epoch 46: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5256 - loss: 0.8245 - val_accuracy: 0.3975 - val_loss: 0.9028\n",
      "Epoch 47/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4844 - loss: 0.8197\n",
      "Epoch 47: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4867 - loss: 0.8205 - val_accuracy: 0.5342 - val_loss: 0.8930\n",
      "Epoch 48/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5201 - loss: 0.8263\n",
      "Epoch 48: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5197 - loss: 0.8256 - val_accuracy: 0.5342 - val_loss: 0.8989\n",
      "Epoch 49/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4895 - loss: 0.8130\n",
      "Epoch 49: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4922 - loss: 0.8149 - val_accuracy: 0.5342 - val_loss: 0.8947\n",
      "Epoch 50/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5302 - loss: 0.8230\n",
      "Epoch 50: accuracy did not improve from 0.52056\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5274 - loss: 0.8233 - val_accuracy: 0.5342 - val_loss: 0.8982\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5877 - loss: 0.8386 \n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Entrenando con embeddings de tamaño: 300\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3194 - loss: 1.3919\n",
      "Epoch 1: accuracy improved from -inf to 0.39721, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.3316 - loss: 1.3678 - val_accuracy: 0.5342 - val_loss: 1.0219\n",
      "Epoch 2/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4367 - loss: 1.0417\n",
      "Epoch 2: accuracy improved from 0.39721 to 0.45384, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4375 - loss: 1.0410 - val_accuracy: 0.3851 - val_loss: 0.9324\n",
      "Epoch 3/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5331 - loss: 0.8909\n",
      "Epoch 3: accuracy improved from 0.45384 to 0.49108, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5235 - loss: 0.9005 - val_accuracy: 0.5217 - val_loss: 0.9029\n",
      "Epoch 4/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5081 - loss: 0.8767\n",
      "Epoch 4: accuracy improved from 0.49108 to 0.50970, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5082 - loss: 0.8772 - val_accuracy: 0.3913 - val_loss: 0.9058\n",
      "Epoch 5/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4919 - loss: 0.8775\n",
      "Epoch 5: accuracy did not improve from 0.50970\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4921 - loss: 0.8776 - val_accuracy: 0.3975 - val_loss: 0.9203\n",
      "Epoch 6/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5160 - loss: 0.8603\n",
      "Epoch 6: accuracy did not improve from 0.50970\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5152 - loss: 0.8612 - val_accuracy: 0.3975 - val_loss: 0.9236\n",
      "Epoch 7/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5087 - loss: 0.8297\n",
      "Epoch 7: accuracy did not improve from 0.50970\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5064 - loss: 0.8367 - val_accuracy: 0.3913 - val_loss: 0.9360\n",
      "Epoch 8/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4859 - loss: 0.8645\n",
      "Epoch 8: accuracy did not improve from 0.50970\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4845 - loss: 0.8677 - val_accuracy: 0.5342 - val_loss: 0.8978\n",
      "Epoch 9/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5223 - loss: 0.8416\n",
      "Epoch 9: accuracy did not improve from 0.50970\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5194 - loss: 0.8452 - val_accuracy: 0.5404 - val_loss: 0.8895\n",
      "Epoch 10/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4931 - loss: 0.8771\n",
      "Epoch 10: accuracy did not improve from 0.50970\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4936 - loss: 0.8760 - val_accuracy: 0.4596 - val_loss: 0.9031\n",
      "Epoch 11/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5523 - loss: 0.8305\n",
      "Epoch 11: accuracy improved from 0.50970 to 0.52521, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5510 - loss: 0.8312 - val_accuracy: 0.3913 - val_loss: 0.9160\n",
      "Epoch 12/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4958 - loss: 0.8522\n",
      "Epoch 12: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4964 - loss: 0.8521 - val_accuracy: 0.3913 - val_loss: 0.9067\n",
      "Epoch 13/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5261 - loss: 0.8290\n",
      "Epoch 13: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5219 - loss: 0.8314 - val_accuracy: 0.4596 - val_loss: 0.9028\n",
      "Epoch 14/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5019 - loss: 0.8647\n",
      "Epoch 14: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5013 - loss: 0.8619 - val_accuracy: 0.5404 - val_loss: 0.8922\n",
      "Epoch 15/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5212 - loss: 0.8346\n",
      "Epoch 15: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5201 - loss: 0.8351 - val_accuracy: 0.5093 - val_loss: 0.8909\n",
      "Epoch 16/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5007 - loss: 0.8446\n",
      "Epoch 16: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5002 - loss: 0.8446 - val_accuracy: 0.3975 - val_loss: 0.9001\n",
      "Epoch 17/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4939 - loss: 0.8586\n",
      "Epoch 17: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4937 - loss: 0.8582 - val_accuracy: 0.3975 - val_loss: 0.9234\n",
      "Epoch 18/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4655 - loss: 0.8648\n",
      "Epoch 18: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4675 - loss: 0.8630 - val_accuracy: 0.3913 - val_loss: 0.9293\n",
      "Epoch 19/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4965 - loss: 0.8479\n",
      "Epoch 19: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4969 - loss: 0.8476 - val_accuracy: 0.3913 - val_loss: 0.9126\n",
      "Epoch 20/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5404 - loss: 0.8198\n",
      "Epoch 20: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5331 - loss: 0.8248 - val_accuracy: 0.3913 - val_loss: 0.9059\n",
      "Epoch 21/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4937 - loss: 0.8365\n",
      "Epoch 21: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4939 - loss: 0.8364 - val_accuracy: 0.3913 - val_loss: 0.9052\n",
      "Epoch 22/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5277 - loss: 0.8280\n",
      "Epoch 22: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5257 - loss: 0.8285 - val_accuracy: 0.3913 - val_loss: 0.9098\n",
      "Epoch 23/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4765 - loss: 0.8470\n",
      "Epoch 23: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4795 - loss: 0.8452 - val_accuracy: 0.3913 - val_loss: 0.9044\n",
      "Epoch 24/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5083 - loss: 0.8397\n",
      "Epoch 24: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5101 - loss: 0.8366 - val_accuracy: 0.3913 - val_loss: 0.9069\n",
      "Epoch 25/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4650 - loss: 0.8439\n",
      "Epoch 25: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4706 - loss: 0.8428 - val_accuracy: 0.4534 - val_loss: 0.9032\n",
      "Epoch 26/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4798 - loss: 0.8642\n",
      "Epoch 26: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4804 - loss: 0.8611 - val_accuracy: 0.3851 - val_loss: 0.9094\n",
      "Epoch 27/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5333 - loss: 0.8318\n",
      "Epoch 27: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5324 - loss: 0.8317 - val_accuracy: 0.3913 - val_loss: 0.9111\n",
      "Epoch 28/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5433 - loss: 0.8532\n",
      "Epoch 28: accuracy improved from 0.52521 to 0.52909, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5401 - loss: 0.8490 - val_accuracy: 0.3913 - val_loss: 0.9075\n",
      "Epoch 29/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5006 - loss: 0.8266\n",
      "Epoch 29: accuracy did not improve from 0.52909\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4989 - loss: 0.8266 - val_accuracy: 0.3913 - val_loss: 0.9101\n",
      "Epoch 30/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5103 - loss: 0.8457\n",
      "Epoch 30: accuracy did not improve from 0.52909\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5087 - loss: 0.8439 - val_accuracy: 0.3851 - val_loss: 0.9147\n",
      "Epoch 31/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4734 - loss: 0.8292\n",
      "Epoch 31: accuracy did not improve from 0.52909\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4758 - loss: 0.8309 - val_accuracy: 0.3913 - val_loss: 0.9174\n",
      "Epoch 32/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5118 - loss: 0.8217\n",
      "Epoch 32: accuracy did not improve from 0.52909\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5096 - loss: 0.8234 - val_accuracy: 0.3913 - val_loss: 0.9189\n",
      "Epoch 33/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4956 - loss: 0.8154\n",
      "Epoch 33: accuracy did not improve from 0.52909\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4973 - loss: 0.8180 - val_accuracy: 0.3913 - val_loss: 0.9210\n",
      "Epoch 34/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5217 - loss: 0.8253\n",
      "Epoch 34: accuracy improved from 0.52909 to 0.53142, saving model to best_model_300_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5222 - loss: 0.8249 - val_accuracy: 0.3913 - val_loss: 0.9052\n",
      "Epoch 35/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5182 - loss: 0.8384\n",
      "Epoch 35: accuracy did not improve from 0.53142\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5178 - loss: 0.8379 - val_accuracy: 0.3913 - val_loss: 0.9135\n",
      "Epoch 36/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5150 - loss: 0.8100\n",
      "Epoch 36: accuracy did not improve from 0.53142\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5149 - loss: 0.8105 - val_accuracy: 0.3913 - val_loss: 0.9086\n",
      "Epoch 37/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5032 - loss: 0.8469\n",
      "Epoch 37: accuracy did not improve from 0.53142\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5036 - loss: 0.8462 - val_accuracy: 0.3913 - val_loss: 0.9222\n",
      "Epoch 38/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5128 - loss: 0.8247\n",
      "Epoch 38: accuracy did not improve from 0.53142\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5137 - loss: 0.8263 - val_accuracy: 0.3913 - val_loss: 0.9191\n",
      "Epoch 39/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5100 - loss: 0.8506\n",
      "Epoch 39: accuracy did not improve from 0.53142\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5137 - loss: 0.8452 - val_accuracy: 0.3975 - val_loss: 0.9252\n",
      "Epoch 40/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4892 - loss: 0.8399\n",
      "Epoch 40: accuracy did not improve from 0.53142\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4930 - loss: 0.8378 - val_accuracy: 0.3975 - val_loss: 0.9204\n",
      "Epoch 41/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5379 - loss: 0.8046\n",
      "Epoch 41: accuracy did not improve from 0.53142\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5373 - loss: 0.8054 - val_accuracy: 0.3975 - val_loss: 0.9257\n",
      "Epoch 42/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5082 - loss: 0.8564\n",
      "Epoch 42: accuracy did not improve from 0.53142\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5082 - loss: 0.8558 - val_accuracy: 0.3975 - val_loss: 0.9219\n",
      "Epoch 43/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4933 - loss: 0.8444\n",
      "Epoch 43: accuracy did not improve from 0.53142\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4935 - loss: 0.8433 - val_accuracy: 0.3913 - val_loss: 0.9059\n",
      "Epoch 44/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4985 - loss: 0.8144\n",
      "Epoch 44: accuracy did not improve from 0.53142\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5001 - loss: 0.8151 - val_accuracy: 0.5342 - val_loss: 0.8938\n",
      "Epoch 45/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5111 - loss: 0.8402\n",
      "Epoch 45: accuracy did not improve from 0.53142\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5086 - loss: 0.8374 - val_accuracy: 0.5342 - val_loss: 0.8944\n",
      "Epoch 46/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5154 - loss: 0.8701\n",
      "Epoch 46: accuracy did not improve from 0.53142\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5146 - loss: 0.8666 - val_accuracy: 0.5155 - val_loss: 0.8943\n",
      "Epoch 47/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5219 - loss: 0.8302\n",
      "Epoch 47: accuracy did not improve from 0.53142\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5215 - loss: 0.8287 - val_accuracy: 0.5404 - val_loss: 0.8995\n",
      "Epoch 48/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5374 - loss: 0.8128\n",
      "Epoch 48: accuracy did not improve from 0.53142\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5370 - loss: 0.8134 - val_accuracy: 0.3913 - val_loss: 0.9018\n",
      "Epoch 49/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5300 - loss: 0.8257\n",
      "Epoch 49: accuracy did not improve from 0.53142\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5279 - loss: 0.8246 - val_accuracy: 0.3851 - val_loss: 0.9085\n",
      "Epoch 50/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5120 - loss: 0.8346\n",
      "Epoch 50: accuracy did not improve from 0.53142\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5115 - loss: 0.8324 - val_accuracy: 0.3913 - val_loss: 0.9112\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3624 - loss: 0.8626 \n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con embeddings de tamaño: 400\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5082 - loss: 0.8531\n",
      "Epoch 1: accuracy improved from -inf to 0.51202, saving model to best_model_400_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5080 - loss: 0.8517 - val_accuracy: 0.5342 - val_loss: 0.9007\n",
      "Epoch 2/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4791 - loss: 0.8483\n",
      "Epoch 2: accuracy did not improve from 0.51202\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4799 - loss: 0.8472 - val_accuracy: 0.5342 - val_loss: 0.9020\n",
      "Epoch 3/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5303 - loss: 0.7901\n",
      "Epoch 3: accuracy improved from 0.51202 to 0.51746, saving model to best_model_400_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5289 - loss: 0.7970 - val_accuracy: 0.5342 - val_loss: 0.8939\n",
      "Epoch 4/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5237 - loss: 0.8344\n",
      "Epoch 4: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5215 - loss: 0.8320 - val_accuracy: 0.5342 - val_loss: 0.8959\n",
      "Epoch 5/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5425 - loss: 0.8010\n",
      "Epoch 5: accuracy improved from 0.51746 to 0.51823, saving model to best_model_400_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5372 - loss: 0.8063 - val_accuracy: 0.3975 - val_loss: 0.9048\n",
      "Epoch 6/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4733 - loss: 0.8224\n",
      "Epoch 6: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4779 - loss: 0.8223 - val_accuracy: 0.3975 - val_loss: 0.9208\n",
      "Epoch 7/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4910 - loss: 0.8362\n",
      "Epoch 7: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4963 - loss: 0.8339 - val_accuracy: 0.5342 - val_loss: 0.9036\n",
      "Epoch 8/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5386 - loss: 0.8236\n",
      "Epoch 8: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5363 - loss: 0.8235 - val_accuracy: 0.3975 - val_loss: 0.9128\n",
      "Epoch 9/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4848 - loss: 0.8226\n",
      "Epoch 9: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4884 - loss: 0.8222 - val_accuracy: 0.5342 - val_loss: 0.9053\n",
      "Epoch 10/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4934 - loss: 0.8174\n",
      "Epoch 10: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4934 - loss: 0.8177 - val_accuracy: 0.5342 - val_loss: 0.8879\n",
      "Epoch 11/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5013 - loss: 0.8230\n",
      "Epoch 11: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5047 - loss: 0.8227 - val_accuracy: 0.5342 - val_loss: 0.8936\n",
      "Epoch 12/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5243 - loss: 0.8194\n",
      "Epoch 12: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5209 - loss: 0.8203 - val_accuracy: 0.5342 - val_loss: 0.8933\n",
      "Epoch 13/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 0.8177\n",
      "Epoch 13: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5045 - loss: 0.8180 - val_accuracy: 0.5342 - val_loss: 0.8986\n",
      "Epoch 14/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5124 - loss: 0.8222\n",
      "Epoch 14: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5143 - loss: 0.8227 - val_accuracy: 0.5342 - val_loss: 0.9287\n",
      "Epoch 15/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5059 - loss: 0.8419\n",
      "Epoch 15: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5076 - loss: 0.8390 - val_accuracy: 0.5342 - val_loss: 0.8989\n",
      "Epoch 16/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5276 - loss: 0.8013\n",
      "Epoch 16: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5263 - loss: 0.8042 - val_accuracy: 0.5342 - val_loss: 0.8895\n",
      "Epoch 17/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4970 - loss: 0.8439\n",
      "Epoch 17: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5001 - loss: 0.8409 - val_accuracy: 0.5342 - val_loss: 0.8955\n",
      "Epoch 18/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5315 - loss: 0.8048\n",
      "Epoch 18: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5282 - loss: 0.8075 - val_accuracy: 0.5342 - val_loss: 0.8886\n",
      "Epoch 19/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5125 - loss: 0.8328\n",
      "Epoch 19: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5135 - loss: 0.8302 - val_accuracy: 0.5342 - val_loss: 0.8994\n",
      "Epoch 20/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5141 - loss: 0.8121\n",
      "Epoch 20: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5145 - loss: 0.8135 - val_accuracy: 0.5342 - val_loss: 0.8912\n",
      "Epoch 21/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4758 - loss: 0.8256\n",
      "Epoch 21: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4768 - loss: 0.8255 - val_accuracy: 0.5342 - val_loss: 0.8917\n",
      "Epoch 22/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5445 - loss: 0.8113\n",
      "Epoch 22: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5338 - loss: 0.8142 - val_accuracy: 0.5342 - val_loss: 0.9085\n",
      "Epoch 23/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5278 - loss: 0.8066\n",
      "Epoch 23: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5240 - loss: 0.8106 - val_accuracy: 0.5342 - val_loss: 0.9043\n",
      "Epoch 24/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5181 - loss: 0.8419\n",
      "Epoch 24: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5176 - loss: 0.8387 - val_accuracy: 0.5342 - val_loss: 0.9143\n",
      "Epoch 25/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4868 - loss: 0.8128\n",
      "Epoch 25: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4883 - loss: 0.8149 - val_accuracy: 0.5342 - val_loss: 0.9086\n",
      "Epoch 26/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5371 - loss: 0.8041\n",
      "Epoch 26: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5339 - loss: 0.8065 - val_accuracy: 0.5342 - val_loss: 0.8930\n",
      "Epoch 27/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4929 - loss: 0.8428\n",
      "Epoch 27: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4986 - loss: 0.8379 - val_accuracy: 0.5342 - val_loss: 0.9224\n",
      "Epoch 28/50\n",
      "\u001b[1m31/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5323 - loss: 0.7838\n",
      "Epoch 28: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5277 - loss: 0.7918 - val_accuracy: 0.5342 - val_loss: 0.8887\n",
      "Epoch 29/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5244 - loss: 0.8181\n",
      "Epoch 29: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5237 - loss: 0.8182 - val_accuracy: 0.5342 - val_loss: 0.8945\n",
      "Epoch 30/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5189 - loss: 0.8429\n",
      "Epoch 30: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5183 - loss: 0.8396 - val_accuracy: 0.5342 - val_loss: 0.9028\n",
      "Epoch 31/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5279 - loss: 0.8218\n",
      "Epoch 31: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5259 - loss: 0.8215 - val_accuracy: 0.5342 - val_loss: 0.8984\n",
      "Epoch 32/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5125 - loss: 0.8385\n",
      "Epoch 32: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5130 - loss: 0.8351 - val_accuracy: 0.5342 - val_loss: 0.9137\n",
      "Epoch 33/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5321 - loss: 0.8102\n",
      "Epoch 33: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5308 - loss: 0.8110 - val_accuracy: 0.5342 - val_loss: 0.8995\n",
      "Epoch 34/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5248 - loss: 0.7989\n",
      "Epoch 34: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5246 - loss: 0.7994 - val_accuracy: 0.5342 - val_loss: 0.8897\n",
      "Epoch 35/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5413 - loss: 0.8252\n",
      "Epoch 35: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5375 - loss: 0.8239 - val_accuracy: 0.5342 - val_loss: 0.8993\n",
      "Epoch 36/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4949 - loss: 0.8213\n",
      "Epoch 36: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4987 - loss: 0.8211 - val_accuracy: 0.5342 - val_loss: 0.8993\n",
      "Epoch 37/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4930 - loss: 0.8483\n",
      "Epoch 37: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4945 - loss: 0.8439 - val_accuracy: 0.3913 - val_loss: 0.9353\n",
      "Epoch 38/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4831 - loss: 0.8155\n",
      "Epoch 38: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4858 - loss: 0.8166 - val_accuracy: 0.5342 - val_loss: 0.8925\n",
      "Epoch 39/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5213 - loss: 0.8327\n",
      "Epoch 39: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5203 - loss: 0.8306 - val_accuracy: 0.5342 - val_loss: 0.9095\n",
      "Epoch 40/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5023 - loss: 0.8137\n",
      "Epoch 40: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5054 - loss: 0.8150 - val_accuracy: 0.5342 - val_loss: 0.8883\n",
      "Epoch 41/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5344 - loss: 0.8104\n",
      "Epoch 41: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5306 - loss: 0.8120 - val_accuracy: 0.5342 - val_loss: 0.8938\n",
      "Epoch 42/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4993 - loss: 0.8101\n",
      "Epoch 42: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5032 - loss: 0.8125 - val_accuracy: 0.5342 - val_loss: 0.8955\n",
      "Epoch 43/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5248 - loss: 0.8246\n",
      "Epoch 43: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5168 - loss: 0.8229 - val_accuracy: 0.5342 - val_loss: 0.9031\n",
      "Epoch 44/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5208 - loss: 0.8126\n",
      "Epoch 44: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5198 - loss: 0.8150 - val_accuracy: 0.5342 - val_loss: 0.9010\n",
      "Epoch 45/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5363 - loss: 0.8111\n",
      "Epoch 45: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5259 - loss: 0.8135 - val_accuracy: 0.5342 - val_loss: 0.8985\n",
      "Epoch 46/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5180 - loss: 0.8105\n",
      "Epoch 46: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5181 - loss: 0.8121 - val_accuracy: 0.5342 - val_loss: 0.8970\n",
      "Epoch 47/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4939 - loss: 0.8236\n",
      "Epoch 47: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4973 - loss: 0.8230 - val_accuracy: 0.5342 - val_loss: 0.8974\n",
      "Epoch 48/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5212 - loss: 0.8132\n",
      "Epoch 48: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5203 - loss: 0.8147 - val_accuracy: 0.5342 - val_loss: 0.9066\n",
      "Epoch 49/50\n",
      "\u001b[1m32/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5289 - loss: 0.8027\n",
      "Epoch 49: accuracy did not improve from 0.51823\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5283 - loss: 0.8076 - val_accuracy: 0.5342 - val_loss: 0.9034\n",
      "Epoch 50/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5287 - loss: 0.8233\n",
      "Epoch 50: accuracy improved from 0.51823 to 0.52754, saving model to best_model_400_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5281 - loss: 0.8223 - val_accuracy: 0.5342 - val_loss: 0.8964\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5877 - loss: 0.8325\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Entrenando con embeddings de tamaño: 400\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4881 - loss: 0.8740\n",
      "Epoch 1: accuracy improved from -inf to 0.49806, saving model to best_model_400_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.4883 - loss: 0.8735 - val_accuracy: 0.5342 - val_loss: 0.9020\n",
      "Epoch 2/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4747 - loss: 0.8463\n",
      "Epoch 2: accuracy did not improve from 0.49806\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4771 - loss: 0.8441 - val_accuracy: 0.3851 - val_loss: 0.9037\n",
      "Epoch 3/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4725 - loss: 0.8407\n",
      "Epoch 3: accuracy did not improve from 0.49806\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4755 - loss: 0.8404 - val_accuracy: 0.5342 - val_loss: 0.9096\n",
      "Epoch 4/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4860 - loss: 0.8111\n",
      "Epoch 4: accuracy did not improve from 0.49806\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4869 - loss: 0.8130 - val_accuracy: 0.5342 - val_loss: 0.9041\n",
      "Epoch 5/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5209 - loss: 0.8732\n",
      "Epoch 5: accuracy improved from 0.49806 to 0.51513, saving model to best_model_400_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.5204 - loss: 0.8697 - val_accuracy: 0.3975 - val_loss: 0.9128\n",
      "Epoch 6/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5058 - loss: 0.8128\n",
      "Epoch 6: accuracy did not improve from 0.51513\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5044 - loss: 0.8155 - val_accuracy: 0.5342 - val_loss: 0.9099\n",
      "Epoch 7/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5007 - loss: 0.8614\n",
      "Epoch 7: accuracy did not improve from 0.51513\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5017 - loss: 0.8569 - val_accuracy: 0.5342 - val_loss: 0.9397\n",
      "Epoch 8/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5091 - loss: 0.8213\n",
      "Epoch 8: accuracy improved from 0.51513 to 0.52444, saving model to best_model_400_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5109 - loss: 0.8223 - val_accuracy: 0.5342 - val_loss: 0.8903\n",
      "Epoch 9/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5002 - loss: 0.8361\n",
      "Epoch 9: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5014 - loss: 0.8354 - val_accuracy: 0.5342 - val_loss: 0.9016\n",
      "Epoch 10/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4950 - loss: 0.8100\n",
      "Epoch 10: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4949 - loss: 0.8105 - val_accuracy: 0.5342 - val_loss: 0.9021\n",
      "Epoch 11/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5142 - loss: 0.8381\n",
      "Epoch 11: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5154 - loss: 0.8364 - val_accuracy: 0.5342 - val_loss: 0.8924\n",
      "Epoch 12/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5233 - loss: 0.8464\n",
      "Epoch 12: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5228 - loss: 0.8447 - val_accuracy: 0.5342 - val_loss: 0.8961\n",
      "Epoch 13/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5028 - loss: 0.8248\n",
      "Epoch 13: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5028 - loss: 0.8257 - val_accuracy: 0.5342 - val_loss: 0.8992\n",
      "Epoch 14/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5150 - loss: 0.8315\n",
      "Epoch 14: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5148 - loss: 0.8311 - val_accuracy: 0.5342 - val_loss: 0.8940\n",
      "Epoch 15/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5054 - loss: 0.8115\n",
      "Epoch 15: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5065 - loss: 0.8127 - val_accuracy: 0.5342 - val_loss: 0.8877\n",
      "Epoch 16/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5083 - loss: 0.8194\n",
      "Epoch 16: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5099 - loss: 0.8210 - val_accuracy: 0.5342 - val_loss: 0.8848\n",
      "Epoch 17/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5150 - loss: 0.8237\n",
      "Epoch 17: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5157 - loss: 0.8235 - val_accuracy: 0.5342 - val_loss: 0.8950\n",
      "Epoch 18/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4865 - loss: 0.8578\n",
      "Epoch 18: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4889 - loss: 0.8547 - val_accuracy: 0.5342 - val_loss: 0.8925\n",
      "Epoch 19/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5102 - loss: 0.8109\n",
      "Epoch 19: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5128 - loss: 0.8132 - val_accuracy: 0.5342 - val_loss: 0.8943\n",
      "Epoch 20/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5408 - loss: 0.8216\n",
      "Epoch 20: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5375 - loss: 0.8218 - val_accuracy: 0.5342 - val_loss: 0.8920\n",
      "Epoch 21/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5093 - loss: 0.8107\n",
      "Epoch 21: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5090 - loss: 0.8125 - val_accuracy: 0.5342 - val_loss: 0.8912\n",
      "Epoch 22/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5072 - loss: 0.8150\n",
      "Epoch 22: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5079 - loss: 0.8157 - val_accuracy: 0.5342 - val_loss: 0.8982\n",
      "Epoch 23/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5309 - loss: 0.8168\n",
      "Epoch 23: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5305 - loss: 0.8170 - val_accuracy: 0.5342 - val_loss: 0.8932\n",
      "Epoch 24/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5184 - loss: 0.8107\n",
      "Epoch 24: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5180 - loss: 0.8129 - val_accuracy: 0.5342 - val_loss: 0.8893\n",
      "Epoch 25/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5248 - loss: 0.8234\n",
      "Epoch 25: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5240 - loss: 0.8239 - val_accuracy: 0.5342 - val_loss: 0.8897\n",
      "Epoch 26/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4861 - loss: 0.8429\n",
      "Epoch 26: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4880 - loss: 0.8415 - val_accuracy: 0.5342 - val_loss: 0.8893\n",
      "Epoch 27/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4786 - loss: 0.8682\n",
      "Epoch 27: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4842 - loss: 0.8610 - val_accuracy: 0.5342 - val_loss: 0.9015\n",
      "Epoch 28/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5188 - loss: 0.8168\n",
      "Epoch 28: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5186 - loss: 0.8176 - val_accuracy: 0.5342 - val_loss: 0.8911\n",
      "Epoch 29/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4932 - loss: 0.8518\n",
      "Epoch 29: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4954 - loss: 0.8493 - val_accuracy: 0.5342 - val_loss: 0.9042\n",
      "Epoch 30/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5239 - loss: 0.8174\n",
      "Epoch 30: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5233 - loss: 0.8182 - val_accuracy: 0.5342 - val_loss: 0.9034\n",
      "Epoch 31/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5343 - loss: 0.8052\n",
      "Epoch 31: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5326 - loss: 0.8072 - val_accuracy: 0.5342 - val_loss: 0.8982\n",
      "Epoch 32/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5392 - loss: 0.8362\n",
      "Epoch 32: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5344 - loss: 0.8352 - val_accuracy: 0.5342 - val_loss: 0.8995\n",
      "Epoch 33/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5073 - loss: 0.7998\n",
      "Epoch 33: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5077 - loss: 0.8010 - val_accuracy: 0.5342 - val_loss: 0.8895\n",
      "Epoch 34/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5122 - loss: 0.8387\n",
      "Epoch 34: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5126 - loss: 0.8371 - val_accuracy: 0.5342 - val_loss: 0.9072\n",
      "Epoch 35/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5128 - loss: 0.7991\n",
      "Epoch 35: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5129 - loss: 0.8001 - val_accuracy: 0.5342 - val_loss: 0.8899\n",
      "Epoch 36/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4877 - loss: 0.8183\n",
      "Epoch 36: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4905 - loss: 0.8189 - val_accuracy: 0.5342 - val_loss: 0.8923\n",
      "Epoch 37/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5269 - loss: 0.8442\n",
      "Epoch 37: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5258 - loss: 0.8416 - val_accuracy: 0.5342 - val_loss: 0.9009\n",
      "Epoch 38/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5420 - loss: 0.8036\n",
      "Epoch 38: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5401 - loss: 0.8057 - val_accuracy: 0.5342 - val_loss: 0.8922\n",
      "Epoch 39/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5252 - loss: 0.8254\n",
      "Epoch 39: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5240 - loss: 0.8253 - val_accuracy: 0.5342 - val_loss: 0.8915\n",
      "Epoch 40/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5093 - loss: 0.8384\n",
      "Epoch 40: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5105 - loss: 0.8367 - val_accuracy: 0.5342 - val_loss: 0.9013\n",
      "Epoch 41/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5343 - loss: 0.8194\n",
      "Epoch 41: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5319 - loss: 0.8200 - val_accuracy: 0.5342 - val_loss: 0.8948\n",
      "Epoch 42/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5172 - loss: 0.8381\n",
      "Epoch 42: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5167 - loss: 0.8362 - val_accuracy: 0.5342 - val_loss: 0.9006\n",
      "Epoch 43/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5267 - loss: 0.8112\n",
      "Epoch 43: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5256 - loss: 0.8131 - val_accuracy: 0.5342 - val_loss: 0.8908\n",
      "Epoch 44/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5141 - loss: 0.8144\n",
      "Epoch 44: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5144 - loss: 0.8153 - val_accuracy: 0.5342 - val_loss: 0.8926\n",
      "Epoch 45/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5206 - loss: 0.8166\n",
      "Epoch 45: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5205 - loss: 0.8172 - val_accuracy: 0.5342 - val_loss: 0.8978\n",
      "Epoch 46/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5003 - loss: 0.8478\n",
      "Epoch 46: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5016 - loss: 0.8461 - val_accuracy: 0.5342 - val_loss: 0.8933\n",
      "Epoch 47/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5334 - loss: 0.8047\n",
      "Epoch 47: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5317 - loss: 0.8070 - val_accuracy: 0.5342 - val_loss: 0.8902\n",
      "Epoch 48/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5017 - loss: 0.8209\n",
      "Epoch 48: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5042 - loss: 0.8204 - val_accuracy: 0.5342 - val_loss: 0.8965\n",
      "Epoch 49/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5415 - loss: 0.8070\n",
      "Epoch 49: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5370 - loss: 0.8109 - val_accuracy: 0.5342 - val_loss: 0.8924\n",
      "Epoch 50/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5113 - loss: 0.8381\n",
      "Epoch 50: accuracy did not improve from 0.52444\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5119 - loss: 0.8373 - val_accuracy: 0.5342 - val_loss: 0.8929\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5877 - loss: 0.8369 \n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Entrenando con embeddings de tamaño: 400\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3409 - loss: 1.2834\n",
      "Epoch 1: accuracy improved from -inf to 0.40652, saving model to best_model_400_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.3513 - loss: 1.2641 - val_accuracy: 0.5342 - val_loss: 0.9478\n",
      "Epoch 2/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5074 - loss: 0.9648\n",
      "Epoch 2: accuracy improved from 0.40652 to 0.50272, saving model to best_model_400_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5071 - loss: 0.9649 - val_accuracy: 0.5342 - val_loss: 0.9021\n",
      "Epoch 3/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4603 - loss: 0.9593\n",
      "Epoch 3: accuracy did not improve from 0.50272\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4650 - loss: 0.9508 - val_accuracy: 0.5342 - val_loss: 0.8956\n",
      "Epoch 4/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5180 - loss: 0.8818\n",
      "Epoch 4: accuracy did not improve from 0.50272\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5138 - loss: 0.8826 - val_accuracy: 0.5342 - val_loss: 0.8856\n",
      "Epoch 5/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5170 - loss: 0.8566\n",
      "Epoch 5: accuracy improved from 0.50272 to 0.51358, saving model to best_model_400_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5166 - loss: 0.8593 - val_accuracy: 0.5342 - val_loss: 0.8867\n",
      "Epoch 6/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4965 - loss: 0.8708\n",
      "Epoch 6: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4972 - loss: 0.8702 - val_accuracy: 0.5342 - val_loss: 0.8901\n",
      "Epoch 7/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4937 - loss: 0.8647\n",
      "Epoch 7: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4940 - loss: 0.8640 - val_accuracy: 0.5404 - val_loss: 0.8924\n",
      "Epoch 8/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4992 - loss: 0.8573\n",
      "Epoch 8: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4956 - loss: 0.8559 - val_accuracy: 0.5404 - val_loss: 0.8994\n",
      "Epoch 9/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5015 - loss: 0.8345\n",
      "Epoch 9: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5043 - loss: 0.8367 - val_accuracy: 0.5342 - val_loss: 0.9008\n",
      "Epoch 10/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5294 - loss: 0.8433\n",
      "Epoch 10: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5289 - loss: 0.8434 - val_accuracy: 0.5280 - val_loss: 0.8958\n",
      "Epoch 11/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4844 - loss: 0.8727\n",
      "Epoch 11: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4855 - loss: 0.8713 - val_accuracy: 0.5404 - val_loss: 0.8890\n",
      "Epoch 12/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5176 - loss: 0.8168\n",
      "Epoch 12: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5167 - loss: 0.8198 - val_accuracy: 0.5280 - val_loss: 0.8979\n",
      "Epoch 13/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4735 - loss: 0.8568\n",
      "Epoch 13: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4738 - loss: 0.8571 - val_accuracy: 0.5342 - val_loss: 0.8935\n",
      "Epoch 14/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5076 - loss: 0.8328\n",
      "Epoch 14: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5054 - loss: 0.8336 - val_accuracy: 0.4658 - val_loss: 0.8976\n",
      "Epoch 15/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5082 - loss: 0.8307\n",
      "Epoch 15: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5081 - loss: 0.8308 - val_accuracy: 0.3913 - val_loss: 0.9073\n",
      "Epoch 16/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4708 - loss: 0.8534\n",
      "Epoch 16: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4725 - loss: 0.8510 - val_accuracy: 0.3913 - val_loss: 0.9090\n",
      "Epoch 17/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5009 - loss: 0.8511\n",
      "Epoch 17: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5016 - loss: 0.8482 - val_accuracy: 0.3975 - val_loss: 0.9018\n",
      "Epoch 18/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5132 - loss: 0.8300\n",
      "Epoch 18: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5118 - loss: 0.8293 - val_accuracy: 0.4472 - val_loss: 0.8972\n",
      "Epoch 19/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5178 - loss: 0.8330\n",
      "Epoch 19: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5152 - loss: 0.8327 - val_accuracy: 0.5342 - val_loss: 0.8929\n",
      "Epoch 20/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5110 - loss: 0.8290\n",
      "Epoch 20: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5097 - loss: 0.8298 - val_accuracy: 0.5155 - val_loss: 0.8942\n",
      "Epoch 21/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4941 - loss: 0.8592\n",
      "Epoch 21: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4932 - loss: 0.8558 - val_accuracy: 0.3975 - val_loss: 0.9007\n",
      "Epoch 22/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4683 - loss: 0.8284\n",
      "Epoch 22: accuracy did not improve from 0.51358\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4696 - loss: 0.8304 - val_accuracy: 0.3913 - val_loss: 0.9026\n",
      "Epoch 23/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5032 - loss: 0.8358\n",
      "Epoch 23: accuracy improved from 0.51358 to 0.51590, saving model to best_model_400_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5059 - loss: 0.8341 - val_accuracy: 0.3789 - val_loss: 0.9039\n",
      "Epoch 24/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4910 - loss: 0.8460\n",
      "Epoch 24: accuracy did not improve from 0.51590\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4918 - loss: 0.8442 - val_accuracy: 0.4596 - val_loss: 0.8959\n",
      "Epoch 25/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4880 - loss: 0.8430\n",
      "Epoch 25: accuracy did not improve from 0.51590\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4877 - loss: 0.8431 - val_accuracy: 0.3913 - val_loss: 0.8994\n",
      "Epoch 26/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5063 - loss: 0.8215\n",
      "Epoch 26: accuracy did not improve from 0.51590\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5063 - loss: 0.8222 - val_accuracy: 0.5342 - val_loss: 0.8905\n",
      "Epoch 27/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4559 - loss: 0.8143\n",
      "Epoch 27: accuracy did not improve from 0.51590\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4583 - loss: 0.8157 - val_accuracy: 0.5342 - val_loss: 0.8856\n",
      "Epoch 28/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5224 - loss: 0.8115\n",
      "Epoch 28: accuracy improved from 0.51590 to 0.52366, saving model to best_model_400_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5224 - loss: 0.8130 - val_accuracy: 0.5342 - val_loss: 0.8881\n",
      "Epoch 29/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5056 - loss: 0.8324\n",
      "Epoch 29: accuracy did not improve from 0.52366\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5053 - loss: 0.8323 - val_accuracy: 0.5280 - val_loss: 0.8914\n",
      "Epoch 30/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5183 - loss: 0.8242\n",
      "Epoch 30: accuracy did not improve from 0.52366\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5179 - loss: 0.8243 - val_accuracy: 0.5342 - val_loss: 0.8931\n",
      "Epoch 31/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5127 - loss: 0.7931\n",
      "Epoch 31: accuracy did not improve from 0.52366\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5109 - loss: 0.7987 - val_accuracy: 0.3975 - val_loss: 0.9011\n",
      "Epoch 32/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4886 - loss: 0.8469\n",
      "Epoch 32: accuracy did not improve from 0.52366\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4885 - loss: 0.8438 - val_accuracy: 0.3975 - val_loss: 0.8989\n",
      "Epoch 33/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5031 - loss: 0.8238\n",
      "Epoch 33: accuracy did not improve from 0.52366\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5024 - loss: 0.8240 - val_accuracy: 0.4099 - val_loss: 0.8987\n",
      "Epoch 34/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5156 - loss: 0.7998\n",
      "Epoch 34: accuracy did not improve from 0.52366\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5160 - loss: 0.8029 - val_accuracy: 0.3975 - val_loss: 0.9009\n",
      "Epoch 35/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5293 - loss: 0.8000\n",
      "Epoch 35: accuracy did not improve from 0.52366\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5276 - loss: 0.8035 - val_accuracy: 0.3851 - val_loss: 0.9036\n",
      "Epoch 36/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5230 - loss: 0.8169\n",
      "Epoch 36: accuracy improved from 0.52366 to 0.53297, saving model to best_model_400_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5237 - loss: 0.8171 - val_accuracy: 0.4534 - val_loss: 0.8978\n",
      "Epoch 37/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5090 - loss: 0.8286\n",
      "Epoch 37: accuracy did not improve from 0.53297\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5102 - loss: 0.8277 - val_accuracy: 0.5342 - val_loss: 0.8962\n",
      "Epoch 38/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5007 - loss: 0.8458\n",
      "Epoch 38: accuracy did not improve from 0.53297\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5029 - loss: 0.8419 - val_accuracy: 0.3913 - val_loss: 0.9078\n",
      "Epoch 39/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4916 - loss: 0.8225\n",
      "Epoch 39: accuracy did not improve from 0.53297\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4935 - loss: 0.8238 - val_accuracy: 0.3913 - val_loss: 0.9148\n",
      "Epoch 40/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4958 - loss: 0.8118\n",
      "Epoch 40: accuracy did not improve from 0.53297\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4978 - loss: 0.8139 - val_accuracy: 0.3913 - val_loss: 0.9109\n",
      "Epoch 41/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5208 - loss: 0.8044\n",
      "Epoch 41: accuracy did not improve from 0.53297\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5192 - loss: 0.8084 - val_accuracy: 0.3913 - val_loss: 0.9099\n",
      "Epoch 42/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5267 - loss: 0.7897\n",
      "Epoch 42: accuracy did not improve from 0.53297\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5266 - loss: 0.7913 - val_accuracy: 0.3913 - val_loss: 0.9060\n",
      "Epoch 43/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5017 - loss: 0.8515\n",
      "Epoch 43: accuracy did not improve from 0.53297\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5035 - loss: 0.8485 - val_accuracy: 0.3913 - val_loss: 0.9057\n",
      "Epoch 44/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4828 - loss: 0.8297\n",
      "Epoch 44: accuracy did not improve from 0.53297\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4846 - loss: 0.8295 - val_accuracy: 0.3913 - val_loss: 0.9005\n",
      "Epoch 45/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5204 - loss: 0.8350\n",
      "Epoch 45: accuracy did not improve from 0.53297\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5201 - loss: 0.8345 - val_accuracy: 0.4037 - val_loss: 0.8955\n",
      "Epoch 46/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5098 - loss: 0.8293\n",
      "Epoch 46: accuracy did not improve from 0.53297\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5094 - loss: 0.8293 - val_accuracy: 0.3975 - val_loss: 0.9124\n",
      "Epoch 47/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4828 - loss: 0.8527\n",
      "Epoch 47: accuracy did not improve from 0.53297\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4852 - loss: 0.8483 - val_accuracy: 0.5404 - val_loss: 0.8977\n",
      "Epoch 48/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5081 - loss: 0.8066\n",
      "Epoch 48: accuracy did not improve from 0.53297\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5087 - loss: 0.8073 - val_accuracy: 0.5280 - val_loss: 0.8959\n",
      "Epoch 49/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5136 - loss: 0.8309\n",
      "Epoch 49: accuracy did not improve from 0.53297\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5138 - loss: 0.8307 - val_accuracy: 0.3975 - val_loss: 0.8966\n",
      "Epoch 50/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5197 - loss: 0.8267\n",
      "Epoch 50: accuracy did not improve from 0.53297\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5197 - loss: 0.8266 - val_accuracy: 0.5155 - val_loss: 0.8957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5643 - loss: 0.8380 \n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con embeddings de tamaño: 500\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4110 - loss: 0.9694\n",
      "Epoch 1: accuracy improved from -inf to 0.45462, saving model to best_model_500_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.4151 - loss: 0.9617 - val_accuracy: 0.5342 - val_loss: 0.9143\n",
      "Epoch 2/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5186 - loss: 0.8367\n",
      "Epoch 2: accuracy improved from 0.45462 to 0.51746, saving model to best_model_500_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5184 - loss: 0.8351 - val_accuracy: 0.5342 - val_loss: 0.9002\n",
      "Epoch 3/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4951 - loss: 0.8377\n",
      "Epoch 3: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4962 - loss: 0.8359 - val_accuracy: 0.5342 - val_loss: 0.9032\n",
      "Epoch 4/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4886 - loss: 0.8542\n",
      "Epoch 4: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4883 - loss: 0.8489 - val_accuracy: 0.5342 - val_loss: 0.9010\n",
      "Epoch 5/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5186 - loss: 0.8126\n",
      "Epoch 5: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5161 - loss: 0.8136 - val_accuracy: 0.5342 - val_loss: 0.8965\n",
      "Epoch 6/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4857 - loss: 0.8356\n",
      "Epoch 6: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4877 - loss: 0.8337 - val_accuracy: 0.5342 - val_loss: 0.9085\n",
      "Epoch 7/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4515 - loss: 0.8253\n",
      "Epoch 7: accuracy did not improve from 0.51746\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4537 - loss: 0.8253 - val_accuracy: 0.3975 - val_loss: 0.9062\n",
      "Epoch 8/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4935 - loss: 0.8266\n",
      "Epoch 8: accuracy improved from 0.51746 to 0.51901, saving model to best_model_500_simple.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4982 - loss: 0.8254 - val_accuracy: 0.5342 - val_loss: 0.8970\n",
      "Epoch 9/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4901 - loss: 0.8350\n",
      "Epoch 9: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4906 - loss: 0.8341 - val_accuracy: 0.5342 - val_loss: 0.9131\n",
      "Epoch 10/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5069 - loss: 0.8367\n",
      "Epoch 10: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5080 - loss: 0.8353 - val_accuracy: 0.5342 - val_loss: 0.9087\n",
      "Epoch 11/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4506 - loss: 0.7985\n",
      "Epoch 11: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4528 - loss: 0.8005 - val_accuracy: 0.5342 - val_loss: 0.8947\n",
      "Epoch 12/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5171 - loss: 0.8118\n",
      "Epoch 12: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5172 - loss: 0.8125 - val_accuracy: 0.5342 - val_loss: 0.8922\n",
      "Epoch 13/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5323 - loss: 0.8322\n",
      "Epoch 13: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5268 - loss: 0.8308 - val_accuracy: 0.5342 - val_loss: 0.8967\n",
      "Epoch 14/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5315 - loss: 0.8375\n",
      "Epoch 14: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5286 - loss: 0.8351 - val_accuracy: 0.3975 - val_loss: 0.9231\n",
      "Epoch 15/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4904 - loss: 0.8325\n",
      "Epoch 15: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4941 - loss: 0.8308 - val_accuracy: 0.5342 - val_loss: 0.9046\n",
      "Epoch 16/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5452 - loss: 0.8169\n",
      "Epoch 16: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5430 - loss: 0.8172 - val_accuracy: 0.3913 - val_loss: 0.9032\n",
      "Epoch 17/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5063 - loss: 0.7925\n",
      "Epoch 17: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5070 - loss: 0.7954 - val_accuracy: 0.5342 - val_loss: 0.8921\n",
      "Epoch 18/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5154 - loss: 0.8281\n",
      "Epoch 18: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5118 - loss: 0.8278 - val_accuracy: 0.5342 - val_loss: 0.8941\n",
      "Epoch 19/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4707 - loss: 0.8304\n",
      "Epoch 19: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4741 - loss: 0.8294 - val_accuracy: 0.5342 - val_loss: 0.8962\n",
      "Epoch 20/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5013 - loss: 0.8313\n",
      "Epoch 20: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5041 - loss: 0.8299 - val_accuracy: 0.5342 - val_loss: 0.9019\n",
      "Epoch 21/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5143 - loss: 0.8134\n",
      "Epoch 21: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5147 - loss: 0.8147 - val_accuracy: 0.5342 - val_loss: 0.8906\n",
      "Epoch 22/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5000 - loss: 0.8303\n",
      "Epoch 22: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5017 - loss: 0.8296 - val_accuracy: 0.5342 - val_loss: 0.9100\n",
      "Epoch 23/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4899 - loss: 0.8216\n",
      "Epoch 23: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4899 - loss: 0.8221 - val_accuracy: 0.5342 - val_loss: 0.8977\n",
      "Epoch 24/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4948 - loss: 0.8280\n",
      "Epoch 24: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4944 - loss: 0.8278 - val_accuracy: 0.5342 - val_loss: 0.8997\n",
      "Epoch 25/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5077 - loss: 0.8145\n",
      "Epoch 25: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5086 - loss: 0.8151 - val_accuracy: 0.5342 - val_loss: 0.8894\n",
      "Epoch 26/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5114 - loss: 0.8289\n",
      "Epoch 26: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5121 - loss: 0.8284 - val_accuracy: 0.5342 - val_loss: 0.8950\n",
      "Epoch 27/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5162 - loss: 0.8274\n",
      "Epoch 27: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5163 - loss: 0.8269 - val_accuracy: 0.5342 - val_loss: 0.8992\n",
      "Epoch 28/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5282 - loss: 0.8204\n",
      "Epoch 28: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5267 - loss: 0.8203 - val_accuracy: 0.5342 - val_loss: 0.9035\n",
      "Epoch 29/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5135 - loss: 0.8258\n",
      "Epoch 29: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5140 - loss: 0.8251 - val_accuracy: 0.5342 - val_loss: 0.9054\n",
      "Epoch 30/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5149 - loss: 0.8258\n",
      "Epoch 30: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5151 - loss: 0.8252 - val_accuracy: 0.5342 - val_loss: 0.9018\n",
      "Epoch 31/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4923 - loss: 0.7948\n",
      "Epoch 31: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4946 - loss: 0.7969 - val_accuracy: 0.5342 - val_loss: 0.8861\n",
      "Epoch 32/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4862 - loss: 0.8292\n",
      "Epoch 32: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4877 - loss: 0.8291 - val_accuracy: 0.5342 - val_loss: 0.9010\n",
      "Epoch 33/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5120 - loss: 0.8401\n",
      "Epoch 33: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5130 - loss: 0.8373 - val_accuracy: 0.5342 - val_loss: 0.9059\n",
      "Epoch 34/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5180 - loss: 0.8055\n",
      "Epoch 34: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5180 - loss: 0.8062 - val_accuracy: 0.5342 - val_loss: 0.8904\n",
      "Epoch 35/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5260 - loss: 0.8220\n",
      "Epoch 35: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5246 - loss: 0.8215 - val_accuracy: 0.5342 - val_loss: 0.8979\n",
      "Epoch 36/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5004 - loss: 0.7963\n",
      "Epoch 36: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5006 - loss: 0.7969 - val_accuracy: 0.5342 - val_loss: 0.8857\n",
      "Epoch 37/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5208 - loss: 0.8201\n",
      "Epoch 37: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5202 - loss: 0.8201 - val_accuracy: 0.5342 - val_loss: 0.9013\n",
      "Epoch 38/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5162 - loss: 0.8160\n",
      "Epoch 38: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5163 - loss: 0.8162 - val_accuracy: 0.5342 - val_loss: 0.8989\n",
      "Epoch 39/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5399 - loss: 0.7948\n",
      "Epoch 39: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5331 - loss: 0.8001 - val_accuracy: 0.5342 - val_loss: 0.8858\n",
      "Epoch 40/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5466 - loss: 0.8037\n",
      "Epoch 40: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5448 - loss: 0.8047 - val_accuracy: 0.5342 - val_loss: 0.8894\n",
      "Epoch 41/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5119 - loss: 0.8170\n",
      "Epoch 41: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5125 - loss: 0.8174 - val_accuracy: 0.5342 - val_loss: 0.8984\n",
      "Epoch 42/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4617 - loss: 0.8169\n",
      "Epoch 42: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4655 - loss: 0.8179 - val_accuracy: 0.5342 - val_loss: 0.8938\n",
      "Epoch 43/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5082 - loss: 0.8133\n",
      "Epoch 43: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5099 - loss: 0.8149 - val_accuracy: 0.5342 - val_loss: 0.8971\n",
      "Epoch 44/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5231 - loss: 0.8310\n",
      "Epoch 44: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5223 - loss: 0.8290 - val_accuracy: 0.5342 - val_loss: 0.9025\n",
      "Epoch 45/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4939 - loss: 0.8336\n",
      "Epoch 45: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4948 - loss: 0.8332 - val_accuracy: 0.5342 - val_loss: 0.9088\n",
      "Epoch 46/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5231 - loss: 0.8397\n",
      "Epoch 46: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5227 - loss: 0.8384 - val_accuracy: 0.5155 - val_loss: 0.9125\n",
      "Epoch 47/50\n",
      "\u001b[1m30/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4908 - loss: 0.8403\n",
      "Epoch 47: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4936 - loss: 0.8358 - val_accuracy: 0.5342 - val_loss: 0.8974\n",
      "Epoch 48/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5390 - loss: 0.8006\n",
      "Epoch 48: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5358 - loss: 0.8035 - val_accuracy: 0.5342 - val_loss: 0.8934\n",
      "Epoch 49/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5269 - loss: 0.8155\n",
      "Epoch 49: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5264 - loss: 0.8158 - val_accuracy: 0.5342 - val_loss: 0.8986\n",
      "Epoch 50/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5111 - loss: 0.8199\n",
      "Epoch 50: accuracy did not improve from 0.51901\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5121 - loss: 0.8195 - val_accuracy: 0.5342 - val_loss: 0.9059\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5877 - loss: 0.8369\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Entrenando con embeddings de tamaño: 500\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4502 - loss: 0.9745\n",
      "Epoch 1: accuracy improved from -inf to 0.47867, saving model to best_model_500_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.4538 - loss: 0.9659 - val_accuracy: 0.5342 - val_loss: 0.8881\n",
      "Epoch 2/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5028 - loss: 0.8410\n",
      "Epoch 2: accuracy improved from 0.47867 to 0.50039, saving model to best_model_500_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5026 - loss: 0.8422 - val_accuracy: 0.3975 - val_loss: 0.9147\n",
      "Epoch 3/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4902 - loss: 0.8337\n",
      "Epoch 3: accuracy did not improve from 0.50039\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4913 - loss: 0.8344 - val_accuracy: 0.5342 - val_loss: 0.8923\n",
      "Epoch 4/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5119 - loss: 0.8409\n",
      "Epoch 4: accuracy improved from 0.50039 to 0.50659, saving model to best_model_500_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5116 - loss: 0.8406 - val_accuracy: 0.5342 - val_loss: 0.8939\n",
      "Epoch 5/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5270 - loss: 0.8160\n",
      "Epoch 5: accuracy improved from 0.50659 to 0.50970, saving model to best_model_500_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5262 - loss: 0.8168 - val_accuracy: 0.5342 - val_loss: 0.8891\n",
      "Epoch 6/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4715 - loss: 0.8438\n",
      "Epoch 6: accuracy did not improve from 0.50970\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4720 - loss: 0.8437 - val_accuracy: 0.5342 - val_loss: 0.9000\n",
      "Epoch 7/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4894 - loss: 0.8323\n",
      "Epoch 7: accuracy did not improve from 0.50970\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4895 - loss: 0.8321 - val_accuracy: 0.5342 - val_loss: 0.9043\n",
      "Epoch 8/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4898 - loss: 0.8493\n",
      "Epoch 8: accuracy did not improve from 0.50970\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4904 - loss: 0.8484 - val_accuracy: 0.5342 - val_loss: 0.9026\n",
      "Epoch 9/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4917 - loss: 0.8072\n",
      "Epoch 9: accuracy did not improve from 0.50970\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4916 - loss: 0.8082 - val_accuracy: 0.5342 - val_loss: 0.8920\n",
      "Epoch 10/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.8113\n",
      "Epoch 10: accuracy did not improve from 0.50970\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5279 - loss: 0.8139 - val_accuracy: 0.5342 - val_loss: 0.8967\n",
      "Epoch 11/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5155 - loss: 0.8291\n",
      "Epoch 11: accuracy did not improve from 0.50970\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5149 - loss: 0.8292 - val_accuracy: 0.5342 - val_loss: 0.8927\n",
      "Epoch 12/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5105 - loss: 0.8296\n",
      "Epoch 12: accuracy improved from 0.50970 to 0.52521, saving model to best_model_500_deep.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5115 - loss: 0.8293 - val_accuracy: 0.5342 - val_loss: 0.9035\n",
      "Epoch 13/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5248 - loss: 0.8421\n",
      "Epoch 13: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5233 - loss: 0.8413 - val_accuracy: 0.5342 - val_loss: 0.8950\n",
      "Epoch 14/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4981 - loss: 0.8138\n",
      "Epoch 14: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4979 - loss: 0.8151 - val_accuracy: 0.5342 - val_loss: 0.9008\n",
      "Epoch 15/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5035 - loss: 0.8254\n",
      "Epoch 15: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5059 - loss: 0.8251 - val_accuracy: 0.5342 - val_loss: 0.8913\n",
      "Epoch 16/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5039 - loss: 0.8244\n",
      "Epoch 16: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5041 - loss: 0.8245 - val_accuracy: 0.5342 - val_loss: 0.8950\n",
      "Epoch 17/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5074 - loss: 0.8099\n",
      "Epoch 17: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5070 - loss: 0.8150 - val_accuracy: 0.5342 - val_loss: 0.8959\n",
      "Epoch 18/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4953 - loss: 0.8505\n",
      "Epoch 18: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4972 - loss: 0.8477 - val_accuracy: 0.5342 - val_loss: 0.9204\n",
      "Epoch 19/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4874 - loss: 0.8534\n",
      "Epoch 19: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4897 - loss: 0.8499 - val_accuracy: 0.5342 - val_loss: 0.9063\n",
      "Epoch 20/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5337 - loss: 0.8175\n",
      "Epoch 20: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5290 - loss: 0.8209 - val_accuracy: 0.5342 - val_loss: 0.8964\n",
      "Epoch 21/50\n",
      "\u001b[1m34/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5208 - loss: 0.8202\n",
      "Epoch 21: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5219 - loss: 0.8213 - val_accuracy: 0.5342 - val_loss: 0.8902\n",
      "Epoch 22/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5210 - loss: 0.8130\n",
      "Epoch 22: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5204 - loss: 0.8133 - val_accuracy: 0.5342 - val_loss: 0.8978\n",
      "Epoch 23/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4984 - loss: 0.8350\n",
      "Epoch 23: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4992 - loss: 0.8342 - val_accuracy: 0.5342 - val_loss: 0.8953\n",
      "Epoch 24/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5212 - loss: 0.8069\n",
      "Epoch 24: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5207 - loss: 0.8079 - val_accuracy: 0.5342 - val_loss: 0.8904\n",
      "Epoch 25/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4784 - loss: 0.8256\n",
      "Epoch 25: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4794 - loss: 0.8258 - val_accuracy: 0.5342 - val_loss: 0.8926\n",
      "Epoch 26/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4924 - loss: 0.8433\n",
      "Epoch 26: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4930 - loss: 0.8428 - val_accuracy: 0.5342 - val_loss: 0.9060\n",
      "Epoch 27/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5260 - loss: 0.8168\n",
      "Epoch 27: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5230 - loss: 0.8194 - val_accuracy: 0.5342 - val_loss: 0.8957\n",
      "Epoch 28/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5097 - loss: 0.8242\n",
      "Epoch 28: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5113 - loss: 0.8245 - val_accuracy: 0.5342 - val_loss: 0.8956\n",
      "Epoch 29/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5359 - loss: 0.8247\n",
      "Epoch 29: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5352 - loss: 0.8248 - val_accuracy: 0.5342 - val_loss: 0.9003\n",
      "Epoch 30/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4488 - loss: 0.8494\n",
      "Epoch 30: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4522 - loss: 0.8465 - val_accuracy: 0.5342 - val_loss: 0.8936\n",
      "Epoch 31/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5239 - loss: 0.8377\n",
      "Epoch 31: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5232 - loss: 0.8356 - val_accuracy: 0.5342 - val_loss: 0.9078\n",
      "Epoch 32/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5154 - loss: 0.8139\n",
      "Epoch 32: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5152 - loss: 0.8148 - val_accuracy: 0.5342 - val_loss: 0.9094\n",
      "Epoch 33/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5276 - loss: 0.8310\n",
      "Epoch 33: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5258 - loss: 0.8308 - val_accuracy: 0.5342 - val_loss: 0.9074\n",
      "Epoch 34/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4883 - loss: 0.8422\n",
      "Epoch 34: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4895 - loss: 0.8415 - val_accuracy: 0.5342 - val_loss: 0.9019\n",
      "Epoch 35/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5435 - loss: 0.8047 \n",
      "Epoch 35: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5419 - loss: 0.8058 - val_accuracy: 0.5342 - val_loss: 0.8949\n",
      "Epoch 36/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5213 - loss: 0.8305\n",
      "Epoch 36: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5208 - loss: 0.8303 - val_accuracy: 0.5342 - val_loss: 0.8959\n",
      "Epoch 37/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5264 - loss: 0.8174\n",
      "Epoch 37: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5259 - loss: 0.8180 - val_accuracy: 0.5342 - val_loss: 0.8890\n",
      "Epoch 38/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5278 - loss: 0.7946\n",
      "Epoch 38: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5264 - loss: 0.7988 - val_accuracy: 0.5342 - val_loss: 0.8897\n",
      "Epoch 39/50\n",
      "\u001b[1m33/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5343 - loss: 0.8198\n",
      "Epoch 39: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5312 - loss: 0.8199 - val_accuracy: 0.5342 - val_loss: 0.8964\n",
      "Epoch 40/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5153 - loss: 0.8199\n",
      "Epoch 40: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5154 - loss: 0.8201 - val_accuracy: 0.5342 - val_loss: 0.8963\n",
      "Epoch 41/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5370 - loss: 0.8095\n",
      "Epoch 41: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5343 - loss: 0.8124 - val_accuracy: 0.5342 - val_loss: 0.8949\n",
      "Epoch 42/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5197 - loss: 0.8260\n",
      "Epoch 42: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5193 - loss: 0.8258 - val_accuracy: 0.5342 - val_loss: 0.8945\n",
      "Epoch 43/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5136 - loss: 0.8210\n",
      "Epoch 43: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5136 - loss: 0.8212 - val_accuracy: 0.5342 - val_loss: 0.8935\n",
      "Epoch 44/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5122 - loss: 0.8450\n",
      "Epoch 44: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5131 - loss: 0.8432 - val_accuracy: 0.5342 - val_loss: 0.8980\n",
      "Epoch 45/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5247 - loss: 0.8183\n",
      "Epoch 45: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5245 - loss: 0.8185 - val_accuracy: 0.5342 - val_loss: 0.9001\n",
      "Epoch 46/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5163 - loss: 0.8144\n",
      "Epoch 46: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5173 - loss: 0.8148 - val_accuracy: 0.5342 - val_loss: 0.8954\n",
      "Epoch 47/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5115 - loss: 0.8174\n",
      "Epoch 47: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5101 - loss: 0.8183 - val_accuracy: 0.5342 - val_loss: 0.8965\n",
      "Epoch 48/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5308 - loss: 0.8108\n",
      "Epoch 48: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5287 - loss: 0.8128 - val_accuracy: 0.5342 - val_loss: 0.8967\n",
      "Epoch 49/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5207 - loss: 0.8135\n",
      "Epoch 49: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5193 - loss: 0.8146 - val_accuracy: 0.5342 - val_loss: 0.8940\n",
      "Epoch 50/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5324 - loss: 0.8036\n",
      "Epoch 50: accuracy did not improve from 0.52521\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5303 - loss: 0.8059 - val_accuracy: 0.5342 - val_loss: 0.8948\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5877 - loss: 0.8379\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Entrenando con embeddings de tamaño: 500\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3046 - loss: 1.4561\n",
      "Epoch 1: accuracy improved from -inf to 0.35531, saving model to best_model_500_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.3103 - loss: 1.4380 - val_accuracy: 0.5404 - val_loss: 1.0546\n",
      "Epoch 2/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4482 - loss: 1.0234\n",
      "Epoch 2: accuracy improved from 0.35531 to 0.44220, saving model to best_model_500_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4475 - loss: 1.0231 - val_accuracy: 0.5342 - val_loss: 0.9682\n",
      "Epoch 3/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4752 - loss: 0.9312\n",
      "Epoch 3: accuracy improved from 0.44220 to 0.47634, saving model to best_model_500_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4753 - loss: 0.9302 - val_accuracy: 0.5342 - val_loss: 0.9220\n",
      "Epoch 4/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5096 - loss: 0.8959\n",
      "Epoch 4: accuracy improved from 0.47634 to 0.49418, saving model to best_model_500_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5081 - loss: 0.8948 - val_accuracy: 0.3975 - val_loss: 0.9430\n",
      "Epoch 5/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4785 - loss: 0.9020\n",
      "Epoch 5: accuracy did not improve from 0.49418\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4794 - loss: 0.8995 - val_accuracy: 0.3975 - val_loss: 0.9216\n",
      "Epoch 6/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4967 - loss: 0.9036\n",
      "Epoch 6: accuracy did not improve from 0.49418\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4966 - loss: 0.9033 - val_accuracy: 0.3913 - val_loss: 0.9206\n",
      "Epoch 7/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5046 - loss: 0.8611\n",
      "Epoch 7: accuracy did not improve from 0.49418\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5031 - loss: 0.8627 - val_accuracy: 0.3913 - val_loss: 0.9045\n",
      "Epoch 8/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4617 - loss: 0.8701\n",
      "Epoch 8: accuracy improved from 0.49418 to 0.49496, saving model to best_model_500_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4640 - loss: 0.8682 - val_accuracy: 0.4783 - val_loss: 0.8952\n",
      "Epoch 9/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5247 - loss: 0.8524\n",
      "Epoch 9: accuracy improved from 0.49496 to 0.50194, saving model to best_model_500_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5218 - loss: 0.8526 - val_accuracy: 0.5404 - val_loss: 0.8951\n",
      "Epoch 10/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4924 - loss: 0.8528\n",
      "Epoch 10: accuracy did not improve from 0.50194\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4925 - loss: 0.8528 - val_accuracy: 0.3913 - val_loss: 0.9062\n",
      "Epoch 11/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4996 - loss: 0.8278\n",
      "Epoch 11: accuracy did not improve from 0.50194\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4978 - loss: 0.8319 - val_accuracy: 0.3851 - val_loss: 0.9080\n",
      "Epoch 12/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4728 - loss: 0.8621\n",
      "Epoch 12: accuracy did not improve from 0.50194\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4733 - loss: 0.8616 - val_accuracy: 0.4348 - val_loss: 0.8942\n",
      "Epoch 13/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5046 - loss: 0.8301\n",
      "Epoch 13: accuracy did not improve from 0.50194\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5013 - loss: 0.8331 - val_accuracy: 0.5466 - val_loss: 0.8961\n",
      "Epoch 14/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5124 - loss: 0.8409\n",
      "Epoch 14: accuracy improved from 0.50194 to 0.50272, saving model to best_model_500_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5119 - loss: 0.8408 - val_accuracy: 0.3975 - val_loss: 0.9043\n",
      "Epoch 15/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4490 - loss: 0.8525\n",
      "Epoch 15: accuracy did not improve from 0.50272\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4533 - loss: 0.8520 - val_accuracy: 0.3913 - val_loss: 0.8982\n",
      "Epoch 16/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4803 - loss: 0.8606\n",
      "Epoch 16: accuracy improved from 0.50272 to 0.50504, saving model to best_model_500_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4820 - loss: 0.8588 - val_accuracy: 0.4658 - val_loss: 0.8952\n",
      "Epoch 17/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5109 - loss: 0.8187\n",
      "Epoch 17: accuracy improved from 0.50504 to 0.52366, saving model to best_model_500_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5124 - loss: 0.8197 - val_accuracy: 0.5342 - val_loss: 0.8898\n",
      "Epoch 18/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4663 - loss: 0.8579\n",
      "Epoch 18: accuracy did not improve from 0.52366\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4668 - loss: 0.8577 - val_accuracy: 0.5404 - val_loss: 1.0684\n",
      "Epoch 19/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5165 - loss: 0.8414\n",
      "Epoch 19: accuracy did not improve from 0.52366\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5166 - loss: 0.8411 - val_accuracy: 0.4534 - val_loss: 0.9251\n",
      "Epoch 20/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5203 - loss: 0.8191\n",
      "Epoch 20: accuracy did not improve from 0.52366\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5197 - loss: 0.8205 - val_accuracy: 0.3913 - val_loss: 0.9076\n",
      "Epoch 21/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5138 - loss: 0.8336\n",
      "Epoch 21: accuracy did not improve from 0.52366\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5139 - loss: 0.8334 - val_accuracy: 0.3913 - val_loss: 0.9076\n",
      "Epoch 22/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5002 - loss: 0.8569\n",
      "Epoch 22: accuracy improved from 0.52366 to 0.52599, saving model to best_model_500_batchNorm.keras\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5034 - loss: 0.8532 - val_accuracy: 0.3913 - val_loss: 0.9110\n",
      "Epoch 23/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4997 - loss: 0.8519\n",
      "Epoch 23: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5008 - loss: 0.8507 - val_accuracy: 0.3913 - val_loss: 0.9104\n",
      "Epoch 24/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4872 - loss: 0.8569\n",
      "Epoch 24: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4859 - loss: 0.8556 - val_accuracy: 0.3913 - val_loss: 0.9071\n",
      "Epoch 25/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5235 - loss: 0.8385\n",
      "Epoch 25: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5224 - loss: 0.8379 - val_accuracy: 0.3913 - val_loss: 0.9044\n",
      "Epoch 26/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5015 - loss: 0.8339\n",
      "Epoch 26: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5016 - loss: 0.8342 - val_accuracy: 0.3913 - val_loss: 0.9061\n",
      "Epoch 27/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5153 - loss: 0.8146\n",
      "Epoch 27: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5152 - loss: 0.8148 - val_accuracy: 0.3913 - val_loss: 0.9233\n",
      "Epoch 28/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4625 - loss: 0.8191\n",
      "Epoch 28: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4632 - loss: 0.8200 - val_accuracy: 0.3913 - val_loss: 0.9114\n",
      "Epoch 29/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5005 - loss: 0.8435\n",
      "Epoch 29: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5005 - loss: 0.8423 - val_accuracy: 0.3913 - val_loss: 0.9044\n",
      "Epoch 30/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5227 - loss: 0.8077\n",
      "Epoch 30: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5218 - loss: 0.8100 - val_accuracy: 0.3913 - val_loss: 0.9155\n",
      "Epoch 31/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4953 - loss: 0.8461\n",
      "Epoch 31: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4951 - loss: 0.8458 - val_accuracy: 0.4099 - val_loss: 0.8999\n",
      "Epoch 32/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5114 - loss: 0.8244\n",
      "Epoch 32: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5111 - loss: 0.8246 - val_accuracy: 0.4907 - val_loss: 0.8944\n",
      "Epoch 33/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5247 - loss: 0.8278\n",
      "Epoch 33: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5239 - loss: 0.8281 - val_accuracy: 0.5155 - val_loss: 0.8962\n",
      "Epoch 34/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5186 - loss: 0.8348\n",
      "Epoch 34: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5186 - loss: 0.8347 - val_accuracy: 0.3975 - val_loss: 0.9014\n",
      "Epoch 35/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5087 - loss: 0.8042\n",
      "Epoch 35: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5087 - loss: 0.8070 - val_accuracy: 0.4099 - val_loss: 0.8999\n",
      "Epoch 36/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5444 - loss: 0.8071\n",
      "Epoch 36: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5432 - loss: 0.8080 - val_accuracy: 0.3975 - val_loss: 0.9068\n",
      "Epoch 37/50\n",
      "\u001b[1m39/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5283 - loss: 0.8215\n",
      "Epoch 37: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5280 - loss: 0.8222 - val_accuracy: 0.3975 - val_loss: 0.9078\n",
      "Epoch 38/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5178 - loss: 0.8331\n",
      "Epoch 38: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5173 - loss: 0.8330 - val_accuracy: 0.3975 - val_loss: 0.9147\n",
      "Epoch 39/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4913 - loss: 0.8181\n",
      "Epoch 39: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4924 - loss: 0.8185 - val_accuracy: 0.3913 - val_loss: 0.9160\n",
      "Epoch 40/50\n",
      "\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4803 - loss: 0.8261\n",
      "Epoch 40: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4841 - loss: 0.8259 - val_accuracy: 0.3913 - val_loss: 0.9086\n",
      "Epoch 41/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5255 - loss: 0.8320\n",
      "Epoch 41: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5245 - loss: 0.8317 - val_accuracy: 0.5217 - val_loss: 0.8909\n",
      "Epoch 42/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5169 - loss: 0.8029\n",
      "Epoch 42: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5170 - loss: 0.8049 - val_accuracy: 0.4472 - val_loss: 0.8979\n",
      "Epoch 43/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5264 - loss: 0.8064\n",
      "Epoch 43: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5249 - loss: 0.8075 - val_accuracy: 0.4720 - val_loss: 0.8961\n",
      "Epoch 44/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5180 - loss: 0.8139\n",
      "Epoch 44: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5168 - loss: 0.8170 - val_accuracy: 0.3913 - val_loss: 0.8997\n",
      "Epoch 45/50\n",
      "\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5020 - loss: 0.8209\n",
      "Epoch 45: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5020 - loss: 0.8209 - val_accuracy: 0.5093 - val_loss: 0.8965\n",
      "Epoch 46/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4823 - loss: 0.8070\n",
      "Epoch 46: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4838 - loss: 0.8088 - val_accuracy: 0.5342 - val_loss: 0.8882\n",
      "Epoch 47/50\n",
      "\u001b[1m38/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5106 - loss: 0.8240\n",
      "Epoch 47: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5091 - loss: 0.8244 - val_accuracy: 0.5342 - val_loss: 0.8881\n",
      "Epoch 48/50\n",
      "\u001b[1m37/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5180 - loss: 0.8255\n",
      "Epoch 48: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5158 - loss: 0.8257 - val_accuracy: 0.5093 - val_loss: 0.8911\n",
      "Epoch 49/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5064 - loss: 0.8270\n",
      "Epoch 49: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5066 - loss: 0.8269 - val_accuracy: 0.5342 - val_loss: 1.0054\n",
      "Epoch 50/50\n",
      "\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5254 - loss: 0.8141\n",
      "Epoch 50: accuracy did not improve from 0.52599\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5245 - loss: 0.8152 - val_accuracy: 0.5155 - val_loss: 0.8933\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5622 - loss: 0.8453\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Results for embeddings size 300_simple:\n",
      "Accuracy: 0.5479876399040222\n",
      "Precision: 0.30029042739794304\n",
      "Recall: 0.5479876160990712\n",
      "F1 Score: 0.3879752321981424\n",
      "Results for embeddings size 300_deep:\n",
      "Accuracy: 0.5479876399040222\n",
      "Precision: 0.30029042739794304\n",
      "Recall: 0.5479876160990712\n",
      "F1 Score: 0.3879752321981424\n",
      "Results for embeddings size 300_batchNorm:\n",
      "Accuracy: 0.396284818649292\n",
      "Precision: 0.16048918337625262\n",
      "Recall: 0.39628482972136225\n",
      "F1 Score: 0.22845688631386737\n",
      "Results for embeddings size 400_simple:\n",
      "Accuracy: 0.5479876399040222\n",
      "Precision: 0.30029042739794304\n",
      "Recall: 0.5479876160990712\n",
      "F1 Score: 0.3879752321981424\n",
      "Results for embeddings size 400_deep:\n",
      "Accuracy: 0.5479876399040222\n",
      "Precision: 0.30029042739794304\n",
      "Recall: 0.5479876160990712\n",
      "F1 Score: 0.3879752321981424\n",
      "Results for embeddings size 400_batchNorm:\n",
      "Accuracy: 0.5510835647583008\n",
      "Precision: 0.527672929301497\n",
      "Recall: 0.5510835913312694\n",
      "F1 Score: 0.5386996904024768\n",
      "Results for embeddings size 500_simple:\n",
      "Accuracy: 0.5479876399040222\n",
      "Precision: 0.30029042739794304\n",
      "Recall: 0.5479876160990712\n",
      "F1 Score: 0.3879752321981424\n",
      "Results for embeddings size 500_deep:\n",
      "Accuracy: 0.5479876399040222\n",
      "Precision: 0.30029042739794304\n",
      "Recall: 0.5479876160990712\n",
      "F1 Score: 0.3879752321981424\n",
      "Results for embeddings size 500_batchNorm:\n",
      "Accuracy: 0.5479876399040222\n",
      "Precision: 0.5198605234185846\n",
      "Recall: 0.5479876160990712\n",
      "F1 Score: 0.5335151238313194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Definir el diccionario vacío donde se almacenarán los resultados\n",
    "results = {}\n",
    "\n",
    "embedding_sizes = [300, 400, 500]\n",
    "\n",
    "# Entrenamiento y evaluación para cada tamaño de embedding\n",
    "for size in embedding_sizes:\n",
    "    # Cargar el modelo Word2Vec preentrenado con el tamaño de embedding actual\n",
    "    word2vecModel = Word2Vec.load(f\"Books_{size}_G4.model\")\n",
    "    vocab_size = len(word2vecModel.wv.key_to_index)\n",
    "    tokenizer = Tokenizer(num_words=vocab_size)\n",
    "\n",
    "    # Dividir el conjunto de datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        dataset['text'], dataset['author'], test_size=0.2, random_state=42)\n",
    "\n",
    "    # Tokenizar\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.transform(y_test)\n",
    "\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "    max_length = 200\n",
    "    X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
    "    X_test = pad_sequences(X_test, maxlen=max_length, padding='post')\n",
    "\n",
    "    # Construir la matriz de embeddings\n",
    "    embedding_matrix = np.zeros((vocab_size, size))\n",
    "    for word, index in word2vecModel.wv.key_to_index.items():\n",
    "        embedding_matrix[index] = word2vecModel.wv[word]\n",
    "    \n",
    "    # Entrenar y evaluar para cada arquitectura\n",
    "    for modelToTrain in [build_simple_model, build_deep_model, build_batchnorm_model]:\n",
    "        print(f\"Entrenando con embeddings de tamaño: {size}\")\n",
    "        \n",
    "        model, arquitectureLabel = modelToTrain(vocab_size, size, embedding_matrix)\n",
    "        \n",
    "        # Callback de EarlyStopping\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        history = compile_and_train_model(model, X_train, y_train, X_val, y_val, size, arquitectureLabel)\n",
    "\n",
    "        # Evaluación del modelo en el conjunto de prueba\n",
    "        test_loss, test_accuracy = history.model.evaluate(X_test, y_test)\n",
    "        \n",
    "        # Predicciones\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # Calcular precisión, recall y f1\n",
    "        precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "        results[f\"{size}_{arquitectureLabel}\"] = {\n",
    "            \"accuracy\": test_accuracy,\n",
    "            \"loss\": test_loss,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1\n",
    "        }\n",
    "\n",
    "# Mostrar resultados finales\n",
    "for size, metrics in results.items():\n",
    "    print(f\"Results for embeddings size {size}:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']}\")\n",
    "    print(f\"Precision: {metrics['precision']}\")\n",
    "    print(f\"Recall: {metrics['recall']}\")\n",
    "    print(f\"F1 Score: {metrics['f1_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestran los resultados de las metricas con los modelos evaluados con las dimensiones especificadas en un dataframe especificando el accuracy, loss, precision, recall y el f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>300_simple</th>\n",
       "      <th>300_deep</th>\n",
       "      <th>300_batchNorm</th>\n",
       "      <th>400_simple</th>\n",
       "      <th>400_deep</th>\n",
       "      <th>400_batchNorm</th>\n",
       "      <th>500_simple</th>\n",
       "      <th>500_deep</th>\n",
       "      <th>500_batchNorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.547988</td>\n",
       "      <td>0.547988</td>\n",
       "      <td>0.396285</td>\n",
       "      <td>0.547988</td>\n",
       "      <td>0.547988</td>\n",
       "      <td>0.551084</td>\n",
       "      <td>0.547988</td>\n",
       "      <td>0.547988</td>\n",
       "      <td>0.547988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>0.843489</td>\n",
       "      <td>0.851372</td>\n",
       "      <td>0.867235</td>\n",
       "      <td>0.848563</td>\n",
       "      <td>0.849432</td>\n",
       "      <td>0.851164</td>\n",
       "      <td>0.853582</td>\n",
       "      <td>0.850351</td>\n",
       "      <td>0.855323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.300290</td>\n",
       "      <td>0.300290</td>\n",
       "      <td>0.160489</td>\n",
       "      <td>0.300290</td>\n",
       "      <td>0.300290</td>\n",
       "      <td>0.527673</td>\n",
       "      <td>0.300290</td>\n",
       "      <td>0.300290</td>\n",
       "      <td>0.519861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.547988</td>\n",
       "      <td>0.547988</td>\n",
       "      <td>0.396285</td>\n",
       "      <td>0.547988</td>\n",
       "      <td>0.547988</td>\n",
       "      <td>0.551084</td>\n",
       "      <td>0.547988</td>\n",
       "      <td>0.547988</td>\n",
       "      <td>0.547988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.387975</td>\n",
       "      <td>0.387975</td>\n",
       "      <td>0.228457</td>\n",
       "      <td>0.387975</td>\n",
       "      <td>0.387975</td>\n",
       "      <td>0.538700</td>\n",
       "      <td>0.387975</td>\n",
       "      <td>0.387975</td>\n",
       "      <td>0.533515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           300_simple  300_deep  300_batchNorm  400_simple  400_deep  \\\n",
       "accuracy     0.547988  0.547988       0.396285    0.547988  0.547988   \n",
       "loss         0.843489  0.851372       0.867235    0.848563  0.849432   \n",
       "precision    0.300290  0.300290       0.160489    0.300290  0.300290   \n",
       "recall       0.547988  0.547988       0.396285    0.547988  0.547988   \n",
       "f1_score     0.387975  0.387975       0.228457    0.387975  0.387975   \n",
       "\n",
       "           400_batchNorm  500_simple  500_deep  500_batchNorm  \n",
       "accuracy        0.551084    0.547988  0.547988       0.547988  \n",
       "loss            0.851164    0.853582  0.850351       0.855323  \n",
       "precision       0.527673    0.300290  0.300290       0.519861  \n",
       "recall          0.551084    0.547988  0.547988       0.547988  \n",
       "f1_score        0.538700    0.387975  0.387975       0.533515  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza una implementación para evidenciar graficamente la comparación de modelos con las metricas consideradas y las dimensiones definidas anteriormente,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df = pd.DataFrame(results).T\n",
    "\n",
    "# Crear gráficos comparativos\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "df[metrics].plot(kind='bar', figsize=(12, 8))\n",
    "plt.title('Comparación de Métricas para Diferentes Modelos')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Modelos')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar gráfico\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
