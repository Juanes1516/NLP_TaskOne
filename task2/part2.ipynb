{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAREA 2\n",
    "## Modelos de lenguage: N-gramas\n",
    "### Parte 2\n",
    "\n",
    "Para el desarrollo de los puntos 5 y 6, se va a proceder con la implementación del cálculo de la perplejidad para los modelos unigrama, bigrama y trigrama. Se va a utilizar los archivos de prueba generados en el punto 3 (20N_4_testing.txt y BAC_4_testing.txt) y las probabilidades ya generadas en el punto 4 (archivos de unigramas, bigramas y trigramas).\n",
    "\n",
    "A continuación se realizan las importaciones necesarias para importar bibliotecas para el procesamiento de lenguaje natural con NLTK, manejo de archivos comprimidos, web scraping, manipulación de datos JSON y combinaciones, además de optimización de cálculos usando GPU con cupy. Facilita tareas como tokenización, creación de n-gramas y análisis eficiente de datos textuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk import (\n",
    "sent_tokenize,\n",
    "word_tokenize,\n",
    "ngrams,\n",
    "bigrams,\n",
    "trigrams\n",
    ")\n",
    "import tarfile\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "import zipfile\n",
    "import json\n",
    "from itertools import combinations_with_replacement\n",
    "import cupy as cp\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la ruta para leer los resultados de la implementación del punto 3 y 4 con los archivos de prueba y los modelos N-gram generados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_dir = \"C:/Users/LENOVO/Downloads/Datasets/resultados\"  # Ruta al directorio con los resultados de los puntos anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes líneas definen las rutas de los archivos de prueba generados en el punto 3. path_testing_BAC y path_testing_20N apuntan a los archivos con las oraciones de prueba del 20% de los datos, que se utilizarán para calcular la perplejidad de los modelos N-Gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_testing_BAC = os.path.join(resultados_dir, 'BAC_4_testing.txt')\n",
    "path_testing_20N = os.path.join(resultados_dir, '20N_4_testing.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Las siguientes , definen las rutas de los archivos JSON que contienen los modelos N-Gram (unigrama, bigrama y trigram) para los conjuntos de datos BAC y 20N, ubicados en la carpeta resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_file_BAC = os.path.join(resultados_dir, 'BAC_4_unigrams.json')\n",
    "bigram_file_BAC = os.path.join(resultados_dir, 'BAC_4_bigrams.json')\n",
    "trigram_file_BAC = os.path.join(resultados_dir, 'BAC_4_trigrams.json')\n",
    "\n",
    "unigram_file_20N = os.path.join(resultados_dir, '20N_4_unigrams.json')\n",
    "bigram_file_20N = os.path.join(resultados_dir, '20N_4_bigrams.json')\n",
    "trigram_file_20N = os.path.join(resultados_dir, '20N_4_trigrams.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. (15p) Using the test dataset, calculate the perplexity of each of the language models. Report the results obtained.If you experience variable overflow, use probabilities in log space\n",
    "\n",
    "A continuación, la siguiente implementación calcula la perplejidada para un modelo de unigramas. Carga el modelo previamente generado, y para cada palabra en las oraciones de prueba, obtiene su probabilidad (o usa la de <UNK> si no está en el modelo). Suma los logaritmos de esas probabilidades y luego calcula la perplejidad total a partir de la suma acumulada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity BAC (unigrama): 605.4393675378017\n",
      "Perplexity 20N (unigrama): 745.3769679173222\n"
     ]
    }
   ],
   "source": [
    "def calculate_perplexity_unigram(test_file, model_file):\n",
    "    # Cargar el modelo de unigramas\n",
    "    with open(model_file, 'r') as f:\n",
    "        unigram_model = json.load(f)\n",
    "    \n",
    "    # Leer el archivo de prueba\n",
    "    with open(test_file, 'r', encoding='utf-8') as f:\n",
    "        sentences = f.readlines()\n",
    "\n",
    "    log_prob_sum = 0\n",
    "    total_words = 0\n",
    "\n",
    "    # Calcular la probabilidad para cada palabra en el conjunto de prueba\n",
    "    for sentence in sentences:\n",
    "        words = sentence.strip().split()\n",
    "        for word in words:\n",
    "            prob = unigram_model.get(word, unigram_model.get('<UNK>', 1e-6))  # Si no está, usar <UNK>\n",
    "            log_prob_sum += math.log(prob)\n",
    "            total_words += 1\n",
    "    \n",
    "    # Calcular la perplexity\n",
    "    perplexity = math.exp(-log_prob_sum / total_words)\n",
    "    return perplexity\n",
    "\n",
    "perplexity_unigram_BAC = calculate_perplexity_unigram(path_testing_BAC, unigram_file_BAC)\n",
    "perplexity_unigram_20N = calculate_perplexity_unigram(path_testing_20N, unigram_file_20N)\n",
    "print(\"Perplejidad BAC (unigrama):\", perplexity_unigram_BAC)\n",
    "print(\"Perplejidad 20N (unigrama):\", perplexity_unigram_20N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Esta función calcula la perplejidad para un modelo de bigramas. Para cada bigrama en las oraciones de prueba, obtiene su probabilidad del modelo (o usa <UNK> si no está en el modelo). Luego, acumula los logaritmos de las probabilidades para calcular la perplejidad total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity BAC (bigrama): 2746.495730388989\n",
      "Perplexity 20N (bigrama): 4944.588159592507\n"
     ]
    }
   ],
   "source": [
    "def calculate_perplexity_bigram(test_file, model_file):\n",
    "    # Cargar el modelo de bigramas\n",
    "    with open(model_file, 'r') as f:\n",
    "        bigram_model = json.load(f)\n",
    "    \n",
    "    # Leer el archivo de prueba\n",
    "    with open(test_file, 'r', encoding='utf-8') as f:\n",
    "        sentences = f.readlines()\n",
    "\n",
    "    log_prob_sum = 0\n",
    "    total_bigrams = 0\n",
    "\n",
    "    # Calcular la probabilidad para cada bigrama en el conjunto de prueba\n",
    "    for sentence in sentences:\n",
    "        words = sentence.strip().split()\n",
    "        bigrams_seq = list(bigrams(words))\n",
    "        for bg in bigrams_seq:\n",
    "            prob = bigram_model.get(str(bg), bigram_model.get(str(('<UNK>', bg[1])), 1e-6))  # Si no está, usar <UNK>\n",
    "            log_prob_sum += math.log(prob)\n",
    "            total_bigrams += 1\n",
    "    \n",
    "    # Calcular la perplexity\n",
    "    perplexity = math.exp(-log_prob_sum / total_bigrams)\n",
    "    return perplexity\n",
    "\n",
    "perplexity_bigram_BAC = calculate_perplexity_bigram(path_testing_BAC, bigram_file_BAC)\n",
    "perplexity_bigram_20N = calculate_perplexity_bigram(path_testing_20N, bigram_file_20N)\n",
    "print(\"Perplejidad BAC (bigrama):\", perplexity_bigram_BAC)\n",
    "print(\"Perplejiad 20N (bigrama):\", perplexity_bigram_20N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función calcula la perplejidad para un modelo de trigramas. Obtiene la probabilidad de cada trigrama en las oraciones de prueba y, si no está presente, utiliza <UNK>. Luego, acumula los logaritmos de las probabilidades para calcular la perplejidad total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity BAC (trigrama): 43353.28489503441\n",
      "Perplexity 20N (trigrama): 58320.094203029264\n"
     ]
    }
   ],
   "source": [
    "def calculate_perplexity_trigram(test_file, model_file):\n",
    "    # Cargar el modelo de trigramas\n",
    "    with open(model_file, 'r') as f:\n",
    "        trigram_model = json.load(f)\n",
    "    \n",
    "    # Leer el archivo de prueba\n",
    "    with open(test_file, 'r', encoding='utf-8') as f:\n",
    "        sentences = f.readlines()\n",
    "\n",
    "    log_prob_sum = 0\n",
    "    total_trigrams = 0\n",
    "\n",
    "    # Calcular la probabilidad para cada trigrama en el conjunto de prueba\n",
    "    for sentence in sentences:\n",
    "        words = sentence.strip().split()\n",
    "        trigrams_seq = list(trigrams(words))\n",
    "        for tg in trigrams_seq:\n",
    "            prob = trigram_model.get(str(tg), trigram_model.get(str(('<UNK>', tg[1], tg[2])), 1e-6))  # Si no está, usar <UNK>\n",
    "            log_prob_sum += math.log(prob)\n",
    "            total_trigrams += 1\n",
    "    \n",
    "    # Calcular la perplexity\n",
    "    perplexity = math.exp(-log_prob_sum / total_trigrams)\n",
    "    return perplexity\n",
    "\n",
    "perplexity_trigram_BAC = calculate_perplexity_trigram(path_testing_BAC, trigram_file_BAC)\n",
    "perplexity_trigram_20N = calculate_perplexity_trigram(path_testing_20N, trigram_file_20N)\n",
    "print(\"Perplejidad BAC (trigrama):\", perplexity_trigram_BAC)\n",
    "print(\"Perplejidad 20N (trigrama):\", perplexity_trigram_20N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. (15p) Using your best language model, build a method/function that automatically generates sentences by receiving the first word of a sentence as input. Take different tests and document them.\n",
    "\n",
    "A continuación, se efectúa la implementación para generar oraciones usando modelos de N-Gramas (unigrama, bigrama o trigramas). Dependiendo del valor de n, la función selecciona la siguiente palabra basándose en el contexto actual (las últimas n-1 palabras) y en las probabilidades del modelo.\n",
    "Dentro de esta se maneja:\n",
    "1. Se realiza la carga el modelo N-Gram desde un archivo JSON.\n",
    "2. Se genera la oración usando las palabras iniciales y selecciona las siguientes según las probabilidades del modelo.\n",
    "\n",
    "Esta implementación es funcional para diferentes modelos de N-Gramas (cambiando el valor de n), esta tiene en cuenta un control de errores para evitar problemas con el tamaño del N-Gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_unigram(model_file, max_length=5):\n",
    "    with open(model_file, 'r') as f:\n",
    "        unigram_model = json.load(f)\n",
    "\n",
    "    sentence = []\n",
    "\n",
    "    # Asegurarse de que la primera palabra no sea <s> o </s>\n",
    "    first_word = random.choices(\n",
    "        [word for word in unigram_model.keys() if word not in ['<s>', '</s>']],\n",
    "        weights=[unigram_model[word] for word in unigram_model.keys() if word not in ['<s>', '</s>']]\n",
    "    )[0]\n",
    "    sentence.append(first_word)\n",
    "\n",
    "    # Continuar generando el resto de la oración\n",
    "    for _ in range(max_length - 1):  \n",
    "        next_word = random.choices(list(unigram_model.keys()), weights=list(unigram_model.values()))[0]\n",
    "        if next_word == '</s>':\n",
    "            break\n",
    "        sentence.append(next_word)\n",
    "    \n",
    "    if len(sentence) < max_length:\n",
    "        sentence.append('</s>')\n",
    "    \n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oración generada en unigrama BAC: table true divorce the and\n",
      "Oración generada en unigrama 20N: buf t ax NUM of\n",
      "Oración generada en bigrama BAC: somebody new tricks\n",
      "Oración generada en bigrama 20N: somebody stankowitz and plausible\n",
      "Oración generada en trigrama BAC: when somebody messes with one </s>\n",
      "Oración generada en trigrama 20N: when somebody gets offed by </s>\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence_ngram(model_file, start_words, n, max_length=5):\n",
    "    with open(model_file, 'r') as f:\n",
    "        ngram_model = json.load(f)\n",
    "    \n",
    "    sentence = start_words[:]  # Comenzar con las palabras iniciales\n",
    "    current_context = tuple(start_words)  # Inicialmente, el contexto será el bigrama o trigrama dado\n",
    "    \n",
    "    for _ in range(max_length - len(start_words)):  # Se resta la longitud inicial del start_words\n",
    "        possible_next_words = [eval(k)[n-1] for k in ngram_model.keys() if len(eval(k)) >= n and eval(k)[:n-1] == current_context]        \n",
    "        if not possible_next_words:  # Si no hay posibles palabras siguientes, se detiene\n",
    "            break\n",
    "    \n",
    "        next_word = random.choices(possible_next_words, weights=[ngram_model[str((*current_context, w))] for w in possible_next_words])[0]\n",
    "        \n",
    "        if next_word == '</s>':  \n",
    "            break\n",
    "        \n",
    "        sentence.append(next_word)\n",
    "        \n",
    "        current_context = tuple(sentence[-(n-1):])  # Mantener las últimas n-1 palabras en el contexto\n",
    "    \n",
    "    if len(sentence) >= max_length:\n",
    "        sentence.append('</s>')\n",
    "\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "# Ejemplo de uso\n",
    "start_word_bigram = [\"somebody\"]\n",
    "start_words_trigram = [\"when\", \"somebody\"]\n",
    "\n",
    "generated_sentence_unigram_BAC = generate_sentence_unigram(unigram_file_BAC, max_length=5)\n",
    "generated_sentence_unigram_20N = generate_sentence_unigram(unigram_file_20N, max_length=5)\n",
    "\n",
    "generated_sentence_bigram_BAC = generate_sentence_ngram(bigram_file_BAC, start_word_bigram, n=2, max_length=5)\n",
    "generated_sentence_bigram_20N = generate_sentence_ngram(bigram_file_20N, start_word_bigram, n=2, max_length=5)\n",
    "\n",
    "generated_sentence_trigram_BAC = generate_sentence_ngram(trigram_file_BAC, start_words_trigram, n=3, max_length=5)\n",
    "generated_sentence_trigram_20N = generate_sentence_ngram(trigram_file_20N, start_words_trigram, n=3, max_length=5)\n",
    "\n",
    "print(\"Oración generada en unigrama BAC:\", generated_sentence_unigram_BAC)\n",
    "print(\"Oración generada en unigrama 20N:\", generated_sentence_unigram_20N)\n",
    "print(\"Oración generada en bigrama BAC:\", generated_sentence_bigram_BAC)\n",
    "print(\"Oración generada en bigrama 20N:\", generated_sentence_bigram_20N)\n",
    "print(\"Oración generada en trigrama BAC:\", generated_sentence_trigram_BAC)\n",
    "print(\"Oración generada en trigrama 20N:\", generated_sentence_trigram_20N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
